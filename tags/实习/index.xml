<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>实习 on ionfeather&#39;Log</title>
        <link>https://ionfeather.github.io/tags/%E5%AE%9E%E4%B9%A0/</link>
        <description>Recent content in 实习 on ionfeather&#39;Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>ionfeather&#39;Log</copyright>
        <lastBuildDate>Thu, 08 Jan 2026 17:14:41 +0800</lastBuildDate><atom:link href="https://ionfeather.github.io/tags/%E5%AE%9E%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>实习 | 兽人永不为奴，但偶尔可以</title>
        <link>https://ionfeather.github.io/2026/intern/</link>
        <pubDate>Thu, 08 Jan 2026 17:14:41 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2026/intern/</guid>
        <description>&lt;p&gt;终于编好了实习的简历。这个帖子记录一下我准备的可能的问题以及面试中的问题。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;微调&#34;&gt;微调
&lt;/h3&gt;&lt;p&gt;LoRA：Low-Rank Adaptation of LLM&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点是什么？
&lt;ul&gt;
&lt;li&gt;参数少：0.1%-0.01%&lt;/li&gt;
&lt;li&gt;速度快：训练和部署&lt;/li&gt;
&lt;li&gt;模块化：不影响原始模型
&lt;ul&gt;
&lt;li&gt;避免灾难性遗忘&lt;/li&gt;
&lt;li&gt;存储效率高&lt;/li&gt;
&lt;li&gt;快速切换&lt;/li&gt;
&lt;li&gt;兼容性强&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;为什么可以进行低秩分解？
&lt;ul&gt;
&lt;li&gt;奇异值分解&lt;/li&gt;
&lt;li&gt;大部分信息集中在了少量的奇异值上。&lt;/li&gt;
&lt;li&gt;LoRA论文中GPT-3上的$\Delta W$的前10-20个奇异值就可以保留90%以上的信息&lt;/li&gt;
&lt;li&gt;由于$\Delta W$的秩很低，可以用A和B直接构造，不需要完整的SVD计算，更加高效&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;一个$512\times 512$的权重矩阵，全微调可能需要$512\times 512$的调整参数量，LoRA如果r=8，只需要$512\times 8$和$8\times 512$的参数变化。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;LoRA如何更新参数？
&lt;ul&gt;
&lt;li&gt;反向传播算法。具体来说是$W&amp;rsquo;=W+\Delta W=W+A\times B$。&lt;/li&gt;
&lt;li&gt;Step1：初始化
&lt;ul&gt;
&lt;li&gt;$W$是预训练好的权重&lt;/li&gt;
&lt;li&gt;$A$通常用小的随机值初始化&lt;/li&gt;
&lt;li&gt;$B$初始可以设置为全0，这样$\Delta W$=0，不干扰原始模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step2：计算损失
&lt;ul&gt;
&lt;li&gt;对于输入X，前向传播计算得到输出$Y_{pred}=(W+A\times B)\times X$。&lt;/li&gt;
&lt;li&gt;根据任务定义损失函数$L=Loss(Y_{true},Y_{pred})$。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step3：反向传播更新
&lt;ul&gt;
&lt;li&gt;计算损失$L$对$A$和$B$的梯度&lt;/li&gt;
&lt;li&gt;梯度下降更新&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step4：迭代优化
&lt;ul&gt;
&lt;li&gt;重复Step2和Step3，直到损失收敛或者达到预定训练轮次&lt;/li&gt;
&lt;li&gt;最终得到$A$和$B$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用在Transformer的哪个层？
&lt;ul&gt;
&lt;li&gt;注意力层中的$W_q$和$W_v$较多，其他的收益有限&lt;/li&gt;
&lt;li&gt;前馈层的LoRA可能会用在较大模型上&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LoRA改进版本
&lt;ul&gt;
&lt;li&gt;LoRA+：加速
&lt;ul&gt;
&lt;li&gt;靠近输出的权重B应该对梯度变化更敏感，需要更大调整。所以调整得B比A的学习率高&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DoRA：稳定高性能
&lt;ul&gt;
&lt;li&gt;把预训练权重矩阵分解为幅度和方向$W=m\times V$&lt;/li&gt;
&lt;li&gt;微调的时候调整方向$V$，幅度单独训练&lt;/li&gt;
&lt;li&gt;训练量增加，性能高&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;rsLoRA：稳定
&lt;ul&gt;
&lt;li&gt;引入动态秩调整和稳定化因子优化训练&lt;/li&gt;
&lt;li&gt;$W&amp;rsquo;=W+\Delta W=W+(\frac{\alpha}{\sqrt{r}})A\times B$。&lt;/li&gt;
&lt;li&gt;训练更稳定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PiSSA：收敛快
&lt;ul&gt;
&lt;li&gt;优化初始化，把A和B矩阵初始化使用SVD分解&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GaLore：内存极低&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LoRA需要的超参数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下是 LLaMA Factory 微调中最重要的超参数及其核心作用的总结表格。这些参数直接决定了微调的成功与否、效率以及资源消耗。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;参数类别&lt;/th&gt;
          &lt;th&gt;参数名&lt;/th&gt;
          &lt;th&gt;核心作用&lt;/th&gt;
          &lt;th&gt;关键建议与说明&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;训练核心​&lt;/td&gt;
          &lt;td&gt;学习率​&lt;/td&gt;
          &lt;td&gt;控制模型参数更新的步长，是影响收敛速度和稳定性的最关键参数。&lt;/td&gt;
          &lt;td&gt;LoRA/QLoRA：可稍大，常用 &lt;code&gt;1e-4&lt;/code&gt;到 &lt;code&gt;5e-4&lt;/code&gt;。  &lt;br&gt;全量微调：需谨慎，常用 &lt;code&gt;1e-5&lt;/code&gt;到 &lt;code&gt;3e-5&lt;/code&gt;。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;per_device_train_batch_size&lt;/code&gt;​  &lt;br&gt;&lt;code&gt;gradient_accumulation_steps&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;共同决定有效批处理大小，影响训练稳定性和显存占用。&lt;/td&gt;
          &lt;td&gt;有效批大小 = 批大小 × 累积步数。建议将此值保持在 16 或以上以获得稳定训练。批大小受显存限制，多用累积步数来补偿。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LoRA核心​&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;lora_rank&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;决定LoRA适配器的能力与参数数量。秩越高，拟合能力越强，但也更易过拟合。&lt;/td&gt;
          &lt;td&gt;通用任务从 8、16 或 32​ 开始尝试。复杂任务可尝试 64 或更高。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;lora_alpha&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;控制LoRA适配器输出的缩放因子，与 &lt;code&gt;lora_rank&lt;/code&gt;配合调节更新强度。&lt;/td&gt;
          &lt;td&gt;一个稳定的经验法则是设置为 &lt;code&gt;lora_rank&lt;/code&gt;的两倍（例如 rank=16, alpha=32）。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;流程控制​&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;num_train_epochs&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;控制整个数据集训练的遍数，直接影响是否过拟合。&lt;/td&gt;
          &lt;td&gt;指令微调通常 1-3 个 epoch​ 足够。务必监视验证集损失，考虑启用早停。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据格式​&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;template&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;指定数据格式模板，将数据转化为模型熟知的对话格式。选错会导致模型无法理解指令。&lt;/td&gt;
          &lt;td&gt;如果不确定，优先使用 &lt;code&gt;default&lt;/code&gt;​ 或与预训练模型对应的模板（如 &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;llama3&lt;/code&gt;）。这是最易忽略但致命的一环。&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;资源与长度​&lt;/td&gt;
          &lt;td&gt;&lt;code&gt;cutoff_len&lt;/code&gt;​&lt;/td&gt;
          &lt;td&gt;设置单条训练数据的最大长度，直接影响显存占用。&lt;/td&gt;
          &lt;td&gt;在显存允许下，根据任务实际需要的上下文长度设置。过短会丢失信息，过长浪费资源。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        
    </channel>
</rss>
