<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>LLM on ionfeather&#39;Log</title>
        <link>https://ionfeather.github.io/tags/llm/</link>
        <description>Recent content in LLM on ionfeather&#39;Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>ionfeather&#39;Log</copyright>
        <lastBuildDate>Tue, 23 Sep 2025 17:22:57 +0800</lastBuildDate><atom:link href="https://ionfeather.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>论文阅读| MCTS</title>
        <link>https://ionfeather.github.io/2025/mcts/</link>
        <pubDate>Tue, 23 Sep 2025 17:22:57 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/mcts/</guid>
        <description>&lt;h2 id=&#34;mcts&#34;&gt;MCTS
&lt;/h2&gt;&lt;h2 id=&#34;mc-dml&#34;&gt;MC-DML
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2504.16855&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2504.16855] Monte Carlo Planning with Large Language Model for Text-Based Game Agents&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;主要解决的问题&#34;&gt;主要解决的问题
&lt;/h3&gt;&lt;p&gt;解决了文字冒险游戏中 AI 规划效率低、缺乏语言理解与经验记忆能力。&lt;/p&gt;
&lt;h3 id=&#34;面临挑战&#34;&gt;面临挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;游戏环境很复杂&lt;/li&gt;
&lt;li&gt;传统的MCTS有局限性&lt;/li&gt;
&lt;li&gt;LLM难以将规划转化成可执行动作，且无法平衡探索与利用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/mcts/assets/IMG-20251008192705223.png&#34;
	width=&#34;890&#34;
	height=&#34;250&#34;
	srcset=&#34;https://ionfeather.github.io/2025/mcts/assets/IMG-20251008192705223_hu_93a9abd9d704c198.png 480w, https://ionfeather.github.io/2025/mcts/assets/IMG-20251008192705223_hu_f511625d83e9b034.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Zork1游戏。这种游戏需要的不能只是短期决策，而是需要长远规划。&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;356&#34;
		data-flex-basis=&#34;854px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;核心方法&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;MC-DML（Monte Carlo planning with Dynamic Memory-guided Large language model）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;四阶段规划流程&lt;/strong&gt;：沿用 MCTS 的Selection, Expansion, Simulation, Backpropagation四阶段。在扩展阶段引入 LLM 作为先验策略，让 LLM 基于场景文本为可选动作分配非均匀搜索优先级；模拟阶段通过多轮推演评估动作结果，回溯阶段更新节点价值与访问次数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;双动态记忆机制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;「 trial 内记忆（$M_i$）」：存储当前轨迹历史（如 “前一观测 - 动作 - 当前观测”），帮 LLM 结合当下语境生成动作概率分布；&lt;/li&gt;
&lt;li&gt;「 trial 间记忆（$M_c$）」：存储过去失败轨迹的反思（如 “无光源时勿入黑暗区域”），动态调整动作价值评估，避免重复犯错。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动作选择公式优化&lt;/strong&gt;：在 PUCT（改进型 MCTS）公式基础上，将 LLM 生成的动作概率（结合双记忆）融入计算，确保选择既符合语言逻辑又兼顾探索-利用平衡。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>书籍阅读 | Speech and Language Processing</title>
        <link>https://ionfeather.github.io/2025/speech-and-language-processing/</link>
        <pubDate>Thu, 28 Aug 2025 19:28:49 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/speech-and-language-processing/</guid>
        <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;阅读&lt;a class=&#34;link&#34; href=&#34;https://web.stanford.edu/~jurafsky/slp3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Speech and Language Processing&lt;/a&gt;这本书的一些笔记。&lt;/p&gt;
&lt;h2 id=&#34;words-and-tokens&#34;&gt;Words and Tokens
&lt;/h2&gt;&lt;p&gt;我们需要一个东西来建模语言，下面是我们的选择：&lt;/p&gt;
&lt;h3 id=&#34;words&#34;&gt;Words
&lt;/h3&gt;&lt;p&gt;为什么不用词？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有些语言没有orthographic words&lt;/li&gt;
&lt;li&gt;词的数量会随着文章增长，词汇表永远都会覆盖不足&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;morphemes&#34;&gt;Morphemes
&lt;/h3&gt;&lt;p&gt;语素类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;屈折语素：inflectional morphemes&lt;/li&gt;
&lt;li&gt;派生语素：derivational morphemes&lt;/li&gt;
&lt;li&gt;附着语素：clitic&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;语言类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analytic&lt;/li&gt;
&lt;li&gt;polysynthetic&lt;/li&gt;
&lt;li&gt;fusional&lt;/li&gt;
&lt;li&gt;agglutinative&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么不用语素？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;语素很复杂，很难定义&lt;/li&gt;
&lt;li&gt;不同语言不同且难以统一&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unicode&#34;&gt;Unicode
&lt;/h3&gt;&lt;p&gt;Unicode的历史&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ASCII&lt;/li&gt;
&lt;li&gt;CJKV&lt;/li&gt;
&lt;li&gt;不断更新中，越来越多，Unicode 16.0已经包含超过150000个字符&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;code-points&#34;&gt;Code Points
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;U+：表示接下来要用Unicode十六进制表示一个code point&lt;/li&gt;
&lt;li&gt;U+0061：0x0061一个意思，也就小写字母a。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;utf-8&#34;&gt;UTF-8
&lt;/h4&gt;&lt;p&gt;目前最常用的encoding字符的方式。中文字符 “中” 的 Unicode 码点是&lt;code&gt;U+4E2D&lt;/code&gt;，UTF-8 编码后为 3 个字节：&lt;code&gt;0xE4 0xB8 0xAD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;UTF-8是一种变长编码，兼容ASCII。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如「世」，UTF-8 编码是&lt;code&gt;0xE4 B8 96&lt;/code&gt;，其中E4的二进制为&lt;code&gt;11100110H&lt;/code&gt;，开头的&lt;code&gt;1110H&lt;/code&gt;表示这是一个3字节字符的第一个字节。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subword-tokenization-byte-pair-encoding&#34;&gt;Subword Tokenization: Byte-Pair Encoding
&lt;/h3&gt;&lt;p&gt;上面的三个候选都不行，word和morpheme难以规范定义，character可以通过unicode来定义，但又对于作为tokens来说太小了。&lt;/p&gt;
&lt;p&gt;为什么要tokenize输入？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将输入转换为一组确定的、固定的单元（Token），能让不同的算法和系统在一些简单问题上达成共识。例如困惑度的计算。&lt;/li&gt;
&lt;li&gt;对可复现很重要&lt;/li&gt;
&lt;li&gt;为了消除unknown words的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了消除unknown words问题，现代tokenizers自动引入了token包含那些比words小的token，叫subword。&lt;/p&gt;
&lt;p&gt;使用&lt;a class=&#34;link&#34; href=&#34;https://platform.openai.com/tokenizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tokenizer - OpenAI API&lt;/a&gt;中的&lt;code&gt;GPT-4o &amp;amp;  GPT-4o mini&lt;/code&gt;来分词下面这一大段话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, if we had happened not to ever see the word lower, when it appears we could segment it successfully into low and er which we had already seen. In the worst case, a really unusual word (perhaps an acronym like GRPO) could be tokenized as a sequence of individual letters if necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最终得到的是
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982.png&#34;
	width=&#34;711&#34;
	height=&#34;279&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_b760c9dcae731844.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_3812253da13ed9c0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;611px&#34;
	
&gt;
现在最流行的tokenization algorithm有两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Byte-Pair Encoding(BPE)&lt;/li&gt;
&lt;li&gt;Unigram Language modeling(ULM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;bpe&#34;&gt;BPE
&lt;/h4&gt;&lt;p&gt;通过分析训练语料，自动学习出一套子词集合（词汇表），使得高频出现的字符 / 子词组合被合并为更大的子词单位。&lt;/p&gt;
&lt;p&gt;训练方法介绍。&lt;/p&gt;
&lt;h4 id=&#34;bpe-encoder&#34;&gt;BPE encoder
&lt;/h4&gt;&lt;h4 id=&#34;bpe-in-practice&#34;&gt;BPE in practice
&lt;/h4&gt;&lt;p&gt;通常，我们会对 UTF-8 编码文本的&lt;strong&gt;单个字节&lt;/strong&gt;执行 BPE 操作。BPE 处理 “中” 时，输入并非&lt;code&gt;U+4E2D&lt;/code&gt;这个码点，而是&lt;code&gt;E4&lt;/code&gt;、&lt;code&gt;B8&lt;/code&gt;、&lt;code&gt;AD&lt;/code&gt;这三个独立字节。&lt;/p&gt;
&lt;p&gt;仅在&lt;strong&gt;预先切分出的单词内部&lt;/strong&gt;执行 BPE 操作，有助于避免潜在问题。&lt;/p&gt;
&lt;p&gt;一些英语里的小发现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数单词的tokens是他们自己，包含词前空格。这样可以避免独立单词和单词内部的subword。&lt;/li&gt;
&lt;li&gt;附着语素Clitics在名字后面分开单独成token，但在常见的词语后面会是token的一部分&lt;/li&gt;
&lt;li&gt;数字通常三位一组&lt;/li&gt;
&lt;li&gt;一些词，如Anyhow和anyhow会有不同的分割方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个和预处理有关系。&lt;/p&gt;
&lt;p&gt;SuperBPE会合并常规的BPE子词分词，效率更高。&lt;/p&gt;
&lt;p&gt;特别地，低资源语言的tokens更碎，就会输出边长，最终LLM的效率变低。&lt;/p&gt;
&lt;h3 id=&#34;rule-based-tokenization&#34;&gt;Rule-based tokenization
&lt;/h3&gt;&lt;p&gt;Penn Treebank Tokenization Standard）：事实性规范。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分开附着语素&lt;/li&gt;
&lt;li&gt;保留连字符连接的词&lt;/li&gt;
&lt;li&gt;分开所有的标点符号&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sentence-segmentation&#34;&gt;Sentence Segmentation
&lt;/h4&gt;&lt;p&gt;sentence tokenization可以和word tokenization联合处理。&lt;/p&gt;
&lt;h3 id=&#34;corpora&#34;&gt;Corpora
&lt;/h3&gt;&lt;p&gt;语料库和语言数量、使用者的特征都有关。&lt;/p&gt;
&lt;p&gt;code switching：在一次持续的交流）中，说话者或作者交替使用两种或多种 “语码”的现象。&lt;/p&gt;
&lt;p&gt;datasheet：存储一句话的特征，如时间、说话人性格、阶级&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;regular-expressions&#34;&gt;Regular Expressions
&lt;/h3&gt;&lt;p&gt;正则表达式的具体实现。包含字符析取、计数、可选性、通配符、锚点和边界、替换和捕获组、前向断言等。&lt;/p&gt;
&lt;h3 id=&#34;simple-unix-tools-for-word-tokenization&#34;&gt;Simple Unix Tools for Word Tokenization
&lt;/h3&gt;&lt;p&gt;可以在Unix、Linux系统中使用正则表达式。如&lt;code&gt;tr -sc &#39;A-Za-z&#39; &#39;\n&#39; &amp;lt; sh.txt&lt;/code&gt;表示从 &lt;code&gt;sh.txt&lt;/code&gt; 文件中提取所有英文字母，并将非字母字符替换为换行符，同时压缩连续的非字母字符为单个换行符。&lt;/p&gt;
&lt;h3 id=&#34;minimum-edit-distance&#34;&gt;Minimum Edit Distance
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;最小编辑距离&lt;/strong&gt;：将一个字符串通过 “插入”“删除”“替换” 三种基本操作转换为另一个字符串所需的最少操作次数&lt;/p&gt;
&lt;h4 id=&#34;the-minimum-edit-distance-algorithm&#34;&gt;The Minimum Edit Distance Algorithm
&lt;/h4&gt;&lt;p&gt;一个经典的动态规划问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;字符对齐&lt;/strong&gt;：通过回溯编辑距离矩阵中的 “最优路径”，反向推导出将一个字符串转换为另一个字符串的具体操作序列。也就是&lt;strong&gt;路径可视化&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;exercies&#34;&gt;Exercies
&lt;/h3&gt;&lt;details&gt;
    &lt;summary&gt;点击展开&lt;/summary&gt;
    &lt;h5 id=&#34;21&#34;&gt;2.1
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all alphabetic strings.&lt;/li&gt;
&lt;li&gt;The set of all lowercase alphabetic strings ending in &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The set of all strings from the alphabet {a, b} such that each &amp;ldquo;a&amp;rdquo; is immediately preceded by and immediately followed by a &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;22&#34;&gt;2.2
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages. By &amp;ldquo;word&amp;rdquo;, we mean an alphabetic string separated from other words by whitespace, relevant punctuation, line breaks, etc.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all strings with two consecutive repeated words (e.g., &amp;ldquo;Humbert Humbert&amp;rdquo; and &amp;ldquo;the the&amp;rdquo; but not &amp;ldquo;the bug&amp;rdquo; or &amp;ldquo;the big bug&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;All strings that start at the beginning of the line with an integer and end at the end of the line with a word.&lt;/li&gt;
&lt;li&gt;All strings that have both the word &amp;ldquo;grotto&amp;rdquo; and the word &amp;ldquo;raven&amp;rdquo; in them (but not, e.g., words like &amp;ldquo;grottos&amp;rdquo; that merely contain &amp;ldquo;grotto&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Write a pattern that places the first word of an English sentence in a register. Deal with punctuation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;23&#34;&gt;2.3
&lt;/h5&gt;&lt;p&gt;Implement an ELIZA-like program, using substitutions such as those described on page 27. You might want to choose a different domain than a Rogerian psychologist, although keep in mind that you would need a domain in which your program can legitimately engage in a lot of simple repetition.&lt;/p&gt;
&lt;h5 id=&#34;24&#34;&gt;2.4
&lt;/h5&gt;&lt;p&gt;Compute the edit distance (using insertion cost 1, deletion cost 1, substitution cost 1) of &amp;ldquo;leda&amp;rdquo; to &amp;ldquo;deal&amp;rdquo;. Show your work (using the edit distance grid).&lt;/p&gt;
&lt;h5 id=&#34;25&#34;&gt;2.5
&lt;/h5&gt;&lt;p&gt;Figure out whether &amp;ldquo;drive&amp;rdquo; is closer to &amp;ldquo;brief&amp;rdquo; or to &amp;ldquo;divers&amp;rdquo; and what the edit distance is to each. You may use any version of distance that you like.&lt;/p&gt;
&lt;h5 id=&#34;26&#34;&gt;2.6
&lt;/h5&gt;&lt;p&gt;Now implement a minimum edit distance algorithm and use your hand-computed results to check your code.&lt;/p&gt;
&lt;h5 id=&#34;27&#34;&gt;2.7
&lt;/h5&gt;&lt;p&gt;Augment the minimum edit distance algorithm to output an alignment; you will need to store pointers and add a stage to compute the backtrace.&lt;/p&gt;

&lt;/details&gt;

&lt;h2 id=&#34;n-gram-language-models&#34;&gt;N-gram Language Models
&lt;/h2&gt;&lt;p&gt;本章介绍最简单的语言模型：&lt;strong&gt;N元语法语言模型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;n-grams&#34;&gt;N-Grams
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;概率链式法则&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;how-to-estimate-probabilities&#34;&gt;How to estimate probabilities
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;马尔科夫假设&lt;/strong&gt;：假设一个单词的出现概率只和前面的一个单词有关。那么n-gram即只和前面的$n-1$个单词有关。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大似然估计&lt;/strong&gt;：已知前一个词$w_{n−1}$​时，当前词$w_n$​的概率&lt;/p&gt;
&lt;p&gt;终止符号（end-symbol）：所有可能句子的概率总和为 1，否则是特定长度的所有句子概率之和为 1。&lt;/p&gt;
&lt;h4 id=&#34;dealing-with-scale-in-large-n-gram-models&#34;&gt;Dealing with scale in large n-gram models
&lt;/h4&gt;&lt;p&gt;Log probabilities&lt;/p&gt;
&lt;p&gt;N元语法的计算现在甚至能达到无限元。&lt;/p&gt;
&lt;p&gt;对N元语法模型进行修剪也是很重要的。&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-training-and-test-sets&#34;&gt;Evaluating Language Models: Training and Test Sets
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;内部评估&lt;/strong&gt;和外部评估。&lt;/p&gt;
&lt;p&gt;训练集、开发集和测试集。&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-perplexity&#34;&gt;Evaluating Language Models: Perplexity
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Perplexity（PPL）&lt;/strong&gt;：困惑度越低，说明模型对文本的预测越准确（即模型越 “不困惑”）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;具体来说，是“联合概率倒数的几何平均值”。&lt;/li&gt;
&lt;li&gt;在计算的时候常常会取对数来将求乘积变为求和，避免数值问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;perplexity-as-weighted-average-branching-factor&#34;&gt;Perplexity as Weighted Average Branching Factor
&lt;/h5&gt;&lt;p&gt;困惑度也可以理解为&lt;strong&gt;加权平均分支系数&lt;/strong&gt;。其中，语言的 “分支系数”指的是 “任何一个词之后可能出现的下一个词的数量”。&lt;/p&gt;
&lt;h3 id=&#34;sampling-sentences-from-a-language-model&#34;&gt;Sampling sentences from a language model
&lt;/h3&gt;&lt;p&gt;“0-1 数轴 + 区间映射”来理解采样的基本原理。&lt;/p&gt;
&lt;h3 id=&#34;generalizing-vs-overfitting-the-training-set&#34;&gt;Generalizing vs. overfitting the training set
&lt;/h3&gt;&lt;p&gt;对于莎士比亚文本和华尔街日报的文本，两者差异过大以至于不能分别作为训练集和测试集。&lt;/p&gt;
&lt;p&gt;所以说要确保训练集和测试集的领域要相似。&lt;/p&gt;
&lt;h3 id=&#34;smoothing-interpolation-and-backoff&#34;&gt;Smoothing, Interpolation, and Backoff
&lt;/h3&gt;&lt;p&gt;zero probability n-grams有两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;低估了词语序可能出现的可能性，导致最终的性能变差&lt;/li&gt;
&lt;li&gt;困惑度无法计算，因为无法除以0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此需要Smoothing或者discounting&lt;/p&gt;
&lt;h4 id=&#34;laplace-smoothing&#34;&gt;Laplace Smoothing
&lt;/h4&gt;&lt;p&gt;其实也就是add one smoothing，就是对于所有的N元语法都加一。&lt;/p&gt;
&lt;p&gt;对于语言模型来说，结果并不是很好。对文本分类有效。&lt;/p&gt;
&lt;h4 id=&#34;add-k-smoothing&#34;&gt;Add-k Smoothing
&lt;/h4&gt;&lt;p&gt;也就是对所有的都加K。&lt;/p&gt;
&lt;p&gt;对语言模型来说仍然效果一般。&lt;/p&gt;
&lt;h4 id=&#34;language-model-interpolation&#34;&gt;Language Model Interpolation
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;n 元语法插值法：加权融合不同阶数 n 元语法的概率&lt;/strong&gt;，避免高阶的n元语法零概率导致的预测失效。&lt;/p&gt;
&lt;p&gt;加权的$\lambda$应该设置成多少呢？可以从预留集held-out corpus中学习。使用EM（期望最大化）算法来学习。&lt;/p&gt;
&lt;h4 id=&#34;stupid-backoff&#34;&gt;Stupid Backoff
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;回退模型&lt;/strong&gt;：高阶n阶的模型无法使用的时候，回退到低阶模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discount&lt;/strong&gt;：要让回退模型（backoff model）输出合理的概率分布，我们必须对高阶 n 元语法的概率进行 “折扣处理”（discount），从而预留出部分概率余量（probability mass），供低阶 n 元语法使用。但在实际应用中，人们常使用一种更简单的 “无折扣回退算法”—— 即名为&lt;strong&gt;Stupid Backoff&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;advanced-perplexitys-relation-to-entropy&#34;&gt;Advanced: Perplexity&amp;rsquo;s Relation to Entropy
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;熵&lt;/strong&gt;：不确定性的度量方式。可以理解是编码某个决策或某条信息所需的最小平均比特数。越不确定，熵越大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;熵率&lt;/strong&gt;：平均的不确定性。自然语言的熵率定义为 “&lt;strong&gt;无限长序列中，每个词的平均熵&lt;/strong&gt;”，反映语言的长期不确定性。例如，英文的熵率约 1-2 比特 / 词，意味着平均每个词需要 1-2 比特来编码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;平稳性&lt;/strong&gt;：序列概率不随着时间改变。自然语言不是，但是N元语法是平稳的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;遍历性&lt;/strong&gt;：长序列中包含了所有的短序列。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shannon-McMillan-Breiman theorem&lt;/strong&gt;：如果语言满足某些正则条件（准确地说，是平稳且遍历的），&lt;strong&gt;序列长度趋近于无穷大时，“序列的平均对数概率的负值” ，即经验熵率会以概率1收敛敛到该过程的理论熵率&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交叉熵（Cross-Entropy）&lt;/strong&gt;：我们虽然不知道数据的真实概率分布p，但是可以用模型m来近似p。（即我们虽然不知道自然语言的真实情况，但是可以用N元语法来近似。）&lt;strong&gt;交叉熵越小，模型越接近真实分布&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;困惑度&lt;/strong&gt;：&lt;strong&gt;困惑度是熵的指数形式&lt;/strong&gt;。比较直观。&lt;/p&gt;
&lt;h3 id=&#34;excercies&#34;&gt;Excercies
&lt;/h3&gt;&lt;details&gt;
    &lt;summary&gt;点击展开&lt;/summary&gt;
    &lt;h5 id=&#34;31&#34;&gt;3.1
&lt;/h5&gt;&lt;p&gt;Write out the equation for trigram probability estimation (modifying Eq. 3.11). Now write out all the non-zero trigram probabilities for the I am Sam corpus on page 40.&lt;/p&gt;
&lt;h5 id=&#34;32&#34;&gt;3.2
&lt;/h5&gt;&lt;p&gt;Calculate the probability of the sentence &lt;code&gt;i want chinese food&lt;/code&gt;. Give two probabilities, one using Fig. 3.2 and the ‘useful probabilities’ just below it on page 42, and another using the add-1 smoothed table in Fig. 3.7. Assume the additional add-1 smoothed probabilities $P(i|&amp;lt;s&amp;gt;) = 0.19$ and $P(&amp;lt;/s&amp;gt;|food) = 0.40$.&lt;/p&gt;
&lt;h5 id=&#34;33&#34;&gt;3.3
&lt;/h5&gt;&lt;p&gt;Which of the two probabilities you computed in the previous exercise is higher, unsmoothed or smoothed? Explain why.&lt;/p&gt;
&lt;h5 id=&#34;34&#34;&gt;3.4
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using a bigram language model with add-one smoothing, what is $P(Sam | am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;35&#34;&gt;3.5
&lt;/h5&gt;&lt;p&gt;Suppose we didn’t use the end-symbol $&amp;lt;/s&amp;gt;$. Train an unsmoothed bigram grammar on the following training corpus without using the end-symbol $&amp;lt;/s&amp;gt;$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b a  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a a
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Demonstrate that your bigram model does not assign a single probability distribution across all sentence lengths by showing that the sum of the probability of the four possible 2 word sentences over the alphabet a,b is 1.0, and the sum of the probability of all possible 3 word sentences over the alphabet a,b is also 1.0.&lt;/p&gt;
&lt;h5 id=&#34;36&#34;&gt;3.6
&lt;/h5&gt;&lt;p&gt;Suppose we train a trigram language model with add-one smoothing on a given corpus. The corpus contains V word types. Express a formula for estimating $P(w3|w1,w2)$, where $w3$ is a word which follows the bigram$ (w1,w2)$, in terms of various n-gram counts and V. Use the notation $c(w1,w2,w3)$ to denote the number of times that trigram $(w1,w2,w3)$ occurs in the corpus, and so on for bigrams and unigrams.&lt;/p&gt;
&lt;h5 id=&#34;37&#34;&gt;3.7
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we use linear interpolation smoothing between a maximum-likelihood bigram model and a maximum-likelihood unigram model with $λ₁ = 1/2$ and $λ₂ = 1/2,$ what is $P(Sam|am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;38&#34;&gt;3.8
&lt;/h5&gt;&lt;p&gt;Write a program to compute unsmoothed unigrams and bigrams.&lt;/p&gt;
&lt;h5 id=&#34;39&#34;&gt;3.9
&lt;/h5&gt;&lt;p&gt;Run your n-gram program on two different small corpora of your choice (you might use email text or newsgroups). Now compare the statistics of the two corpora. What are the differences in the most common unigrams between the two? How about interesting differences in bigrams?&lt;/p&gt;
&lt;h5 id=&#34;310&#34;&gt;3.10
&lt;/h5&gt;&lt;p&gt;Add an option to your program to generate random sentences.&lt;/p&gt;
&lt;h5 id=&#34;311&#34;&gt;3.11
&lt;/h5&gt;&lt;p&gt;Add an option to your program to compute the perplexity of a test set.&lt;/p&gt;
&lt;h5 id=&#34;312&#34;&gt;3.12
&lt;/h5&gt;&lt;p&gt;You are given a training set of 100 numbers that consists of 91 zeros and 1 each of the other digits 1-9. Now we see the following test set: 0 0 0 0 0 3 0 0 0 0. What is the unigram perplexity?&lt;/p&gt;

&lt;/details&gt;

&lt;h2 id=&#34;logistic-regression-and-text-classification&#34;&gt;Logistic Regression and Text Classification
&lt;/h2&gt;&lt;p&gt;经典任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sentiment analysis&lt;/li&gt;
&lt;li&gt;spam detection&lt;/li&gt;
&lt;li&gt;language id&lt;/li&gt;
&lt;li&gt;authorship attribution&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;machine-learning-and-classification&#34;&gt;Machine Learning and Classification
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;人工规则很脆弱，数据一变化就无法使用&lt;/li&gt;
&lt;li&gt;LLM的弱点：幻觉、无法解释。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此最常见的分类方法是&lt;strong&gt;有监督机器学习&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;概率分类器：输出&lt;strong&gt;样本属于每个类别的概率&lt;/strong&gt;而不是类别标签，保证在合并的系统里不过早地输出结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分类器的核心组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A feature representation of the input&lt;/li&gt;
&lt;li&gt;A classificaition function that computes $\hat{y}$&lt;/li&gt;
&lt;li&gt;An objective funcion that we want to potimize for learning
&lt;ul&gt;
&lt;li&gt;loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An algorithm for optimizing the objective function
&lt;ul&gt;
&lt;li&gt;stochastic gradient descent algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-sigmoid-function&#34;&gt;The Sigmoid Function
&lt;/h3&gt;&lt;p&gt;二分类逻辑回归的目标是：计算样本属于正类的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一步：计算线性得分$z=w⋅x+b$，值域为$[-\infty, +\infty ]$&lt;/li&gt;
&lt;li&gt;第二步：&lt;strong&gt;通过 Sigmoid 函数转换为概率&lt;/strong&gt;：  将线性得分 z 映射到 $[0,1] $区间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$z$常常被称作Logit（对数几率）。Logit就是Sigmoid的反函数。可以提醒我们后续要加上Sigmoid进行转换，因为$z$并不是一个真实的值。&lt;/p&gt;
&lt;p&gt;特别地，&lt;strong&gt;“正类的对数几率” 与特征呈线性关系&lt;/strong&gt;。也就是当其他条件不变时，特征$x_1$每增加1，Logit就增加$w_1$。这非常有可解释性。&lt;/p&gt;
&lt;h3 id=&#34;classification-with-logistic-regression&#34;&gt;Classification with Logistic Regression
&lt;/h3&gt;&lt;p&gt;当概率大于0.5的时候，就把它分类到正类里。&lt;/p&gt;
&lt;h4 id=&#34;sentiment-classification&#34;&gt;Sentiment Classification
&lt;/h4&gt;&lt;p&gt;举了一个例子。&lt;/p&gt;
&lt;h4 id=&#34;other-classification-tasks-and-features&#34;&gt;Other Classification Tasks and Features
&lt;/h4&gt;&lt;p&gt;Period disambiguation：确定句号是EOS还是其他。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Designing v.s. Learning features：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;刚刚的例子，特征都是人工设计的。此外还有：
&lt;ul&gt;
&lt;li&gt;feaure interactions：基础特征组合成的复杂特征&lt;/li&gt;
&lt;li&gt;feature templates：抽象的特征规范来定义特征。这里的特征空间是稀疏的，此外特征一般是字符串描述的Hash值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;人工设计太复杂了。因此现代的NLP系统都是用Representation Learning来解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;standardize和normalize。&lt;/p&gt;
&lt;h4 id=&#34;processing-many-examples-at-once&#34;&gt;Processing many examples at once
&lt;/h4&gt;&lt;p&gt;如果有许多的值要计算，可以使用matrix arithmetic来一次计算完。&lt;/p&gt;
&lt;h3 id=&#34;multinomial-logistic-regression&#34;&gt;Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;多项逻辑回归也称softmax regression，老的教材上也叫maxent clasifier。&lt;/p&gt;
&lt;p&gt;在多项逻辑回归中，直接输出结果而不是一个概率值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hard classification&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;softmax&#34;&gt;Softmax
&lt;/h4&gt;&lt;p&gt;Sigmoid函数在多分类情况下的推广。&lt;/p&gt;
&lt;h4 id=&#34;applying-softmax-in-logistic-regression&#34;&gt;Applying Softmax in Logistic Regression
&lt;/h4&gt;&lt;p&gt;可以使用矩阵运算方式加快计算。&lt;/p&gt;
$$\hat{y}=softmax(Wx+b)$$&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2506.11035&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Doumbouya et al., 2025&lt;/a&gt;是这么认为的：逻辑回归将矩阵的每一行 $w_k$视为&lt;strong&gt;第 $k$ 类的原型（prototype）&lt;/strong&gt;，由于两个向量的相似度越高，它们的点积（dot product）值就越大，因此点积可作为衡量向量相似度的函数。模型最终将输入分配给相似度最高的类别。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;features-in-multinomial-logistic-regression&#34;&gt;Features in Multinomial Logistic Regression
&lt;/h4&gt;&lt;p&gt;特征权重同时依赖于输入文本和输出类别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597.png&#34;
	width=&#34;744&#34;
	height=&#34;837&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_dcd37b06fe097e65.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_87f8d0d9a05a6baf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;213px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;learning-in-logistic-regression&#34;&gt;Learning in Logistic Regression
&lt;/h3&gt;&lt;p&gt;逻辑回归是如何实现学习的？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使system output（classifier output）和gold output（correct output）越接近越好。两者之间的距离可以称作&lt;strong&gt;损失函数&lt;/strong&gt;或者&lt;strong&gt;代价函数&lt;/strong&gt;。下面介绍交叉熵。&lt;/li&gt;
&lt;li&gt;需要一个算法来最小化损失函数。下面介绍随机梯度下降算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-cross-entropy-loss-function&#34;&gt;The Cross-entropy Loss Function
&lt;/h3&gt;&lt;p&gt;条件最大似然估计：在给定$x$下，选择参数$w$和$b$使得$y$的对数概率最大。&lt;/p&gt;
&lt;p&gt;这里损失函数是&lt;strong&gt;负对数似然损失（negative log likelihood loss）&lt;/strong&gt;，通常也被称为&lt;strong&gt;交叉熵损失（cross-entropy loss）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;介绍了一下为什么&lt;strong&gt;最小化交叉熵损失可以使得真实分布和预测分布更加接近&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent
&lt;/h3&gt;&lt;p&gt;梯度下降算法的原理。介绍了梯度、学习率。&lt;/p&gt;
&lt;h4 id=&#34;the-gradient-for-logistic-regression&#34;&gt;The Gradient for Logistic Regression
&lt;/h4&gt;&lt;p&gt;逻辑回归的梯度就是
&lt;/p&gt;
$$\frac{\partial L_{\mathrm{CE}}(\hat{y},y)}{\partial w_{j}}=-(y-\hat{y})x_{j}$$&lt;p&gt;
也就是预测值$\hat{y}$和实际值$y$之间的差乘输入值$x_j$。&lt;/p&gt;
&lt;h4 id=&#34;the-stochastic-gradient-descent-algorithm&#34;&gt;The Stochastic Gradient Descent Algorithm
&lt;/h4&gt;&lt;p&gt;随机梯度下降算法是一种在线算法，可以边接收数据边学习。&lt;/p&gt;
&lt;p&gt;SGD每次用&lt;strong&gt;单个随机样本&lt;/strong&gt;计算梯度。&lt;/p&gt;
&lt;h4 id=&#34;mini-batch-training&#34;&gt;Mini-batch Training
&lt;/h4&gt;&lt;p&gt;batch training和mini-batch training的区别。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch gradient：所有的随机样本计算梯度。&lt;/li&gt;
&lt;li&gt;mini-batch gradient：小批量梯度下降算法。每次选择&lt;strong&gt;一小批随机样本&lt;/strong&gt;计算梯度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learning-in-multinomial-logistic-regression&#34;&gt;Learning in Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;多项式逻辑回归其实和二项式逻辑回归差不多。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本质是使用独热标签+概率向量的形式进行计算。&lt;/li&gt;
&lt;li&gt;核心是 “对正确类别的预测概率取负对数”，得到交叉熵损失，其越小则预测概率越高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-precision-recall-f-measure&#34;&gt;Evaluation: Precision, Recall, F-measure
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;confusion matrix&lt;/li&gt;
&lt;li&gt;accuracy&lt;/li&gt;
&lt;li&gt;precision&lt;/li&gt;
&lt;li&gt;recall&lt;/li&gt;
&lt;li&gt;F-measure
&lt;ul&gt;
&lt;li&gt;F1&lt;/li&gt;
&lt;li&gt;a weighted harmonic mean of precision and recall.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893.png&#34;
	width=&#34;928&#34;
	height=&#34;394&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_5b835770261a7097.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_9163edd8010643ed.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;microaveraging v.s. macroaveraging&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微观平均：更关注 “整体样本的预测准确性”，&lt;strong&gt;少数类错判代价低于多数类&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;宏观平均：更关注所有的类的错判代价的公平，&lt;strong&gt;少数类和多数类的代价相等&lt;/strong&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005.png&#34;
	width=&#34;1084&#34;
	height=&#34;468&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_bca6ffdfb72f8971.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_899e55b55133737a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;555px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;test-sets-and-cross-validation&#34;&gt;Test sets and Cross-validation
&lt;/h3&gt;&lt;p&gt;Cross-validation：解决测试集不足的问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;固定训练集和测试集。&lt;/li&gt;
&lt;li&gt;训练集中进行分割。
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382.png&#34;
	width=&#34;895&#34;
	height=&#34;462&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_4558bdf3b4166cbe.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_e53d98bd5ba967c8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;statistical-significance-testing&#34;&gt;Statistical Significance Testing
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;统计显著性检验&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不只是简单地检查A在测试集上的结果$M(A,x)$好于B在测试集上的结果$M(B,x)$。如果差很小的话，其实不一定能证明A的结果比B小，不具有统计学上的显著性。&lt;/li&gt;
&lt;li&gt;设计一个效应量$\delta (x)=M(A,x)-M(B,x)$，原假设是$H_0 :\delta (x)\leq 0$。这样计算p值是否小于阈值可以得出是否显著性地A比B要好。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在NLP中，一般不用ANOVAs或者t检验，而是使用非参数检验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;近似随机化检验&lt;/strong&gt;（Approximate Randomization Test）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bootstrap 检验&lt;/strong&gt;（Bootstrap Test）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;方差分析和t检验都需要有假设：方差齐性或数据服从正态分布。所以只能用非参数检验。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;the-paired-bootstrap-test&#34;&gt;The Paired Bootstrap Test
&lt;/h4&gt;&lt;p&gt;Bootstrap 检验的核心是 “重抽样”—— 从原始测试集&lt;code&gt;x&lt;/code&gt;中&lt;strong&gt;有放回地随机抽取&lt;/strong&gt;生成新的测试集。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970.png&#34;
	width=&#34;1097&#34;
	height=&#34;490&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_8f406568f15b6414.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_c48413deb765f0e1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;
在新的测试集上，P 值等于 “重抽样测试集中，$d(x^{(i)})≥2d(x)$的数量占总重抽样次数b的比例”。&lt;strong&gt;判断此时的p值是否低于阈值就可以判断出是否是数据集本身的偏差导致了A比B要结果好。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LLM的解释：Bootstrap 重抽样，就是在 “不改变天平初始倾斜（测试集偏向）” 的前提下，反复放 “随机重量（重抽样的样本）”，看左边会比右边多低多少格 —— 如果只是天平本身歪了，随机放重量时，左边最多低 2 格左右（常规波动）；如果左边真的更重，就可能低 4 格以上（极端情况）。这种极端情况多了，超过了阈值，我们就更相信是天平本身的问题。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;avoiding-harms-in-classification&#34;&gt;Avoiding Harms in Classification
&lt;/h3&gt;&lt;p&gt;representational harms：由于对特定社会群体的贬低或刻板印象导致的伤害。&lt;/p&gt;
&lt;p&gt;toxic detection&lt;/p&gt;
&lt;p&gt;model card&lt;/p&gt;
&lt;h3 id=&#34;interpereting-models&#34;&gt;Interpereting Models
&lt;/h3&gt;&lt;p&gt;模型的可解释性也是很重要的。逻辑回归就是比较好的可解释的模型。&lt;/p&gt;
&lt;h3 id=&#34;advanced-regularization&#34;&gt;Advanced: Regularization
&lt;/h3&gt;&lt;p&gt;regularization来解决过拟合的问题，提高模型泛化能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2 regulaization&lt;/li&gt;
&lt;li&gt;L1 regulaization&lt;/li&gt;
&lt;li&gt;lasso&lt;/li&gt;
&lt;li&gt;ridge&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;embeddings&#34;&gt;Embeddings
&lt;/h2&gt;&lt;p&gt;分布假说：相似的上下文总会表现出相似的意思。&lt;/p&gt;
&lt;p&gt;Embeddings分类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;static embeddings&lt;/li&gt;
&lt;li&gt;contextualized embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;学习embeddings和它的意义的理论称为向量语义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自监督模型&lt;/li&gt;
&lt;li&gt;representation learning的一种&lt;/li&gt;
&lt;li&gt;无需通过特征工程的人工制造representations&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lexical-semantics&#34;&gt;Lexical Semantics
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;lemma：citation form，词元，引用形式，一个词的基本形式。&lt;/li&gt;
&lt;li&gt;wordform：词形，一个词的具体使用形态。&lt;/li&gt;
&lt;li&gt;word sense：词义。&lt;/li&gt;
&lt;li&gt;synonymy：同义关系。&lt;/li&gt;
&lt;li&gt;word similarity：词语相似度。
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1408.3456&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SimLex-999&lt;/a&gt;中就让人们给一个词和另一个词的相似度打分。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;word relatedness/association：词汇关联性，所有能让词汇有关联感的关系。
&lt;ul&gt;
&lt;li&gt;semantic fields&lt;/li&gt;
&lt;li&gt;topic models：特别地有Latent Dirichlet Allocation，LDA&lt;/li&gt;
&lt;li&gt;最常见的关系
&lt;ul&gt;
&lt;li&gt;hypernymy or IS-A&lt;/li&gt;
&lt;li&gt;antonymy&lt;/li&gt;
&lt;li&gt;mernoymy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;connotation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vector-semantics-the-intuition&#34;&gt;Vector Semantics: The Intuition
&lt;/h3&gt;&lt;p&gt;一个单词可以表示为&lt;strong&gt;多维语义空间中的一个点&lt;/strong&gt;。而这个多维语义空间是从单词邻居的分布规律中推导而来的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf-idf&lt;/li&gt;
&lt;li&gt;word2vec&lt;/li&gt;
&lt;li&gt;cosine&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;simple-count-based-embeddings&#34;&gt;Simple Count-based Embeddings
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;词汇表一般在1-5万之间&lt;/li&gt;
&lt;li&gt;稀疏向量表示：多数数值为0，目前有有效算法来有效存储和计算&lt;/li&gt;
&lt;li&gt;权重函数
&lt;ul&gt;
&lt;li&gt;计数的时候可以用权重函数&lt;/li&gt;
&lt;li&gt;目前最流行的方法是tf-idf&lt;/li&gt;
&lt;li&gt;还有一些历史权重方式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cosine-for-measuring-similarity&#34;&gt;Cosine for Measuring Similarity
&lt;/h4&gt;&lt;p&gt;使用余弦计算相似度。适用于稀疏长向量。&lt;/p&gt;
&lt;h4 id=&#34;word2vec&#34;&gt;Word2vec
&lt;/h4&gt;&lt;p&gt;embeddings要区别于原来的稀疏长向量，通常指短而稠密的向量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习的权重变少，学习更快&lt;/li&gt;
&lt;li&gt;有助于泛化和避免过拟合&lt;/li&gt;
&lt;li&gt;能够更好捕捉同义性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;skip-gram with negative sampling（SGNS）是word2vec两种方法的一种。word2vec是一种&lt;strong&gt;静态embedding&lt;/strong&gt;方法，区别于动态embedding，如BERT表示。&lt;/p&gt;
&lt;p&gt;这里有一个极具创新性的想法 ——&lt;strong&gt;不直接计算 “词与词的关联”（共现矩阵），而是通过一个 “预测任务” 让模型自动学习这种关联，再将学习成果（权重）作为词嵌入&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这被称为&lt;strong&gt;自监督方法&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Skip-gram 模型的核心思路如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将目标词与其相邻的语境词视为&lt;strong&gt;正例&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;从词汇表中随机选取其他词语，作为&lt;strong&gt;负例&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;利用&lt;strong&gt;逻辑回归训练一个分类器，使其能够区分上述两种情况&lt;/strong&gt;（即区分 “目标词与语境词是相邻关系” 和 “目标词与随机词无相邻关系”）。&lt;/li&gt;
&lt;li&gt;将训练过程中学到的权重作为embedding。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;the-classifier&#34;&gt;The Classifier
&lt;/h5&gt;&lt;p&gt;Skip-gram目标是训练一个分类器，计算这个地方填这个词的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心思路&lt;/strong&gt;：一个词是否可能出现在目标词附近，取决于它的嵌入向量与目标词的嵌入向量是否相似。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;相似度计算&lt;/strong&gt;：点积&lt;/li&gt;
&lt;li&gt;点积结果并非概率值，还需要经过Sigmoid函数运算‘&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Skip-gram模型其实是存储了每个单词的两个embeddings，一个作为目标词，一个作为上下文。分别从target matrix W和context matrix C矩阵中学习。&lt;/p&gt;
&lt;h4 id=&#34;learning-skip-gram-embeddings&#34;&gt;Learning Skip-gram Embeddings
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;positive examples&lt;/strong&gt;：上下文滑动窗口&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;negative examples&lt;/strong&gt;：词汇表中随机抽取，一般是positive examples的k倍，由目标词$w$和噪声词组成。&lt;/p&gt;
&lt;p&gt;在抽样的时候，会设置一个权重系数$\alpha =0.75$来调整概率$P(w)$避免总是选择高频词。&lt;/p&gt;
&lt;p&gt;学习目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最大化positive examples中学习的相似度&lt;/li&gt;
&lt;li&gt;最小化negative examples中的相似度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831142750258.png&#34;
	width=&#34;880&#34;
	height=&#34;558&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831142750258_hu_b96cde190aab3329.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831142750258_hu_1050abc09f7158b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;378px&#34;
	
&gt;
如图，目标是使得apricot和jam的点积更大，和matrix、Tolstoy的点积更小。&lt;/p&gt;
&lt;p&gt;在学习完了之后，一般只使用W来表示。&lt;/p&gt;
&lt;h4 id=&#34;other-kinds-of-static-embeddings&#34;&gt;Other kinds of static embeddings
&lt;/h4&gt;&lt;p&gt;fasttext&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决了word2vec的未知词问题&lt;/li&gt;
&lt;li&gt;subword models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GloVe&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Global Vectors&lt;/li&gt;
&lt;li&gt;基于词词共现矩阵的概率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;word2vec可以看成&lt;strong&gt;间接优化一个 “带PPMI（Positive Pointwise Mutual Information）权重的共现矩阵” 的函数&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我的一些想法：GNN是否也可以做类似的工作？GNN目前的方法就是直接处理图结构，进行局部图结构学习。不专门训练一个模型进行预测，而是把这个训练的模型的参数直接作为一个向量使用，反而能够更好地捕捉到隐含关系。&lt;/p&gt;
&lt;p&gt;这种想法是否可以将LLM和GNN更好地连接起来？&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;visualizing-embeddings&#34;&gt;Visualizing Embeddings
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;直接列出最相似的单词&lt;/li&gt;
&lt;li&gt;聚类算法&lt;/li&gt;
&lt;li&gt;t-SNE：让低维空间中 “点与点的相似概率”，尽量和高维空间中 “点与点的相似概率” 一致&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;semantic-properites-of-embeddings&#34;&gt;Semantic Properites of Embeddings
&lt;/h3&gt;&lt;p&gt;关联和相似的区别：越短的上下文得到的向量，相似越好找，关联越难；越长正好相反。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一阶共现：组合关系，一起组合出现，如write和poem&lt;/li&gt;
&lt;li&gt;二阶共享：聚合关系，直接相关，如write和say&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;类比关系：平行四边形模型
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150132974.png&#34;
	width=&#34;1134&#34;
	height=&#34;469&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150132974_hu_363723ff4c0d8ebb.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150132974_hu_327a3c1c3636cedb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;241&#34;
		data-flex-basis=&#34;580px&#34;
	
&gt;
问题是只能用在明确的关系、短的距离和频繁的单词上。&lt;/p&gt;
&lt;h4 id=&#34;embeddings-and-historical-semantics&#34;&gt;Embeddings and Historical Semantics
&lt;/h4&gt;&lt;p&gt;嵌入的应用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150603967.png&#34;
	width=&#34;839&#34;
	height=&#34;505&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150603967_hu_baa0cb87e66ee17e.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250831150603967_hu_76e49fbca324cd4d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;398px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;很有意思。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gay：愉悦的-&amp;gt;明亮的-&amp;gt;男同性恋&lt;/li&gt;
&lt;li&gt;broadcast：散播-&amp;gt;报纸-&amp;gt;BBC&lt;/li&gt;
&lt;li&gt;awful：庄严的-&amp;gt;可怕的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bias-and-embeddings&#34;&gt;Bias and Embeddings
&lt;/h3&gt;&lt;p&gt;allocational harm&lt;/p&gt;
&lt;p&gt;embedding不仅反映输入，还放大偏见。&lt;/p&gt;
&lt;h3 id=&#34;evaluating-vector-models&#34;&gt;Evaluating Vector Models
&lt;/h3&gt;&lt;p&gt;相似度度量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不含上下文
&lt;ul&gt;
&lt;li&gt;WordSim-353&lt;/li&gt;
&lt;li&gt;SimLex-999&lt;/li&gt;
&lt;li&gt;TOEFL dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;含上下文
&lt;ul&gt;
&lt;li&gt;SCWS&lt;/li&gt;
&lt;li&gt;WiC&lt;/li&gt;
&lt;li&gt;semantic textual similarity task&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;类比度量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SemEval-2012 Task 2 dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有的Embedding算法都会存在固有的变异性。建议使用bootstrap采样后的文档中训练多个embeddings并平均。&lt;/p&gt;
&lt;h2 id=&#34;neural-networks&#34;&gt;Neural Networks
&lt;/h2&gt;&lt;p&gt;McCulloch-Pitts neuron&lt;/p&gt;
&lt;p&gt;feedforward&lt;/p&gt;
&lt;p&gt;deep learning&lt;/p&gt;
&lt;h3 id=&#34;units&#34;&gt;Units
&lt;/h3&gt;&lt;p&gt;bias term&lt;/p&gt;
&lt;p&gt;activation：使用non-linear functions，如sigmoid、tanh、ReLU等&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901195216978.png&#34;
	width=&#34;833&#34;
	height=&#34;422&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901195216978_hu_e98d5b59e57b93ca.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901195216978_hu_75d0b4b410c52d3a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;473px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sigmoid和tanh的问题：特别容易出现饱和的现象，如当特别靠近1的时候，此时的导数接近于0，输入的微小改变将无法引起输出的任何变化。这种现象称为&lt;strong&gt;梯度消失&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-xor-problem&#34;&gt;The XOR Problem
&lt;/h3&gt;&lt;p&gt;Minsky and Papert：一层神经元无法解决异或问题。如感知机。&lt;/p&gt;
&lt;h4 id=&#34;the-solution-neural-networks&#34;&gt;The Solution: Neural Networks
&lt;/h4&gt;&lt;p&gt;包含隐藏层的多层感知机MLP解决了这个问题。&lt;/p&gt;
&lt;p&gt;下面这个图，不管对于原来的[0,1]还是[1,0]都会将他们在隐含层里转化为[1,0]。而原来的[0,0]和[1,1]则变为[2,1]，此时便线性可分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901200315265.png&#34;
	width=&#34;762&#34;
	height=&#34;337&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901200315265_hu_820ad2365c82284f.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901200315265_hu_8ed92ef255ef500a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;226&#34;
		data-flex-basis=&#34;542px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901201345068.png&#34;
	width=&#34;686&#34;
	height=&#34;446&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901201345068_hu_a56fa62e2362e855.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250901201345068_hu_c12f6c72632725f1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;153&#34;
		data-flex-basis=&#34;369px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;feedforward-neural-networks&#34;&gt;Feedforward Neural Networks
&lt;/h3&gt;&lt;p&gt;与RNN对应，前馈神经网络（FNN）不带有循环。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于历史原因，FNN也称为多层感知机，MLPs，事实上现在的多层网络中已经不是感知机了。&lt;/li&gt;
&lt;li&gt;感知机使用阶跃函数，现在的神经网络用的是多种非线性的单元如ReLUs或者Sigmoid等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前馈神经网络的标准结构是全连接的。
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902182112223.png&#34;
	width=&#34;726&#34;
	height=&#34;429&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902182112223_hu_28bfdb5ad0f61a8a.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902182112223_hu_d4c96ab1783e2a89.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;406px&#34;
	
&gt;
在这里，W作为输入层到隐含层的权重矩阵，U则是隐含层到输出层的权重矩阵。
&lt;/p&gt;
$$h=\sigma(Wx+b)$$&lt;p&gt;
&lt;/p&gt;
$$z=Uh$$&lt;p&gt;
在得到输出结果$z$之后，由于$z$是一个实数值向量（其实就是logits），而分类需要的是概率分布向量，所以要对其进行归一化（normalizing）。这里使用的是softmax函数。
&lt;/p&gt;
$$y = \text{softmax}(z)$$&lt;p&gt;神经网络和多项逻辑回归的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有许多层&lt;/li&gt;
&lt;li&gt;中间层的激活函数不只使用sigmoid&lt;/li&gt;
&lt;li&gt;特征可以不只是由人工的特征模板设计，而可以由网络自身得到&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;逻辑回归可以理解成一层的神经网络。&lt;/p&gt;
&lt;h4 id=&#34;more-details-on-feedforward-networks&#34;&gt;More Details on Feedforward Networks
&lt;/h4&gt;&lt;p&gt;为什么激活函数要非线性&lt;/p&gt;
&lt;p&gt;替换偏置项：使用dummy node来代替原来的偏置项。也就是下图中把b换成一个新的固定为1的$x_0$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185044344.png&#34;
	width=&#34;692&#34;
	height=&#34;372&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185044344_hu_22233632699e1e11.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185044344_hu_f917792a9f3a40e1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;feedforward-networks-for-nlp-classification&#34;&gt;Feedforward Networks for NLP: Classification
&lt;/h3&gt;&lt;p&gt;嵌入矩阵、表示池化、表示学习先不讲，先学一下用前馈神经网络解决分类问题。&lt;/p&gt;
&lt;h4 id=&#34;neural-net-classifiers-with-hand-built-features&#34;&gt;Neural Net Classifiers with Hand-built Features
&lt;/h4&gt;&lt;p&gt;人工设计的特征，除了把MLP换成FNN之外没变化。
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185551826.png&#34;
	width=&#34;688&#34;
	height=&#34;399&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185551826_hu_e7290fd892ec1524.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902185551826_hu_7954655261211383.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;vectorizing-for-parallelizing-inference&#34;&gt;Vectorizing for Parallelizing Inference
&lt;/h4&gt;&lt;p&gt;单个样本特征维度是d，有m个样本，就可以将输入写成一个矩阵X为m×d维。&lt;/p&gt;
&lt;p&gt;其他的偏置项等也可以写成矩阵的形式，有助于最后的运算。此时有
&lt;/p&gt;
$$H=\sigma(XW^T+\textbf{b})$$$$Z=HU^T$$$$\hat{Y}=\text{softmax}(Z)$$&lt;blockquote&gt;
&lt;p&gt;这里的X中行向量表示一个样本的完整特征。有的时候会写成$WX+b$，有的时候是$XW+b$。注意X的形状有所不同。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;embeddings-as-the-input-to-neural-net-classifiers&#34;&gt;Embeddings as the Input to Neural Net Classifiers
&lt;/h3&gt;&lt;p&gt;static embeddings代替hand-designed features。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存储static embeddings的词典称为embedding matrix &lt;strong&gt;E&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;one-hot vector：从embedding matrix选取token embedding的方法
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192356608.png&#34;
	width=&#34;688&#34;
	height=&#34;215&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192356608_hu_35c57fe6c6d3b00d.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192356608_hu_c416dc54a98e3898.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;320&#34;
		data-flex-basis=&#34;768px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;分类器：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;concatenation：适合对token顺序和细节敏感的任务，如语言建模&lt;/li&gt;
&lt;li&gt;pooling：适合对整体语义敏感的任务，如情感分析
&lt;ul&gt;
&lt;li&gt;mean-pooling&lt;/li&gt;
&lt;li&gt;max-pooling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192912076.png&#34;
	width=&#34;807&#34;
	height=&#34;712&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192912076_hu_e6ec73621f005a0d.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902192912076_hu_c30b59ad826afcc3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;前馈神经网络用于情感分析，带有池化层的结构&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;272px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;神经语言模型和N元语法模型的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以处理更多的上下文，更加泛化，预测更准确；速度更慢，训练更麻烦&lt;/li&gt;
&lt;li&gt;使用embeddings表示词而不是word identity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902193413335.png&#34;
	width=&#34;717&#34;
	height=&#34;645&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902193413335_hu_aab9c40f89390eef.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902193413335_hu_98641d26ebbce7c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;embedding layer e这里是拼接起来的&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;111&#34;
		data-flex-basis=&#34;266px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;training-neural-nets&#34;&gt;Training Neural Nets
&lt;/h3&gt;&lt;p&gt;损失函数、交叉熵&lt;/p&gt;
&lt;p&gt;误差反向传播/反向微分&lt;/p&gt;
&lt;h4 id=&#34;loss-function&#34;&gt;Loss Function
&lt;/h4&gt;&lt;p&gt;交叉熵损失函数：负对数似然损失。用于&lt;strong&gt;输出为 “类别概率” 的任务&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;computing-the-gradient&#34;&gt;Computing the Gradient
&lt;/h4&gt;&lt;p&gt;一层的时候可以用损失的导数，但是多层的时候需要用反向传播算法。&lt;/p&gt;
&lt;h4 id=&#34;computation-graphs&#34;&gt;Computation Graphs
&lt;/h4&gt;&lt;p&gt;介绍了什么是计算图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902201310848.png&#34;
	width=&#34;697&#34;
	height=&#34;263&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902201310848_hu_9525e3130f2a9740.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902201310848_hu_d15c38716a3d7624.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;265&#34;
		data-flex-basis=&#34;636px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;backward-differentiation-on-computation-graphs&#34;&gt;Backward Differentiation on Computation Graphs
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;反向传播&lt;/strong&gt;：用链式法则一次性计算出所有参数的梯度。
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213405406.png&#34;
	width=&#34;829&#34;
	height=&#34;432&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213405406_hu_aea55f690f9591d7.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213405406_hu_e6e577c00244a646.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;460px&#34;
	
&gt;
先正向传播一次，然后反向传播计算。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正向传播是为了得到损失值&lt;/li&gt;
&lt;li&gt;反向传播是为了得到梯度，从而进行参数优化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然在真正的神经网络中，计算会更加复杂。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213726628.png&#34;
	width=&#34;851&#34;
	height=&#34;528&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213726628_hu_86b4e3d87a5a98fe.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250902213726628_hu_508ea0186fde9736.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;386px&#34;
	
&gt;
但是方法万变不离其宗。&lt;/p&gt;
&lt;h4 id=&#34;more-details-on-learning&#34;&gt;More Details on Learning
&lt;/h4&gt;&lt;p&gt;神经网络优化问题是一个非凸优化问题。目前有了很多好的正则化方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始值不设为0，而是随机的一些小的数&lt;/li&gt;
&lt;li&gt;dropout&lt;/li&gt;
&lt;li&gt;超参数：Adam等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GPUs等计算加速&lt;/p&gt;
&lt;h2 id=&#34;large-language-models&#34;&gt;Large Language Models
&lt;/h2&gt;&lt;p&gt;ELIZA&lt;/p&gt;
&lt;p&gt;Distributional hypothesis&lt;/p&gt;
&lt;p&gt;Pretraining&lt;/p&gt;
&lt;p&gt;语言模型：依据前文预测下一个词的分布&lt;/p&gt;
&lt;p&gt;发展：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N元语法&lt;/li&gt;
&lt;li&gt;LSA/LSI，隐含语义分析，开始用向量表示词&lt;/li&gt;
&lt;li&gt;神经网络语言模型neural language model&lt;/li&gt;
&lt;li&gt;RNN语言模型&lt;/li&gt;
&lt;li&gt;word2vec&lt;/li&gt;
&lt;li&gt;预训练技术&lt;/li&gt;
&lt;li&gt;Transformer提出&lt;/li&gt;
&lt;li&gt;掩码语言模型&lt;/li&gt;
&lt;li&gt;自回归语言模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221442377.png&#34;
	width=&#34;817&#34;
	height=&#34;367&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221442377_hu_625cc627b168f68a.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221442377_hu_9ee53070fd85a32c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;534px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如果可以预测下一个词的概率分布，那么就可以从概率分布中进行采样，从而生成下一个词。这样就从预测模型变成了生成模型。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221449983.png&#34;
	width=&#34;800&#34;
	height=&#34;551&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221449983_hu_3354a2ee29195159.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221449983_hu_38463e6c14e8a47d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因果语言模型/自回归语言模型：从左到右依次生成&lt;/li&gt;
&lt;li&gt;掩码语言模型：BERT等，可以同时利用左右两侧的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生成式AI&lt;/p&gt;
&lt;h3 id=&#34;three-architecture-for-language-models&#34;&gt;Three Architecture for Language Models
&lt;/h3&gt;&lt;p&gt;三种结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221500783.png&#34;
	width=&#34;842&#34;
	height=&#34;383&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221500783_hu_5e7d45143603e021.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903221500783_hu_756c75157cc64aa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;527px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;decoder：上文中的架构。输入为一系列的token，&lt;strong&gt;依次迭代&lt;/strong&gt;生成输出的token。用于自回归语言模型。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成文本等，如GPT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;encoder：用于掩码语言模型。输入为文本，输出为标签。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分类文本等，如BERT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;encoder-decoder：输入为一串token，输出也是一串token。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;相比decoder来说，和输入输出token的关系更不紧密，这类模型用于在不同类型的标记之间进行映射&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;机器翻译等&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;他们都是基于神经网络构建的。&lt;/p&gt;
&lt;h3 id=&#34;conditional-generation-of-text-the-intuition&#34;&gt;Conditional Generation of Text: The Intuition
&lt;/h3&gt;&lt;p&gt;不管什么任务，都可以简化为给定prompt的下一个词的预测任务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222035606.png&#34;
	width=&#34;813&#34;
	height=&#34;346&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222035606_hu_b84c5560c85d0ad0.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222035606_hu_e5d863ff7f7b20c8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;563px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;prompting&#34;&gt;Prompting
&lt;/h3&gt;&lt;p&gt;指令微调&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222047947.png&#34;
	width=&#34;815&#34;
	height=&#34;386&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222047947_hu_6ad9dfc9690a84c8.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222047947_hu_8595ec17a22bd37b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;506px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;prompt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Demonstrations&lt;/li&gt;
&lt;li&gt;Few-shot prompting&lt;/li&gt;
&lt;li&gt;Zero-shot prompting&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;这种Demonstrations可以手动筛选，也可以由优化器如DSPy来自动选择。此外，Demonstrations似乎并不是一定要给正确的问题和答案，错误的也行，主要作用是格式。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;prompt：可以看做一个学习信号。&lt;strong&gt;提示词不会更新模型的权重，其改变的仅仅是模型的上下文信息以及网络中的激活状态。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in-context learning：参数没有改变的学习&lt;/li&gt;
&lt;li&gt;System prompt：影响全局的一个文本prompt，被添加到所有用户prompt或查询的前面&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generation-and-sampling&#34;&gt;Generation and Sampling
&lt;/h3&gt;&lt;p&gt;语言模型的内部网络会生成logits，再由softmax计算得到概率，随后在这些token中进行采样。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222105152.png&#34;
	width=&#34;812&#34;
	height=&#34;329&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222105152_hu_16ad1c8697e23a8f.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222105152_hu_fff46d8496576fff.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;decoding：基于概率选择token生成的过程常称为decoding&lt;/p&gt;
&lt;p&gt;自回归生成
D&lt;/p&gt;
&lt;h4 id=&#34;greedy-decoding&#34;&gt;Greedy decoding
&lt;/h4&gt;&lt;p&gt;贪心解码：选择概率最高的那个token生成（argmax）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222114008.png&#34;
	width=&#34;830&#34;
	height=&#34;334&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222114008_hu_98ac761f730aacb7.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222114008_hu_49ef26f8c34a2658.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;248&#34;
		data-flex-basis=&#34;596px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;效果不好——输入文本如果相同，结果是固定的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;束搜索&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;random-sampling&#34;&gt;Random Sampling
&lt;/h4&gt;&lt;p&gt;按照分布采样，直到采样到EOS。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222124629.png&#34;
	width=&#34;811&#34;
	height=&#34;326&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222124629_hu_11963dc8db1e3582.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222124629_hu_4629a2f05c285dce.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;248&#34;
		data-flex-basis=&#34;597px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;效果也不好——有些token虽然占比小，但是这些token很多，导致占比也不小。如果被采样到了，句子会变得很奇怪&lt;/p&gt;
&lt;h4 id=&#34;temperature-sampling&#34;&gt;Temperature Sampling
&lt;/h4&gt;&lt;p&gt;logits转化为probability的时候用带有temperature的softmax计算。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222132977.png&#34;
	width=&#34;958&#34;
	height=&#34;388&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222132977_hu_3596e2556cd62f8b.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222132977_hu_41d0f2085c2134bd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;当$\tau \le 1$的时候，会倾向将高概率拉得更高，低概率拉得更低，反之则更容易选择到低概率事件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222140906.png&#34;
	width=&#34;799&#34;
	height=&#34;603&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222140906_hu_bf742fb76c7ff9ec.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222140906_hu_bfff8415c93c103b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;132&#34;
		data-flex-basis=&#34;318px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;training-large-language-models&#34;&gt;Training Large Language Models
&lt;/h3&gt;&lt;p&gt;一般分为三个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预训练&lt;/li&gt;
&lt;li&gt;指令微调&lt;/li&gt;
&lt;li&gt;偏好对齐&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222151929.png&#34;
	width=&#34;800&#34;
	height=&#34;514&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222151929_hu_25e107b931e1b56a.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222151929_hu_bf627f72fb75e27d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;373px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;self-supervised-training-algorithm-for-pretraining&#34;&gt;Self-supervised Training Algorithm for Pretraining
&lt;/h4&gt;&lt;p&gt;Teacher forcing：永远给模型正确的序列，而不是按照模型的预测接着往下来预测下一个词&lt;/p&gt;
&lt;p&gt;如下图，网络中的权重会通过梯度下降进行调整，以最小化该批次上的平均交叉熵损失。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222201965.png&#34;
	width=&#34;808&#34;
	height=&#34;469&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222201965_hu_571b6370d9971e97.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903222201965_hu_b722f8598f57cfd6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这些权重包括嵌入矩阵 E。由此学习到的嵌入，将能最有效地预测后续词语。&lt;/p&gt;
&lt;h4 id=&#34;pretraining-corpora-for-large-language-models&#34;&gt;Pretraining Corpora for Large Language Models
&lt;/h4&gt;&lt;p&gt;训练数据可以用网络数据，并且加上一些精心筛选的数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;common crawl&lt;/li&gt;
&lt;li&gt;Colossal CLean Crawled Corpus&lt;/li&gt;
&lt;li&gt;The Pile&lt;/li&gt;
&lt;li&gt;Dolma&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;避免个人信息PII，去重，安全筛选，toxicity detection。注意版权、数据同意、隐私和偏差等问题。&lt;/p&gt;
&lt;h4 id=&#34;finetuning&#34;&gt;Finetuning
&lt;/h4&gt;&lt;p&gt;对已经与训练过的模型加入一些新的知识进行微调。如果新的数据是预训练的后面，也可以叫continued pretraining。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903194702282.png&#34;
	width=&#34;704&#34;
	height=&#34;363&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903194702282_hu_ef5bfaca2f0c0697.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903194702282_hu_5326aa4cc5696be2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;465px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluating-large-language-models&#34;&gt;Evaluating Large Language Models
&lt;/h3&gt;&lt;h4 id=&#34;perplexity&#34;&gt;Perplexity
&lt;/h4&gt;&lt;p&gt;由于链式法则，使用&lt;strong&gt;对数似然&lt;/strong&gt;来作为衡量语言模型性能的指标的话，测试集的概率大小会受到token数量的影响。文本越长，测试集的概率越小。&lt;/p&gt;
&lt;p&gt;Perplexity：困惑度，长度归一化的指标。困惑度的具体公式是测试集概率的倒数，再按标记数量进行归一化。
&lt;/p&gt;
$$\begin{aligned}
\text{Perplexity}_{\boldsymbol{\theta}}(w_{1:n}) &amp; =P_{\boldsymbol{\theta}}(w_{1:n})^{-\frac{1}{n}} \\
 &amp; =\sqrt[n]{\frac{1}{P_{\boldsymbol{\theta}}(w_{1:n})}}
\end{aligned}$$&lt;p&gt;
&lt;strong&gt;困惑度越低，模型越好。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;困惑度非常依赖tokens的数量，因此不能对两个使用不同tokenizer的模型进行比较，而是只能对使用同一个tokenizer的模型比较。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;downstream-tasks-reasoniong-and-world-knowledge&#34;&gt;Downstream Tasks: Reasoniong and World Knowledge
&lt;/h4&gt;&lt;p&gt;准确率：可以直接使用下游任务来衡量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MMLU
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214854478.png&#34;
	width=&#34;805&#34;
	height=&#34;289&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214854478_hu_f3db381a926f2221.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214854478_hu_7d93c033b6db94ba.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;278&#34;
		data-flex-basis=&#34;668px&#34;
	
&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214915252.png&#34;
	width=&#34;806&#34;
	height=&#34;475&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214915252_hu_101f6843eda66160.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250903214915252_hu_d2314743aaea0c7f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;一个2-shot prompt的MMLU高中数学题&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是问题是&lt;strong&gt;数据泄露&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;other-factors-for-evaluating-language-models&#34;&gt;Other Factors for Evaluating Language Models
&lt;/h4&gt;&lt;p&gt;模型大小，训练时间，推理时间，GPU数量&lt;/p&gt;
&lt;p&gt;公平&lt;/p&gt;
&lt;p&gt;leaderboards&lt;/p&gt;
&lt;h3 id=&#34;ethical-and-safety-issues-with-language-models&#34;&gt;Ethical and Safety Issues with Language Models
&lt;/h3&gt;&lt;p&gt;大模型幻觉问题：RAG&lt;/p&gt;
&lt;p&gt;安全问题：安全微调和对齐&lt;/p&gt;
&lt;p&gt;representational harms&lt;/p&gt;
&lt;p&gt;隐私问题&lt;/p&gt;
&lt;p&gt;情感依赖&lt;/p&gt;
&lt;p&gt;增长谎言、宣传、虚假信息等文本生成&lt;/p&gt;
</description>
        </item>
        <item>
        <title>学习笔记 | LangChain学习笔记</title>
        <link>https://ionfeather.github.io/2024/langchain-learning/</link>
        <pubDate>Tue, 26 Nov 2024 13:45:58 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2024/langchain-learning/</guid>
        <description>&lt;img src="https://ionfeather.github.io/2024/langchain-learning/cover.png" alt="Featured image of post 学习笔记 | LangChain学习笔记" /&gt;&lt;h2 id=&#34;为什么要学习langchain&#34;&gt;为什么要学习LangChain
&lt;/h2&gt;&lt;p&gt;我希望能够构建一个能阅读PDF论文的Agent，并且能够输出对论文优缺点的评价。&lt;/p&gt;

&lt;div class=&#34;chat --other&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34;&gt;导师&amp;nbsp;&amp;nbsp;&amp;nbsp;2024-10-12 14:30&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
做一个论文阅读的大模型。  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;


&lt;div class=&#34;chat --self&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34; style=&#34;text-align: right;&#34;&gt;2024-10-12 14:45&amp;nbsp;&amp;nbsp;&amp;nbsp;我&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
好的老师。  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;

&lt;p&gt;使用LangChain听说比较方便。&lt;/p&gt;
&lt;h2 id=&#34;langchain是用来做什么的&#34;&gt;LangChain是用来做什么的？
&lt;/h2&gt;&lt;p&gt;LangChain是一个用于开发由LLM驱动的应用程序的框架。也就是说我们可以把LLM作为内核，LangChain作为外壳，搭建一个程序出来。&lt;/p&gt;
&lt;p&gt;LangChain提供了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;组件：处理LLM的组件的抽象；&lt;/li&gt;
&lt;li&gt;定制链：把组件拼起来，实现一个特定用例。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于阅读PDF，目前有两个想法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将PDF转为JSON，然后输入到LLM中；&lt;/li&gt;
&lt;li&gt;构建RAG。使用LangChain能够比较方便地实现这个功能，听ZLB说这个也不是很难。我之前的畏难情绪可能太重了，现在写一个文档，激励和记录一下自己学习。&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
    &lt;summary&gt;RAG是什么？&lt;/summary&gt;
    &lt;p&gt;虽然LLM非常强大，但它们对于它们未经训练的信息一无所知。如果您想使用LLM来回答它未经训练的文档相关问题，您需要向其提供这些文档的信息。最常用的方法是通过“检索增强生成”（ retrieval augmented generation，RAG ）。&lt;/p&gt;
&lt;p&gt;检索增强生成的思想是，在给定一个问题时，首先进行检索步骤以获取任何相关文档。然后将这些文档与原始问题一起传递给语言模型，并让它生成一个回答。然而，为了做到这一点，首先需要将文档以适合进行此类查询的格式呈现。&lt;/p&gt;

&lt;/details&gt;

&lt;h2 id=&#34;构造一个语义搜索引擎&#34;&gt;构造一个语义搜索引擎
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/tutorials/retrievers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Build a semantic search engine | 🦜️🔗 LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;读取pdf&#34;&gt;读取PDF
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to load PDFs | 🦜️🔗 LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这里，文档中推荐使用了pypdf库。这里&lt;/p&gt;
&lt;p&gt;在实际应用中可以使用其他提取效果更好的库。LangChain支持的PDF格式很多，可以选择一下。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Document Loader&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
          &lt;th&gt;Package/API&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfloader&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses &lt;code&gt;pypdf&lt;/code&gt; to load and parse PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/unstructured_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Unstructured&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses Unstructured&amp;rsquo;s open source library to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/amazon_textract&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazon Textract&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses AWS API to load PDFs&lt;/td&gt;
          &lt;td&gt;API&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/mathpix&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MathPix&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses MathPix to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfplumber&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFPlumber&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFPlumber&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfdirectory&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFDirectry&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load a directory with PDF files&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfium2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFium2&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyPDFium2&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pymupdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyMuPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyMuPDF&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfminer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFMiner&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFMiner&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;此外，导师之前还给我推荐了&lt;a class=&#34;link&#34; href=&#34;https://github.com/titipata/scipdf_parser&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;titipata/scipdf_parser&lt;/a&gt;库，能够更好地处理图像和扫描文本，并且运行在docker上，便于部署。&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;pypdf的介绍&lt;/summary&gt;
    &lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pypdf.readthedocs.io/en/stable/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Welcome to pypdf — pypdf 5.1.0 documentation&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;PyPDF 是一个用于处理 PDF 文件的 Python库。它提供了一组工具和功能，用于读取、解析和操作 PDF 文件的内容。&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&#34;splitting&#34;&gt;Splitting
&lt;/h3&gt;&lt;details&gt;
    &lt;summary&gt;原文&lt;/summary&gt;
    &lt;p&gt;For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve &lt;code&gt;Document&lt;/code&gt; objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not &amp;ldquo;washed out&amp;rdquo; by surrounding text.&lt;/p&gt;
&lt;p&gt;We can use &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/concepts/text_splitters/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;text splitters&lt;/a&gt; for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/recursive_text_splitter/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RecursiveCharacterTextSplitter&lt;/a&gt;, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.&lt;/p&gt;
&lt;p&gt;We set &lt;code&gt;add_start_index=True&lt;/code&gt; so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”.&lt;/p&gt;
&lt;p&gt;See &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this guide&lt;/a&gt; for more detail about working with PDFs, including how to extract text from specific sections and images.&lt;/p&gt;

&lt;/details&gt;

&lt;p&gt;对于问题提问的文本来说，直接回答一整页肯定是太粗略了。我们最终的目标是检索回答输入查询的文档对象，进一步拆分 PDF 将有助于确保文档相关部分的含义不会被周围的文本“冲淡”。&lt;/p&gt;
&lt;p&gt;所以接下来应该用文本分割器来进行分割（Splitting）处理。这里用一个&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;进行分割。这里使用常见分隔符来对文档进行分割，适用于一般的文本。&lt;/p&gt;

&lt;div class=&#34;notice notice-warning&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 576 512&#34; fill=&#34;#704343&#34;&gt;&lt;path d=&#34;M570 440c18 32-5 72-42 72H48c-37 0-60-40-42-72L246 24c19-32 65-32 84 0l240 416zm-282-86a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;使用&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;无法读取图像或特定区域的文本。&lt;/p&gt;&lt;/div&gt;

&lt;h3 id=&#34;embeddings&#34;&gt;Embeddings
&lt;/h3&gt;&lt;p&gt;接下来将文本嵌入到向量中去，便于进行相似度指标来识别相关文本。&lt;/p&gt;
&lt;p&gt;这里LangChain支持数十种Embeddings方法。这里我选择了使用Hugging Face，可以选择将模型下载至本地或者使用&lt;code&gt;Hugging Face Inference API&lt;/code&gt;来调用接口。这里可以直接使用&lt;code&gt;HuggingFaceEmbeddings&lt;/code&gt;来进行处理。非常方便。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_huggingface&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sentence-transformers/all-mpnet-base-v2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Generated vectors of length &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;vector-stores&#34;&gt;Vector Stores
&lt;/h3&gt;&lt;p&gt;LangChain的Vector Stores对象包括了一些把文本和Document对象加入到Stores中的方法，然后通过相似性进行一个排列。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.vectorstores&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_documents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;documents&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;此时就完成了存储和排列。&lt;/p&gt;
&lt;p&gt;这里向量存储一般来说是可以连接到现有的Vector Stores中的。&lt;/p&gt;
&lt;h3 id=&#34;usage&#34;&gt;Usage
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;查询和这句话相似的句子&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Diffusion is a image generation method.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;异步查询（用于流程控制）&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asimilarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;返回分数&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Note that providers implement different scores; &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# the score here is a distance metric that varies inversely with similarity.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_with_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is Diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Score: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;通过和embedded query的相似度进行查询&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_by_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;retrievers&#34;&gt;Retrievers
&lt;/h3&gt;&lt;p&gt;检索器（Retriever）可以从向量存储中进行构建，但是也可以和非向量形式进行交互。如果我们要构建一个能够检索文档的方法的话，我们可以创建一个runnable的检索器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;typing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.documents&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.runnables&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is forward process?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;至此，我们构建了一个能够读多篇PDF文章的、能够对PDF文章进行查询的语义搜索引擎。&lt;/p&gt;
&lt;h2 id=&#34;chat-models和prompt模板&#34;&gt;Chat Models和Prompt模板
&lt;/h2&gt;&lt;p&gt;这里通过Vllm启动LLM，以Qwen2.5-7B-Instruct模型为例。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_community.llms&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/home/ubuntu/jjq/Qwen/Qwen2.5-7B-Instruct/&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;trust_remote_code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_new_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_model_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is the capital of France ?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来设计Prompt模板。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LLMChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.memory&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.chains&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts.chat&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ChatPromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SystemMessagePromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HumanMessagePromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;template&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        【任务描述】
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        请仔细阅读论文，回答用户给出的问题，尽量具有批判性。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        【论文】
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        {{context}}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        -----------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{question}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 检索器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;as_retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 记忆&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;chat_history&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 构建Agent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;question&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;能不能用中文给出论文的优势或者前景？&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
