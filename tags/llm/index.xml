<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>LLM on ionfeather&#39;Log</title>
        <link>https://ionfeather.github.io/tags/llm/</link>
        <description>Recent content in LLM on ionfeather&#39;Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>ionfeather&#39;Log</copyright>
        <lastBuildDate>Thu, 28 Aug 2025 19:28:49 +0800</lastBuildDate><atom:link href="https://ionfeather.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ä¹¦ç±é˜…è¯» | Speech and Language Processing</title>
        <link>https://ionfeather.github.io/2025/speech-and-language-processing/</link>
        <pubDate>Thu, 28 Aug 2025 19:28:49 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/speech-and-language-processing/</guid>
        <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;é˜…è¯»&lt;a class=&#34;link&#34; href=&#34;https://web.stanford.edu/~jurafsky/slp3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Speech and Language Processing&lt;/a&gt;è¿™æœ¬ä¹¦çš„ä¸€äº›ç¬”è®°ï¼Œä»¥ä¾›åæ¥çš„è‡ªå·±å‚è€ƒã€‚&lt;/p&gt;
&lt;h2 id=&#34;words-and-tokens&#34;&gt;Words and Tokens
&lt;/h2&gt;&lt;p&gt;æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸œè¥¿æ¥å»ºæ¨¡è¯­è¨€ï¼Œä¸‹é¢æ˜¯æˆ‘ä»¬çš„é€‰æ‹©ï¼š&lt;/p&gt;
&lt;h3 id=&#34;words&#34;&gt;Words
&lt;/h3&gt;&lt;p&gt;ä¸ºä»€ä¹ˆä¸ç”¨è¯ï¼Ÿ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æœ‰äº›è¯­è¨€æ²¡æœ‰orthographic words&lt;/li&gt;
&lt;li&gt;è¯çš„æ•°é‡ä¼šéšç€æ–‡ç« å¢é•¿ï¼Œè¯æ±‡è¡¨æ°¸è¿œéƒ½ä¼šè¦†ç›–ä¸è¶³&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;morphemes&#34;&gt;Morphemes
&lt;/h3&gt;&lt;p&gt;è¯­ç´ ç±»å‹&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å±ˆæŠ˜è¯­ç´ ï¼šinflectional morphemes&lt;/li&gt;
&lt;li&gt;æ´¾ç”Ÿè¯­ç´ ï¼šderivational morphemes&lt;/li&gt;
&lt;li&gt;é™„ç€è¯­ç´ ï¼šclitic&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¯­è¨€ç±»å‹&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analytic&lt;/li&gt;
&lt;li&gt;polysynthetic&lt;/li&gt;
&lt;li&gt;fusional&lt;/li&gt;
&lt;li&gt;agglutinative&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸ºä»€ä¹ˆä¸ç”¨è¯­ç´ ï¼Ÿ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¯­ç´ å¾ˆå¤æ‚ï¼Œå¾ˆéš¾å®šä¹‰&lt;/li&gt;
&lt;li&gt;ä¸åŒè¯­è¨€ä¸åŒä¸”éš¾ä»¥ç»Ÿä¸€&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unicode&#34;&gt;Unicode
&lt;/h3&gt;&lt;p&gt;Unicodeçš„å†å²&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ASCII&lt;/li&gt;
&lt;li&gt;CJKV&lt;/li&gt;
&lt;li&gt;ä¸æ–­æ›´æ–°ä¸­ï¼Œè¶Šæ¥è¶Šå¤šï¼ŒUnicode 16.0å·²ç»åŒ…å«è¶…è¿‡150000ä¸ªå­—ç¬¦&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;code-points&#34;&gt;Code Points
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;U+ï¼šè¡¨ç¤ºæ¥ä¸‹æ¥è¦ç”¨Unicodeåå…­è¿›åˆ¶è¡¨ç¤ºä¸€ä¸ªcode point&lt;/li&gt;
&lt;li&gt;U+0061ï¼š0x0061ä¸€ä¸ªæ„æ€ï¼Œä¹Ÿå°±å°å†™å­—æ¯aã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;utf-8&#34;&gt;UTF-8
&lt;/h4&gt;&lt;p&gt;ç›®å‰æœ€å¸¸ç”¨çš„encodingå­—ç¬¦çš„æ–¹å¼ã€‚ä¸­æ–‡å­—ç¬¦ â€œä¸­â€ çš„ Unicode ç ç‚¹æ˜¯&lt;code&gt;U+4E2D&lt;/code&gt;ï¼ŒUTF-8 ç¼–ç åä¸º 3 ä¸ªå­—èŠ‚ï¼š&lt;code&gt;0xE4 0xB8 0xAD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;UTF-8æ˜¯ä¸€ç§å˜é•¿ç¼–ç ï¼Œå…¼å®¹ASCIIã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¦‚ã€Œä¸–ã€ï¼ŒUTF-8 ç¼–ç æ˜¯&lt;code&gt;0xE4 B8 96&lt;/code&gt;ï¼Œå…¶ä¸­E4çš„äºŒè¿›åˆ¶ä¸º&lt;code&gt;11100110H&lt;/code&gt;ï¼Œå¼€å¤´çš„&lt;code&gt;1110H&lt;/code&gt;è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ª3å­—èŠ‚å­—ç¬¦çš„ç¬¬ä¸€ä¸ªå­—èŠ‚ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subword-tokenization-byte-pair-encoding&#34;&gt;Subword Tokenization: Byte-Pair Encoding
&lt;/h3&gt;&lt;p&gt;ä¸Šé¢çš„ä¸‰ä¸ªå€™é€‰éƒ½ä¸è¡Œï¼Œwordå’Œmorphemeéš¾ä»¥è§„èŒƒå®šä¹‰ï¼Œcharacterå¯ä»¥é€šè¿‡unicodeæ¥å®šä¹‰ï¼Œä½†åˆå¯¹äºä½œä¸ºtokensæ¥è¯´å¤ªå°äº†ã€‚&lt;/p&gt;
&lt;p&gt;ä¸ºä»€ä¹ˆè¦tokenizeè¾“å…¥ï¼Ÿ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å°†è¾“å…¥è½¬æ¢ä¸ºä¸€ç»„ç¡®å®šçš„ã€å›ºå®šçš„å•å…ƒï¼ˆTokenï¼‰ï¼Œèƒ½è®©ä¸åŒçš„ç®—æ³•å’Œç³»ç»Ÿåœ¨ä¸€äº›ç®€å•é—®é¢˜ä¸Šè¾¾æˆå…±è¯†ã€‚ä¾‹å¦‚å›°æƒ‘åº¦çš„è®¡ç®—ã€‚&lt;/li&gt;
&lt;li&gt;å¯¹å¯å¤ç°å¾ˆé‡è¦&lt;/li&gt;
&lt;li&gt;ä¸ºäº†æ¶ˆé™¤unknown wordsçš„é—®é¢˜&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸ºäº†æ¶ˆé™¤unknown wordsé—®é¢˜ï¼Œç°ä»£tokenizersè‡ªåŠ¨å¼•å…¥äº†tokenåŒ…å«é‚£äº›æ¯”wordså°çš„tokenï¼Œå«subwordã€‚&lt;/p&gt;
&lt;p&gt;ä½¿ç”¨&lt;a class=&#34;link&#34; href=&#34;https://platform.openai.com/tokenizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tokenizer - OpenAI API&lt;/a&gt;ä¸­çš„&lt;code&gt;GPT-4o &amp;amp;  GPT-4o mini&lt;/code&gt;æ¥åˆ†è¯ä¸‹é¢è¿™ä¸€å¤§æ®µè¯ï¼š&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, if we had happened not to ever see the word lower, when it appears we could segment it successfully into low and er which we had already seen. In the worst case, a really unusual word (perhaps an acronym like GRPO) could be tokenized as a sequence of individual letters if necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;æœ€ç»ˆå¾—åˆ°çš„æ˜¯
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982.png&#34;
	width=&#34;711&#34;
	height=&#34;279&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_b760c9dcae731844.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_3812253da13ed9c0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;611px&#34;
	
&gt;
ç°åœ¨æœ€æµè¡Œçš„tokenization algorithmæœ‰ä¸¤ä¸ªï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Byte-Pair Encoding(BPE)&lt;/li&gt;
&lt;li&gt;Unigram Language modeling(ULM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;bpe&#34;&gt;BPE
&lt;/h4&gt;&lt;p&gt;é€šè¿‡åˆ†æè®­ç»ƒè¯­æ–™ï¼Œè‡ªåŠ¨å­¦ä¹ å‡ºä¸€å¥—å­è¯é›†åˆï¼ˆè¯æ±‡è¡¨ï¼‰ï¼Œä½¿å¾—é«˜é¢‘å‡ºç°çš„å­—ç¬¦ / å­è¯ç»„åˆè¢«åˆå¹¶ä¸ºæ›´å¤§çš„å­è¯å•ä½ã€‚&lt;/p&gt;
&lt;p&gt;è®­ç»ƒæ–¹æ³•ä»‹ç»ã€‚&lt;/p&gt;
&lt;h4 id=&#34;bpe-encoder&#34;&gt;BPE encoder
&lt;/h4&gt;&lt;h4 id=&#34;bpe-in-practice&#34;&gt;BPE in practice
&lt;/h4&gt;&lt;p&gt;é€šå¸¸ï¼Œæˆ‘ä»¬ä¼šå¯¹ UTF-8 ç¼–ç æ–‡æœ¬çš„&lt;strong&gt;å•ä¸ªå­—èŠ‚&lt;/strong&gt;æ‰§è¡Œ BPE æ“ä½œã€‚BPE å¤„ç† â€œä¸­â€ æ—¶ï¼Œè¾“å…¥å¹¶é&lt;code&gt;U+4E2D&lt;/code&gt;è¿™ä¸ªç ç‚¹ï¼Œè€Œæ˜¯&lt;code&gt;E4&lt;/code&gt;ã€&lt;code&gt;B8&lt;/code&gt;ã€&lt;code&gt;AD&lt;/code&gt;è¿™ä¸‰ä¸ªç‹¬ç«‹å­—èŠ‚ã€‚&lt;/p&gt;
&lt;p&gt;ä»…åœ¨&lt;strong&gt;é¢„å…ˆåˆ‡åˆ†å‡ºçš„å•è¯å†…éƒ¨&lt;/strong&gt;æ‰§è¡Œ BPE æ“ä½œï¼Œæœ‰åŠ©äºé¿å…æ½œåœ¨é—®é¢˜ã€‚&lt;/p&gt;
&lt;p&gt;ä¸€äº›è‹±è¯­é‡Œçš„å°å‘ç°ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¤§å¤šæ•°å•è¯çš„tokensæ˜¯ä»–ä»¬è‡ªå·±ï¼ŒåŒ…å«è¯å‰ç©ºæ ¼ã€‚è¿™æ ·å¯ä»¥é¿å…ç‹¬ç«‹å•è¯å’Œå•è¯å†…éƒ¨çš„subwordã€‚&lt;/li&gt;
&lt;li&gt;é™„ç€è¯­ç´ Cliticsåœ¨åå­—åé¢åˆ†å¼€å•ç‹¬æˆtokenï¼Œä½†åœ¨å¸¸è§çš„è¯è¯­åé¢ä¼šæ˜¯tokençš„ä¸€éƒ¨åˆ†&lt;/li&gt;
&lt;li&gt;æ•°å­—é€šå¸¸ä¸‰ä½ä¸€ç»„&lt;/li&gt;
&lt;li&gt;ä¸€äº›è¯ï¼Œå¦‚Anyhowå’Œanyhowä¼šæœ‰ä¸åŒçš„åˆ†å‰²æ–¹æ³•&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ä¸ªå’Œé¢„å¤„ç†æœ‰å…³ç³»ã€‚&lt;/p&gt;
&lt;p&gt;SuperBPEä¼šåˆå¹¶å¸¸è§„çš„BPEå­è¯åˆ†è¯ï¼Œæ•ˆç‡æ›´é«˜ã€‚&lt;/p&gt;
&lt;p&gt;ç‰¹åˆ«åœ°ï¼Œä½èµ„æºè¯­è¨€çš„tokensæ›´ç¢ï¼Œå°±ä¼šè¾“å‡ºè¾¹é•¿ï¼Œæœ€ç»ˆLLMçš„æ•ˆç‡å˜ä½ã€‚&lt;/p&gt;
&lt;h3 id=&#34;rule-based-tokenization&#34;&gt;Rule-based tokenization
&lt;/h3&gt;&lt;p&gt;Penn Treebank Tokenization Standardï¼‰ï¼šäº‹å®æ€§è§„èŒƒã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åˆ†å¼€é™„ç€è¯­ç´ &lt;/li&gt;
&lt;li&gt;ä¿ç•™è¿å­—ç¬¦è¿æ¥çš„è¯&lt;/li&gt;
&lt;li&gt;åˆ†å¼€æ‰€æœ‰çš„æ ‡ç‚¹ç¬¦å·&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sentence-segmentation&#34;&gt;Sentence Segmentation
&lt;/h4&gt;&lt;p&gt;sentence tokenizationå¯ä»¥å’Œword tokenizationè”åˆå¤„ç†ã€‚&lt;/p&gt;
&lt;h3 id=&#34;corpora&#34;&gt;Corpora
&lt;/h3&gt;&lt;p&gt;è¯­æ–™åº“å’Œè¯­è¨€æ•°é‡ã€ä½¿ç”¨è€…çš„ç‰¹å¾éƒ½æœ‰å…³ã€‚&lt;/p&gt;
&lt;p&gt;code switchingï¼šåœ¨ä¸€æ¬¡æŒç»­çš„äº¤æµï¼‰ä¸­ï¼Œè¯´è¯è€…æˆ–ä½œè€…äº¤æ›¿ä½¿ç”¨ä¸¤ç§æˆ–å¤šç§ â€œè¯­ç â€çš„ç°è±¡ã€‚&lt;/p&gt;
&lt;p&gt;datasheetï¼šå­˜å‚¨ä¸€å¥è¯çš„ç‰¹å¾ï¼Œå¦‚æ—¶é—´ã€è¯´è¯äººæ€§æ ¼ã€é˜¶çº§&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;regular-expressions&#34;&gt;Regular Expressions
&lt;/h3&gt;&lt;p&gt;æ­£åˆ™è¡¨è¾¾å¼çš„å…·ä½“å®ç°ã€‚åŒ…å«å­—ç¬¦æå–ã€è®¡æ•°ã€å¯é€‰æ€§ã€é€šé…ç¬¦ã€é”šç‚¹å’Œè¾¹ç•Œã€æ›¿æ¢å’Œæ•è·ç»„ã€å‰å‘æ–­è¨€ç­‰ã€‚&lt;/p&gt;
&lt;h3 id=&#34;simple-unix-tools-for-word-tokenization&#34;&gt;Simple Unix Tools for Word Tokenization
&lt;/h3&gt;&lt;p&gt;å¯ä»¥åœ¨Unixã€Linuxç³»ç»Ÿä¸­ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ã€‚å¦‚&lt;code&gt;tr -sc &#39;A-Za-z&#39; &#39;\n&#39; &amp;lt; sh.txt&lt;/code&gt;è¡¨ç¤ºä»Â &lt;code&gt;sh.txt&lt;/code&gt;Â æ–‡ä»¶ä¸­æå–æ‰€æœ‰è‹±æ–‡å­—æ¯ï¼Œå¹¶å°†éå­—æ¯å­—ç¬¦æ›¿æ¢ä¸ºæ¢è¡Œç¬¦ï¼ŒåŒæ—¶å‹ç¼©è¿ç»­çš„éå­—æ¯å­—ç¬¦ä¸ºå•ä¸ªæ¢è¡Œç¬¦ã€‚&lt;/p&gt;
&lt;h3 id=&#34;minimum-edit-distance&#34;&gt;Minimum Edit Distance
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;æœ€å°ç¼–è¾‘è·ç¦»&lt;/strong&gt;ï¼šå°†ä¸€ä¸ªå­—ç¬¦ä¸²é€šè¿‡ â€œæ’å…¥â€â€œåˆ é™¤â€â€œæ›¿æ¢â€ ä¸‰ç§åŸºæœ¬æ“ä½œè½¬æ¢ä¸ºå¦ä¸€ä¸ªå­—ç¬¦ä¸²æ‰€éœ€çš„æœ€å°‘æ“ä½œæ¬¡æ•°&lt;/p&gt;
&lt;h4 id=&#34;the-minimum-edit-distance-algorithm&#34;&gt;The Minimum Edit Distance Algorithm
&lt;/h4&gt;&lt;p&gt;ä¸€ä¸ªç»å…¸çš„åŠ¨æ€è§„åˆ’é—®é¢˜ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å­—ç¬¦å¯¹é½&lt;/strong&gt;ï¼šé€šè¿‡å›æº¯ç¼–è¾‘è·ç¦»çŸ©é˜µä¸­çš„ â€œæœ€ä¼˜è·¯å¾„â€ï¼Œåå‘æ¨å¯¼å‡ºå°†ä¸€ä¸ªå­—ç¬¦ä¸²è½¬æ¢ä¸ºå¦ä¸€ä¸ªå­—ç¬¦ä¸²çš„å…·ä½“æ“ä½œåºåˆ—ã€‚ä¹Ÿå°±æ˜¯&lt;strong&gt;è·¯å¾„å¯è§†åŒ–&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id=&#34;exercies&#34;&gt;Exercies
&lt;/h3&gt;&lt;h5 id=&#34;21&#34;&gt;2.1
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all alphabetic strings.&lt;/li&gt;
&lt;li&gt;The set of all lowercase alphabetic strings ending in &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The set of all strings from the alphabet {a, b} such that each &amp;ldquo;a&amp;rdquo; is immediately preceded by and immediately followed by a &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;22&#34;&gt;2.2
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages. By &amp;ldquo;word&amp;rdquo;, we mean an alphabetic string separated from other words by whitespace, relevant punctuation, line breaks, etc.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all strings with two consecutive repeated words (e.g., &amp;ldquo;Humbert Humbert&amp;rdquo; and &amp;ldquo;the the&amp;rdquo; but not &amp;ldquo;the bug&amp;rdquo; or &amp;ldquo;the big bug&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;All strings that start at the beginning of the line with an integer and end at the end of the line with a word.&lt;/li&gt;
&lt;li&gt;All strings that have both the word &amp;ldquo;grotto&amp;rdquo; and the word &amp;ldquo;raven&amp;rdquo; in them (but not, e.g., words like &amp;ldquo;grottos&amp;rdquo; that merely contain &amp;ldquo;grotto&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Write a pattern that places the first word of an English sentence in a register. Deal with punctuation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;23&#34;&gt;2.3
&lt;/h5&gt;&lt;p&gt;Implement an ELIZA-like program, using substitutions such as those described on page 27. You might want to choose a different domain than a Rogerian psychologist, although keep in mind that you would need a domain in which your program can legitimately engage in a lot of simple repetition.&lt;/p&gt;
&lt;h5 id=&#34;24&#34;&gt;2.4
&lt;/h5&gt;&lt;p&gt;Compute the edit distance (using insertion cost 1, deletion cost 1, substitution cost 1) of &amp;ldquo;leda&amp;rdquo; to &amp;ldquo;deal&amp;rdquo;. Show your work (using the edit distance grid).&lt;/p&gt;
&lt;h5 id=&#34;25&#34;&gt;2.5
&lt;/h5&gt;&lt;p&gt;Figure out whether &amp;ldquo;drive&amp;rdquo; is closer to &amp;ldquo;brief&amp;rdquo; or to &amp;ldquo;divers&amp;rdquo; and what the edit distance is to each. You may use any version of distance that you like.&lt;/p&gt;
&lt;h5 id=&#34;26&#34;&gt;2.6
&lt;/h5&gt;&lt;p&gt;Now implement a minimum edit distance algorithm and use your hand-computed results to check your code.&lt;/p&gt;
&lt;h5 id=&#34;27&#34;&gt;2.7
&lt;/h5&gt;&lt;p&gt;Augment the minimum edit distance algorithm to output an alignment; you will need to store pointers and add a stage to compute the backtrace.&lt;/p&gt;
&lt;h2 id=&#34;n-gram-language-models&#34;&gt;N-gram Language Models
&lt;/h2&gt;&lt;p&gt;æœ¬ç« ä»‹ç»æœ€ç®€å•çš„è¯­è¨€æ¨¡å‹ï¼š&lt;strong&gt;Nå…ƒè¯­æ³•è¯­è¨€æ¨¡å‹&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id=&#34;n-grams&#34;&gt;N-Grams
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;æ¦‚ç‡é“¾å¼æ³•åˆ™&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;how-to-estimate-probabilities&#34;&gt;How to estimate probabilities
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;é©¬å°”ç§‘å¤«å‡è®¾&lt;/strong&gt;ï¼šå‡è®¾ä¸€ä¸ªå•è¯çš„å‡ºç°æ¦‚ç‡åªå’Œå‰é¢çš„ä¸€ä¸ªå•è¯æœ‰å…³ã€‚é‚£ä¹ˆn-gramå³åªå’Œå‰é¢çš„$n-1$ä¸ªå•è¯æœ‰å…³ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æœ€å¤§ä¼¼ç„¶ä¼°è®¡&lt;/strong&gt;ï¼šå·²çŸ¥å‰ä¸€ä¸ªè¯$w_{nâˆ’1}$â€‹æ—¶ï¼Œå½“å‰è¯$w_n$â€‹çš„æ¦‚ç‡&lt;/p&gt;
&lt;p&gt;ç»ˆæ­¢ç¬¦å·ï¼ˆend-symbolï¼‰ï¼šæ‰€æœ‰å¯èƒ½å¥å­çš„æ¦‚ç‡æ€»å’Œä¸º 1ï¼Œå¦åˆ™æ˜¯ç‰¹å®šé•¿åº¦çš„æ‰€æœ‰å¥å­æ¦‚ç‡ä¹‹å’Œä¸º 1ã€‚&lt;/p&gt;
&lt;h4 id=&#34;dealing-with-scale-in-large-n-gram-models&#34;&gt;Dealing with scale in large n-gram models
&lt;/h4&gt;&lt;p&gt;Log probabilities&lt;/p&gt;
&lt;p&gt;Nå…ƒè¯­æ³•çš„è®¡ç®—ç°åœ¨ç”šè‡³èƒ½è¾¾åˆ°æ— é™å…ƒã€‚&lt;/p&gt;
&lt;p&gt;å¯¹Nå…ƒè¯­æ³•æ¨¡å‹è¿›è¡Œä¿®å‰ªä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-training-and-test-sets&#34;&gt;Evaluating Language Models: Training and Test Sets
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;å†…éƒ¨è¯„ä¼°&lt;/strong&gt;å’Œå¤–éƒ¨è¯„ä¼°ã€‚&lt;/p&gt;
&lt;p&gt;è®­ç»ƒé›†ã€å¼€å‘é›†å’Œæµ‹è¯•é›†ã€‚&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-perplexity&#34;&gt;Evaluating Language Models: Perplexity
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Perplexityï¼ˆPPLï¼‰&lt;/strong&gt;ï¼šå›°æƒ‘åº¦è¶Šä½ï¼Œè¯´æ˜æ¨¡å‹å¯¹æ–‡æœ¬çš„é¢„æµ‹è¶Šå‡†ç¡®ï¼ˆå³æ¨¡å‹è¶Š â€œä¸å›°æƒ‘â€ï¼‰ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å…·ä½“æ¥è¯´ï¼Œæ˜¯â€œè”åˆæ¦‚ç‡å€’æ•°çš„å‡ ä½•å¹³å‡å€¼â€ã€‚&lt;/li&gt;
&lt;li&gt;åœ¨è®¡ç®—çš„æ—¶å€™å¸¸å¸¸ä¼šå–å¯¹æ•°æ¥å°†æ±‚ä¹˜ç§¯å˜ä¸ºæ±‚å’Œï¼Œé¿å…æ•°å€¼é—®é¢˜&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;perplexity-as-weighted-average-branching-factor&#34;&gt;Perplexity as Weighted Average Branching Factor
&lt;/h5&gt;&lt;p&gt;å›°æƒ‘åº¦ä¹Ÿå¯ä»¥ç†è§£ä¸º&lt;strong&gt;åŠ æƒå¹³å‡åˆ†æ”¯ç³»æ•°&lt;/strong&gt;ã€‚å…¶ä¸­ï¼Œè¯­è¨€çš„ â€œåˆ†æ”¯ç³»æ•°â€æŒ‡çš„æ˜¯ â€œä»»ä½•ä¸€ä¸ªè¯ä¹‹åå¯èƒ½å‡ºç°çš„ä¸‹ä¸€ä¸ªè¯çš„æ•°é‡â€ã€‚&lt;/p&gt;
&lt;h3 id=&#34;sampling-sentences-from-a-language-model&#34;&gt;Sampling sentences from a language model
&lt;/h3&gt;&lt;p&gt;â€œ0-1 æ•°è½´ + åŒºé—´æ˜ å°„â€æ¥ç†è§£é‡‡æ ·çš„åŸºæœ¬åŸç†ã€‚&lt;/p&gt;
&lt;h3 id=&#34;generalizing-vs-overfitting-the-training-set&#34;&gt;Generalizing vs. overfitting the training set
&lt;/h3&gt;&lt;p&gt;å¯¹äºèå£«æ¯”äºšæ–‡æœ¬å’Œåå°”è¡—æ—¥æŠ¥çš„æ–‡æœ¬ï¼Œä¸¤è€…å·®å¼‚è¿‡å¤§ä»¥è‡³äºä¸èƒ½åˆ†åˆ«ä½œä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚&lt;/p&gt;
&lt;p&gt;æ‰€ä»¥è¯´è¦ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„é¢†åŸŸè¦ç›¸ä¼¼ã€‚&lt;/p&gt;
&lt;h3 id=&#34;smoothing-interpolation-and-backoff&#34;&gt;Smoothing, Interpolation, and Backoff
&lt;/h3&gt;&lt;p&gt;zero probability n-gramsæœ‰ä¸¤ä¸ªé—®é¢˜ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä½ä¼°äº†è¯è¯­åºå¯èƒ½å‡ºç°çš„å¯èƒ½æ€§ï¼Œå¯¼è‡´æœ€ç»ˆçš„æ€§èƒ½å˜å·®&lt;/li&gt;
&lt;li&gt;å›°æƒ‘åº¦æ— æ³•è®¡ç®—ï¼Œå› ä¸ºæ— æ³•é™¤ä»¥0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å› æ­¤éœ€è¦Smoothingæˆ–è€…discounting&lt;/p&gt;
&lt;h4 id=&#34;laplace-smoothing&#34;&gt;Laplace Smoothing
&lt;/h4&gt;&lt;p&gt;å…¶å®ä¹Ÿå°±æ˜¯add one smoothingï¼Œå°±æ˜¯å¯¹äºæ‰€æœ‰çš„Nå…ƒè¯­æ³•éƒ½åŠ ä¸€ã€‚&lt;/p&gt;
&lt;p&gt;å¯¹äºè¯­è¨€æ¨¡å‹æ¥è¯´ï¼Œç»“æœå¹¶ä¸æ˜¯å¾ˆå¥½ã€‚å¯¹æ–‡æœ¬åˆ†ç±»æœ‰æ•ˆã€‚&lt;/p&gt;
&lt;h4 id=&#34;add-k-smoothing&#34;&gt;Add-k Smoothing
&lt;/h4&gt;&lt;p&gt;ä¹Ÿå°±æ˜¯å¯¹æ‰€æœ‰çš„éƒ½åŠ Kã€‚&lt;/p&gt;
&lt;p&gt;å¯¹è¯­è¨€æ¨¡å‹æ¥è¯´ä»ç„¶æ•ˆæœä¸€èˆ¬ã€‚&lt;/p&gt;
&lt;h4 id=&#34;language-model-interpolation&#34;&gt;Language Model Interpolation
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;n å…ƒè¯­æ³•æ’å€¼æ³•ï¼šåŠ æƒèåˆä¸åŒé˜¶æ•° n å…ƒè¯­æ³•çš„æ¦‚ç‡&lt;/strong&gt;ï¼Œé¿å…é«˜é˜¶çš„nå…ƒè¯­æ³•é›¶æ¦‚ç‡å¯¼è‡´çš„é¢„æµ‹å¤±æ•ˆã€‚&lt;/p&gt;
&lt;p&gt;åŠ æƒçš„$\lambda$åº”è¯¥è®¾ç½®æˆå¤šå°‘å‘¢ï¼Ÿå¯ä»¥ä»é¢„ç•™é›†held-out corpusä¸­å­¦ä¹ ã€‚ä½¿ç”¨EMï¼ˆæœŸæœ›æœ€å¤§åŒ–ï¼‰ç®—æ³•æ¥å­¦ä¹ ã€‚&lt;/p&gt;
&lt;h4 id=&#34;stupid-backoff&#34;&gt;Stupid Backoff
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;å›é€€æ¨¡å‹&lt;/strong&gt;ï¼šé«˜é˜¶né˜¶çš„æ¨¡å‹æ— æ³•ä½¿ç”¨çš„æ—¶å€™ï¼Œå›é€€åˆ°ä½é˜¶æ¨¡å‹ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discount&lt;/strong&gt;ï¼šè¦è®©å›é€€æ¨¡å‹ï¼ˆbackoff modelï¼‰è¾“å‡ºåˆç†çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¿…é¡»å¯¹é«˜é˜¶ n å…ƒè¯­æ³•çš„æ¦‚ç‡è¿›è¡Œ â€œæŠ˜æ‰£å¤„ç†â€ï¼ˆdiscountï¼‰ï¼Œä»è€Œé¢„ç•™å‡ºéƒ¨åˆ†æ¦‚ç‡ä½™é‡ï¼ˆprobability massï¼‰ï¼Œä¾›ä½é˜¶ n å…ƒè¯­æ³•ä½¿ç”¨ã€‚ä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œäººä»¬å¸¸ä½¿ç”¨ä¸€ç§æ›´ç®€å•çš„ â€œæ— æŠ˜æ‰£å›é€€ç®—æ³•â€â€”â€” å³åä¸º&lt;strong&gt;Stupid Backoff&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id=&#34;advanced-perplexitys-relation-to-entropy&#34;&gt;Advanced: Perplexity&amp;rsquo;s Relation to Entropy
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;ç†µ&lt;/strong&gt;ï¼šä¸ç¡®å®šæ€§çš„åº¦é‡æ–¹å¼ã€‚å¯ä»¥ç†è§£æ˜¯ç¼–ç æŸä¸ªå†³ç­–æˆ–æŸæ¡ä¿¡æ¯æ‰€éœ€çš„æœ€å°å¹³å‡æ¯”ç‰¹æ•°ã€‚è¶Šä¸ç¡®å®šï¼Œç†µè¶Šå¤§ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ç†µç‡&lt;/strong&gt;ï¼šå¹³å‡çš„ä¸ç¡®å®šæ€§ã€‚è‡ªç„¶è¯­è¨€çš„ç†µç‡å®šä¹‰ä¸º â€œ&lt;strong&gt;æ— é™é•¿åºåˆ—ä¸­ï¼Œæ¯ä¸ªè¯çš„å¹³å‡ç†µ&lt;/strong&gt;â€ï¼Œåæ˜ è¯­è¨€çš„é•¿æœŸä¸ç¡®å®šæ€§ã€‚ä¾‹å¦‚ï¼Œè‹±æ–‡çš„ç†µç‡çº¦ 1-2 æ¯”ç‰¹ / è¯ï¼Œæ„å‘³ç€å¹³å‡æ¯ä¸ªè¯éœ€è¦ 1-2 æ¯”ç‰¹æ¥ç¼–ç ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å¹³ç¨³æ€§&lt;/strong&gt;ï¼šåºåˆ—æ¦‚ç‡ä¸éšç€æ—¶é—´æ”¹å˜ã€‚è‡ªç„¶è¯­è¨€ä¸æ˜¯ï¼Œä½†æ˜¯Nå…ƒè¯­æ³•æ˜¯å¹³ç¨³çš„ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;éå†æ€§&lt;/strong&gt;ï¼šé•¿åºåˆ—ä¸­åŒ…å«äº†æ‰€æœ‰çš„çŸ­åºåˆ—ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shannon-McMillan-Breiman theorem&lt;/strong&gt;ï¼šå¦‚æœè¯­è¨€æ»¡è¶³æŸäº›æ­£åˆ™æ¡ä»¶ï¼ˆå‡†ç¡®åœ°è¯´ï¼Œæ˜¯å¹³ç¨³ä¸”éå†çš„ï¼‰ï¼Œ&lt;strong&gt;åºåˆ—é•¿åº¦è¶‹è¿‘äºæ— ç©·å¤§æ—¶ï¼Œâ€œåºåˆ—çš„å¹³å‡å¯¹æ•°æ¦‚ç‡çš„è´Ÿå€¼â€ ï¼Œå³ç»éªŒç†µç‡ä¼šä»¥æ¦‚ç‡1æ”¶æ•›æ•›åˆ°è¯¥è¿‡ç¨‹çš„ç†è®ºç†µç‡&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;äº¤å‰ç†µï¼ˆCross-Entropyï¼‰&lt;/strong&gt;ï¼šæˆ‘ä»¬è™½ç„¶ä¸çŸ¥é“æ•°æ®çš„çœŸå®æ¦‚ç‡åˆ†å¸ƒpï¼Œä½†æ˜¯å¯ä»¥ç”¨æ¨¡å‹mæ¥è¿‘ä¼¼pã€‚ï¼ˆå³æˆ‘ä»¬è™½ç„¶ä¸çŸ¥é“è‡ªç„¶è¯­è¨€çš„çœŸå®æƒ…å†µï¼Œä½†æ˜¯å¯ä»¥ç”¨Nå…ƒè¯­æ³•æ¥è¿‘ä¼¼ã€‚ï¼‰&lt;strong&gt;äº¤å‰ç†µè¶Šå°ï¼Œæ¨¡å‹è¶Šæ¥è¿‘çœŸå®åˆ†å¸ƒ&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å›°æƒ‘åº¦&lt;/strong&gt;ï¼š&lt;strong&gt;å›°æƒ‘åº¦æ˜¯ç†µçš„æŒ‡æ•°å½¢å¼&lt;/strong&gt;ã€‚æ¯”è¾ƒç›´è§‚ã€‚&lt;/p&gt;
&lt;h3 id=&#34;excercies&#34;&gt;Excercies
&lt;/h3&gt;&lt;h5 id=&#34;31&#34;&gt;3.1
&lt;/h5&gt;&lt;p&gt;Write out the equation for trigram probability estimation (modifying Eq. 3.11). Now write out all the non-zero trigram probabilities for the I am Sam corpus on page 40.&lt;/p&gt;
&lt;h5 id=&#34;32&#34;&gt;3.2
&lt;/h5&gt;&lt;p&gt;Calculate the probability of the sentence &lt;code&gt;i want chinese food&lt;/code&gt;. Give two probabilities, one using Fig. 3.2 and the â€˜useful probabilitiesâ€™ just below it on page 42, and another using the add-1 smoothed table in Fig. 3.7. Assume the additional add-1 smoothed probabilities $P(i|&amp;lt;s&amp;gt;) = 0.19$ and $P(&amp;lt;/s&amp;gt;|food) = 0.40$.&lt;/p&gt;
&lt;h5 id=&#34;33&#34;&gt;3.3
&lt;/h5&gt;&lt;p&gt;Which of the two probabilities you computed in the previous exercise is higher, unsmoothed or smoothed? Explain why.&lt;/p&gt;
&lt;h5 id=&#34;34&#34;&gt;3.4
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using a bigram language model with add-one smoothing, what is $P(Sam | am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;35&#34;&gt;3.5
&lt;/h5&gt;&lt;p&gt;Suppose we didnâ€™t use the end-symbol $&amp;lt;/s&amp;gt;$. Train an unsmoothed bigram grammar on the following training corpus without using the end-symbol $&amp;lt;/s&amp;gt;$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b a  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a a
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Demonstrate that your bigram model does not assign a single probability distribution across all sentence lengths by showing that the sum of the probability of the four possible 2 word sentences over the alphabet a,b is 1.0, and the sum of the probability of all possible 3 word sentences over the alphabet a,b is also 1.0.&lt;/p&gt;
&lt;h5 id=&#34;36&#34;&gt;3.6
&lt;/h5&gt;&lt;p&gt;Suppose we train a trigram language model with add-one smoothing on a given corpus. The corpus contains V word types. Express a formula for estimating $P(w3|w1,w2)$, where $w3$ is a word which follows the bigram$ (w1,w2)$, in terms of various n-gram counts and V. Use the notation $c(w1,w2,w3)$ to denote the number of times that trigram $(w1,w2,w3)$ occurs in the corpus, and so on for bigrams and unigrams.&lt;/p&gt;
&lt;h5 id=&#34;37&#34;&gt;3.7
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we use linear interpolation smoothing between a maximum-likelihood bigram model and a maximum-likelihood unigram model with $Î»â‚ = 1/2$ and $Î»â‚‚ = 1/2,$ what is $P(Sam|am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;38&#34;&gt;3.8
&lt;/h5&gt;&lt;p&gt;Write a program to compute unsmoothed unigrams and bigrams.&lt;/p&gt;
&lt;h5 id=&#34;39&#34;&gt;3.9
&lt;/h5&gt;&lt;p&gt;Run your n-gram program on two different small corpora of your choice (you might use email text or newsgroups). Now compare the statistics of the two corpora. What are the differences in the most common unigrams between the two? How about interesting differences in bigrams?&lt;/p&gt;
&lt;h5 id=&#34;310&#34;&gt;3.10
&lt;/h5&gt;&lt;p&gt;Add an option to your program to generate random sentences.&lt;/p&gt;
&lt;h5 id=&#34;311&#34;&gt;3.11
&lt;/h5&gt;&lt;p&gt;Add an option to your program to compute the perplexity of a test set.&lt;/p&gt;
&lt;h5 id=&#34;312&#34;&gt;3.12
&lt;/h5&gt;&lt;p&gt;You are given a training set of 100 numbers that consists of 91 zeros and 1 each of the other digits 1-9. Now we see the following test set: 0 0 0 0 0 3 0 0 0 0. What is the unigram perplexity?&lt;/p&gt;
&lt;h2 id=&#34;logistic-regression-and-text-classification&#34;&gt;Logistic Regression and Text Classification
&lt;/h2&gt;&lt;p&gt;ç»å…¸ä»»åŠ¡ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sentiment analysis&lt;/li&gt;
&lt;li&gt;spam detection&lt;/li&gt;
&lt;li&gt;language id&lt;/li&gt;
&lt;li&gt;authorship attribution&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;machine-learning-and-classification&#34;&gt;Machine Learning and Classification
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;äººå·¥è§„åˆ™å¾ˆè„†å¼±ï¼Œæ•°æ®ä¸€å˜åŒ–å°±æ— æ³•ä½¿ç”¨&lt;/li&gt;
&lt;li&gt;LLMçš„å¼±ç‚¹ï¼šå¹»è§‰ã€æ— æ³•è§£é‡Šã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å› æ­¤æœ€å¸¸è§çš„åˆ†ç±»æ–¹æ³•æ˜¯&lt;strong&gt;æœ‰ç›‘ç£æœºå™¨å­¦ä¹ &lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ¦‚ç‡åˆ†ç±»å™¨ï¼šè¾“å‡º&lt;strong&gt;æ ·æœ¬å±äºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡&lt;/strong&gt;è€Œä¸æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œä¿è¯åœ¨åˆå¹¶çš„ç³»ç»Ÿé‡Œä¸è¿‡æ—©åœ°è¾“å‡ºç»“æœã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åˆ†ç±»å™¨çš„æ ¸å¿ƒç»„ä»¶ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A feature representation of the input&lt;/li&gt;
&lt;li&gt;A classificaition function that computes $\hat{y}$&lt;/li&gt;
&lt;li&gt;An objective funcion that we want to potimize for learning
&lt;ul&gt;
&lt;li&gt;loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An algorithm for optimizing the objective function
&lt;ul&gt;
&lt;li&gt;stochastic gradient descent algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-sigmoid-function&#34;&gt;The Sigmoid Function
&lt;/h3&gt;&lt;p&gt;äºŒåˆ†ç±»é€»è¾‘å›å½’çš„ç›®æ ‡æ˜¯ï¼šè®¡ç®—æ ·æœ¬å±äºæ­£ç±»çš„æ¦‚ç‡ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¬¬ä¸€æ­¥ï¼šè®¡ç®—çº¿æ€§å¾—åˆ†$z=wâ‹…x+b$ï¼Œå€¼åŸŸä¸º$[-\infty, +\infty ]$&lt;/li&gt;
&lt;li&gt;ç¬¬äºŒæ­¥ï¼š&lt;strong&gt;é€šè¿‡ Sigmoid å‡½æ•°è½¬æ¢ä¸ºæ¦‚ç‡&lt;/strong&gt;ï¼š  å°†çº¿æ€§å¾—åˆ†Â zÂ æ˜ å°„åˆ°Â $[0,1]Â $åŒºé—´&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$z$å¸¸å¸¸è¢«ç§°ä½œLogitï¼ˆå¯¹æ•°å‡ ç‡ï¼‰ã€‚Logitå°±æ˜¯Sigmoidçš„åå‡½æ•°ã€‚å¯ä»¥æé†’æˆ‘ä»¬åç»­è¦åŠ ä¸ŠSigmoidè¿›è¡Œè½¬æ¢ï¼Œå› ä¸º$z$å¹¶ä¸æ˜¯ä¸€ä¸ªçœŸå®çš„å€¼ã€‚&lt;/p&gt;
&lt;h3 id=&#34;classification-with-logistic-regression&#34;&gt;Classification with Logistic Regression
&lt;/h3&gt;&lt;p&gt;å½“æ¦‚ç‡å¤§äº0.5çš„æ—¶å€™ï¼Œå°±æŠŠå®ƒåˆ†ç±»åˆ°æ­£ç±»é‡Œã€‚&lt;/p&gt;
&lt;h4 id=&#34;sentiment-classification&#34;&gt;Sentiment Classification
&lt;/h4&gt;&lt;p&gt;ä¸¾äº†ä¸€ä¸ªä¾‹å­ã€‚&lt;/p&gt;
&lt;h4 id=&#34;other-classification-tasks-and-features&#34;&gt;Other Classification Tasks and Features
&lt;/h4&gt;&lt;p&gt;Period disambiguationï¼šç¡®å®šå¥å·æ˜¯EOSè¿˜æ˜¯å…¶ä»–ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Designing v.s. Learning featuresï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åˆšåˆšçš„ä¾‹å­ï¼Œç‰¹å¾éƒ½æ˜¯äººå·¥è®¾è®¡çš„ã€‚æ­¤å¤–è¿˜æœ‰ï¼š
&lt;ul&gt;
&lt;li&gt;feaure interactionsï¼šåŸºç¡€ç‰¹å¾ç»„åˆæˆçš„å¤æ‚ç‰¹å¾&lt;/li&gt;
&lt;li&gt;feature templatesï¼šæŠ½è±¡çš„ç‰¹å¾è§„èŒƒæ¥å®šä¹‰ç‰¹å¾ã€‚è¿™é‡Œçš„ç‰¹å¾ç©ºé—´æ˜¯ç¨€ç–çš„ï¼Œæ­¤å¤–ç‰¹å¾ä¸€èˆ¬æ˜¯å­—ç¬¦ä¸²æè¿°çš„Hashå€¼ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;äººå·¥è®¾è®¡å¤ªå¤æ‚äº†ã€‚å› æ­¤ç°ä»£çš„NLPç³»ç»Ÿéƒ½æ˜¯ç”¨Representation Learningæ¥è§£å†³ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;standardizeå’Œnormalizeã€‚&lt;/p&gt;
&lt;h4 id=&#34;processing-many-examples-at-once&#34;&gt;Processing many examples at once
&lt;/h4&gt;&lt;p&gt;å¦‚æœæœ‰è®¸å¤šçš„å€¼è¦è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨matrix arithmeticæ¥ä¸€æ¬¡è®¡ç®—å®Œã€‚&lt;/p&gt;
&lt;h3 id=&#34;multinomial-logistic-regression&#34;&gt;Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;å¤šé¡¹é€»è¾‘å›å½’ä¹Ÿç§°softmax regressionï¼Œè€çš„æ•™æä¸Šä¹Ÿå«maxent clasifierã€‚&lt;/p&gt;
&lt;p&gt;åœ¨å¤šé¡¹é€»è¾‘å›å½’ä¸­ï¼Œç›´æ¥è¾“å‡ºç»“æœè€Œä¸æ˜¯ä¸€ä¸ªæ¦‚ç‡å€¼ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hard classification&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;softmax&#34;&gt;Softmax
&lt;/h4&gt;&lt;p&gt;Sigmoidå‡½æ•°åœ¨å¤šåˆ†ç±»æƒ…å†µä¸‹çš„æ¨å¹¿ã€‚&lt;/p&gt;
&lt;h4 id=&#34;applying-softmax-in-logistic-regression&#34;&gt;Applying Softmax in Logistic Regression
&lt;/h4&gt;&lt;p&gt;å¯ä»¥ä½¿ç”¨çŸ©é˜µè¿ç®—æ–¹å¼åŠ å¿«è®¡ç®—ã€‚&lt;/p&gt;
$$\hat{y}=softmax(Wx+b)$$&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2506.11035&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Doumbouya et al., 2025&lt;/a&gt;æ˜¯è¿™ä¹ˆè®¤ä¸ºçš„ï¼šé€»è¾‘å›å½’å°†çŸ©é˜µçš„æ¯ä¸€è¡ŒÂ $w_k$è§†ä¸º&lt;strong&gt;ç¬¬Â $k$Â ç±»çš„åŸå‹ï¼ˆprototypeï¼‰&lt;/strong&gt;ï¼Œç”±äºä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå®ƒä»¬çš„ç‚¹ç§¯ï¼ˆdot productï¼‰å€¼å°±è¶Šå¤§ï¼Œå› æ­¤ç‚¹ç§¯å¯ä½œä¸ºè¡¡é‡å‘é‡ç›¸ä¼¼åº¦çš„å‡½æ•°ã€‚æ¨¡å‹æœ€ç»ˆå°†è¾“å…¥åˆ†é…ç»™ç›¸ä¼¼åº¦æœ€é«˜çš„ç±»åˆ«ã€‚&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;features-in-multinomial-logistic-regression&#34;&gt;Features in Multinomial Logistic Regression
&lt;/h4&gt;&lt;p&gt;ç‰¹å¾æƒé‡åŒæ—¶ä¾èµ–äºè¾“å…¥æ–‡æœ¬å’Œè¾“å‡ºç±»åˆ«ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597.png&#34;
	width=&#34;744&#34;
	height=&#34;837&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_dcd37b06fe097e65.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_87f8d0d9a05a6baf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;213px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;learning-in-logistic-regression&#34;&gt;Learning in Logistic Regression
&lt;/h3&gt;&lt;p&gt;é€»è¾‘å›å½’æ˜¯å¦‚ä½•å®ç°å­¦ä¹ çš„ï¼Ÿ&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä½¿system outputï¼ˆclassifier outputï¼‰å’Œgold outputï¼ˆcorrect outputï¼‰è¶Šæ¥è¿‘è¶Šå¥½ã€‚ä¸¤è€…ä¹‹é—´çš„è·ç¦»å¯ä»¥ç§°ä½œ&lt;strong&gt;æŸå¤±å‡½æ•°&lt;/strong&gt;æˆ–è€…&lt;strong&gt;ä»£ä»·å‡½æ•°&lt;/strong&gt;ã€‚ä¸‹é¢ä»‹ç»äº¤å‰ç†µã€‚&lt;/li&gt;
&lt;li&gt;éœ€è¦ä¸€ä¸ªç®—æ³•æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚ä¸‹é¢ä»‹ç»éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-cross-entropy-loss-function&#34;&gt;The Cross-entropy Loss Function
&lt;/h3&gt;&lt;p&gt;æ¡ä»¶æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼šåœ¨ç»™å®š$x$ä¸‹ï¼Œé€‰æ‹©å‚æ•°$w$å’Œ$b$ä½¿å¾—$y$çš„å¯¹æ•°æ¦‚ç‡æœ€å¤§ã€‚&lt;/p&gt;
&lt;p&gt;è¿™é‡ŒæŸå¤±å‡½æ•°æ˜¯&lt;strong&gt;è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼ˆnegative log likelihood lossï¼‰&lt;/strong&gt;ï¼Œé€šå¸¸ä¹Ÿè¢«ç§°ä¸º&lt;strong&gt;äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;p&gt;ä»‹ç»äº†ä¸€ä¸‹ä¸ºä»€ä¹ˆ&lt;strong&gt;æœ€å°åŒ–äº¤å‰ç†µæŸå¤±å¯ä»¥ä½¿å¾—çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹åˆ†å¸ƒæ›´åŠ æ¥è¿‘&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent
&lt;/h3&gt;&lt;p&gt;æ¢¯åº¦ä¸‹é™ç®—æ³•çš„åŸç†ã€‚ä»‹ç»äº†æ¢¯åº¦ã€å­¦ä¹ ç‡ã€‚&lt;/p&gt;
&lt;h4 id=&#34;the-gradient-for-logistic-regression&#34;&gt;The Gradient for Logistic Regression
&lt;/h4&gt;&lt;p&gt;é€»è¾‘å›å½’çš„æ¢¯åº¦å°±æ˜¯
&lt;/p&gt;
$$\frac{\partial L_{\mathrm{CE}}(\hat{y},y)}{\partial w_{j}}=-(y-\hat{y})x_{j}$$&lt;p&gt;
ä¹Ÿå°±æ˜¯é¢„æµ‹å€¼$\hat{y}$å’Œå®é™…å€¼$y$ä¹‹é—´çš„å·®ä¹˜è¾“å…¥å€¼$x_j$ã€‚&lt;/p&gt;
&lt;h4 id=&#34;the-stochastic-gradient-descent-algorithm&#34;&gt;The Stochastic Gradient Descent Algorithm
&lt;/h4&gt;&lt;p&gt;éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•æ˜¯ä¸€ç§åœ¨çº¿ç®—æ³•ï¼Œå¯ä»¥è¾¹æ¥æ”¶æ•°æ®è¾¹å­¦ä¹ ã€‚&lt;/p&gt;
&lt;p&gt;SGDæ¯æ¬¡ç”¨&lt;strong&gt;å•ä¸ªéšæœºæ ·æœ¬&lt;/strong&gt;è®¡ç®—æ¢¯åº¦ã€‚&lt;/p&gt;
&lt;h4 id=&#34;mini-batch-training&#34;&gt;Mini-batch Training
&lt;/h4&gt;&lt;p&gt;batch trainingå’Œmini-batch trainingçš„åŒºåˆ«ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch gradientï¼šæ‰€æœ‰çš„éšæœºæ ·æœ¬è®¡ç®—æ¢¯åº¦ã€‚&lt;/li&gt;
&lt;li&gt;mini-batch gradientï¼šå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚æ¯æ¬¡é€‰æ‹©&lt;strong&gt;ä¸€å°æ‰¹éšæœºæ ·æœ¬&lt;/strong&gt;è®¡ç®—æ¢¯åº¦ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learning-in-multinomial-logistic-regression&#34;&gt;Learning in Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;å¤šé¡¹å¼é€»è¾‘å›å½’å…¶å®å’ŒäºŒé¡¹å¼é€»è¾‘å›å½’å·®ä¸å¤šã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æœ¬è´¨æ˜¯ä½¿ç”¨ç‹¬çƒ­æ ‡ç­¾+æ¦‚ç‡å‘é‡çš„å½¢å¼è¿›è¡Œè®¡ç®—ã€‚&lt;/li&gt;
&lt;li&gt;æ ¸å¿ƒæ˜¯ â€œå¯¹æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡å–è´Ÿå¯¹æ•°â€ï¼Œå¾—åˆ°äº¤å‰ç†µæŸå¤±ï¼Œå…¶è¶Šå°åˆ™é¢„æµ‹æ¦‚ç‡è¶Šé«˜ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-precision-recall-f-measure&#34;&gt;Evaluation: Precision, Recall, F-measure
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;confusion matrix&lt;/li&gt;
&lt;li&gt;accuracy&lt;/li&gt;
&lt;li&gt;precision&lt;/li&gt;
&lt;li&gt;recall&lt;/li&gt;
&lt;li&gt;F-measure
&lt;ul&gt;
&lt;li&gt;F1&lt;/li&gt;
&lt;li&gt;a weighted harmonic mean of precision and recall.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893.png&#34;
	width=&#34;928&#34;
	height=&#34;394&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_5b835770261a7097.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_9163edd8010643ed.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;microaveraging v.s. macroaveraging&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¾®è§‚å¹³å‡ï¼šæ›´å…³æ³¨ â€œæ•´ä½“æ ·æœ¬çš„é¢„æµ‹å‡†ç¡®æ€§â€ï¼Œ&lt;strong&gt;å°‘æ•°ç±»é”™åˆ¤ä»£ä»·ä½äºå¤šæ•°ç±»&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;å®è§‚å¹³å‡ï¼šæ›´å…³æ³¨æ‰€æœ‰çš„ç±»çš„é”™åˆ¤ä»£ä»·çš„å…¬å¹³ï¼Œ&lt;strong&gt;å°‘æ•°ç±»å’Œå¤šæ•°ç±»çš„ä»£ä»·ç›¸ç­‰&lt;/strong&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005.png&#34;
	width=&#34;1084&#34;
	height=&#34;468&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_bca6ffdfb72f8971.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_899e55b55133737a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;555px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;test-sets-and-cross-validation&#34;&gt;Test sets and Cross-validation
&lt;/h3&gt;&lt;p&gt;Cross-validationï¼šè§£å†³æµ‹è¯•é›†ä¸è¶³çš„é—®é¢˜ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å›ºå®šè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚&lt;/li&gt;
&lt;li&gt;è®­ç»ƒé›†ä¸­è¿›è¡Œåˆ†å‰²ã€‚
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382.png&#34;
	width=&#34;895&#34;
	height=&#34;462&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_4558bdf3b4166cbe.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_e53d98bd5ba967c8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;statistical-significance-testing&#34;&gt;Statistical Significance Testing
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä¸åªæ˜¯ç®€å•åœ°æ£€æŸ¥Aåœ¨æµ‹è¯•é›†ä¸Šçš„ç»“æœ$M(A,x)$å¥½äºBåœ¨æµ‹è¯•é›†ä¸Šçš„ç»“æœ$M(B,x)$ã€‚å¦‚æœå·®å¾ˆå°çš„è¯ï¼Œå…¶å®ä¸ä¸€å®šèƒ½è¯æ˜Açš„ç»“æœæ¯”Bå°ï¼Œä¸å…·æœ‰ç»Ÿè®¡å­¦ä¸Šçš„æ˜¾è‘—æ€§ã€‚&lt;/li&gt;
&lt;li&gt;è®¾è®¡ä¸€ä¸ªæ•ˆåº”é‡$\delta (x)=M(A,x)-M(B,x)$ï¼ŒåŸå‡è®¾æ˜¯$H_0 :\delta (x)\leq 0$ã€‚è¿™æ ·è®¡ç®—på€¼æ˜¯å¦å°äºé˜ˆå€¼å¯ä»¥å¾—å‡ºæ˜¯å¦æ˜¾è‘—æ€§åœ°Aæ¯”Bè¦å¥½ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åœ¨NLPä¸­ï¼Œä¸€èˆ¬ä¸ç”¨ANOVAsæˆ–è€…tæ£€éªŒï¼Œè€Œæ˜¯ä½¿ç”¨éå‚æ•°æ£€éªŒï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;è¿‘ä¼¼éšæœºåŒ–æ£€éªŒ&lt;/strong&gt;ï¼ˆApproximate Randomization Testï¼‰&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bootstrap æ£€éªŒ&lt;/strong&gt;ï¼ˆBootstrap Testï¼‰&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;æ–¹å·®åˆ†æå’Œtæ£€éªŒéƒ½éœ€è¦æœ‰å‡è®¾ï¼šæ–¹å·®é½æ€§æˆ–æ•°æ®æœä»æ­£æ€åˆ†å¸ƒã€‚æ‰€ä»¥åªèƒ½ç”¨éå‚æ•°æ£€éªŒã€‚&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;the-paired-bootstrap-test&#34;&gt;The Paired Bootstrap Test
&lt;/h4&gt;&lt;p&gt;Bootstrap æ£€éªŒçš„æ ¸å¿ƒæ˜¯ â€œé‡æŠ½æ ·â€â€”â€” ä»åŸå§‹æµ‹è¯•é›†&lt;code&gt;x&lt;/code&gt;ä¸­&lt;strong&gt;æœ‰æ”¾å›åœ°éšæœºæŠ½å–&lt;/strong&gt;ç”Ÿæˆæ–°çš„æµ‹è¯•é›†ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970.png&#34;
	width=&#34;1097&#34;
	height=&#34;490&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_8f406568f15b6414.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_c48413deb765f0e1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;
åœ¨æ–°çš„æµ‹è¯•é›†ä¸Šï¼ŒP å€¼ç­‰äº â€œé‡æŠ½æ ·æµ‹è¯•é›†ä¸­ï¼Œ$d(x^{(i)})â‰¥2d(x)$çš„æ•°é‡å æ€»é‡æŠ½æ ·æ¬¡æ•°bçš„æ¯”ä¾‹â€ã€‚&lt;strong&gt;åˆ¤æ–­æ­¤æ—¶çš„på€¼æ˜¯å¦ä½äºé˜ˆå€¼å°±å¯ä»¥åˆ¤æ–­å‡ºæ˜¯å¦æ˜¯æ•°æ®é›†æœ¬èº«çš„åå·®å¯¼è‡´äº†Aæ¯”Bè¦ç»“æœå¥½ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LLMçš„è§£é‡Šï¼šBootstrap é‡æŠ½æ ·ï¼Œå°±æ˜¯åœ¨ â€œä¸æ”¹å˜å¤©å¹³åˆå§‹å€¾æ–œï¼ˆæµ‹è¯•é›†åå‘ï¼‰â€ çš„å‰æä¸‹ï¼Œåå¤æ”¾ â€œéšæœºé‡é‡ï¼ˆé‡æŠ½æ ·çš„æ ·æœ¬ï¼‰â€ï¼Œçœ‹å·¦è¾¹ä¼šæ¯”å³è¾¹å¤šä½å¤šå°‘æ ¼ â€”â€” å¦‚æœåªæ˜¯å¤©å¹³æœ¬èº«æ­ªäº†ï¼Œéšæœºæ”¾é‡é‡æ—¶ï¼Œå·¦è¾¹æœ€å¤šä½ 2 æ ¼å·¦å³ï¼ˆå¸¸è§„æ³¢åŠ¨ï¼‰ï¼›å¦‚æœå·¦è¾¹çœŸçš„æ›´é‡ï¼Œå°±å¯èƒ½ä½ 4 æ ¼ä»¥ä¸Šï¼ˆæç«¯æƒ…å†µï¼‰ã€‚è¿™ç§æç«¯æƒ…å†µå¤šäº†ï¼Œè¶…è¿‡äº†é˜ˆå€¼ï¼Œæˆ‘ä»¬å°±æ›´ç›¸ä¿¡æ˜¯å¤©å¹³æœ¬èº«çš„é—®é¢˜ã€‚&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;avoiding-harms-in-classification&#34;&gt;Avoiding Harms in Classification
&lt;/h3&gt;&lt;p&gt;representational harmsï¼šç”±äºå¯¹ç‰¹å®šç¤¾ä¼šç¾¤ä½“çš„è´¬ä½æˆ–åˆ»æ¿å°è±¡å¯¼è‡´çš„ä¼¤å®³ã€‚&lt;/p&gt;
&lt;p&gt;toxic detection&lt;/p&gt;
&lt;p&gt;model card&lt;/p&gt;
&lt;h3 id=&#34;interpereting-models&#34;&gt;Interpereting Models
&lt;/h3&gt;&lt;p&gt;æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ã€‚é€»è¾‘å›å½’å°±æ˜¯æ¯”è¾ƒå¥½çš„å¯è§£é‡Šçš„æ¨¡å‹ã€‚&lt;/p&gt;
&lt;h3 id=&#34;advanced-regularization&#34;&gt;Advanced: Regularization
&lt;/h3&gt;&lt;p&gt;regularizationæ¥è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2 regulaization&lt;/li&gt;
&lt;li&gt;L1 regulaization&lt;/li&gt;
&lt;li&gt;lasso&lt;/li&gt;
&lt;li&gt;ridge&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>å­¦ä¹ ç¬”è®° | LangChainå­¦ä¹ ç¬”è®°</title>
        <link>https://ionfeather.github.io/2024/langchain-learning/</link>
        <pubDate>Tue, 26 Nov 2024 13:45:58 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2024/langchain-learning/</guid>
        <description>&lt;img src="https://ionfeather.github.io/2024/langchain-learning/cover.png" alt="Featured image of post å­¦ä¹ ç¬”è®° | LangChainå­¦ä¹ ç¬”è®°" /&gt;&lt;h2 id=&#34;ä¸ºä»€ä¹ˆè¦å­¦ä¹ langchain&#34;&gt;ä¸ºä»€ä¹ˆè¦å­¦ä¹ LangChain
&lt;/h2&gt;&lt;p&gt;æˆ‘å¸Œæœ›èƒ½å¤Ÿæ„å»ºä¸€ä¸ªèƒ½é˜…è¯»PDFè®ºæ–‡çš„Agentï¼Œå¹¶ä¸”èƒ½å¤Ÿè¾“å‡ºå¯¹è®ºæ–‡ä¼˜ç¼ºç‚¹çš„è¯„ä»·ã€‚&lt;/p&gt;

&lt;div class=&#34;chat --other&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34;&gt;å¯¼å¸ˆ&amp;nbsp;&amp;nbsp;&amp;nbsp;2024-10-12 14:30&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
åšä¸€ä¸ªè®ºæ–‡é˜…è¯»çš„å¤§æ¨¡å‹ã€‚  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;


&lt;div class=&#34;chat --self&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34; style=&#34;text-align: right;&#34;&gt;2024-10-12 14:45&amp;nbsp;&amp;nbsp;&amp;nbsp;æˆ‘&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
å¥½çš„è€å¸ˆã€‚  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;

&lt;p&gt;ä½¿ç”¨LangChainå¬è¯´æ¯”è¾ƒæ–¹ä¾¿ã€‚&lt;/p&gt;
&lt;h2 id=&#34;langchainæ˜¯ç”¨æ¥åšä»€ä¹ˆçš„&#34;&gt;LangChainæ˜¯ç”¨æ¥åšä»€ä¹ˆçš„ï¼Ÿ
&lt;/h2&gt;&lt;p&gt;LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±LLMé©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å¯ä»¥æŠŠLLMä½œä¸ºå†…æ ¸ï¼ŒLangChainä½œä¸ºå¤–å£³ï¼Œæ­å»ºä¸€ä¸ªç¨‹åºå‡ºæ¥ã€‚&lt;/p&gt;
&lt;p&gt;LangChainæä¾›äº†&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç»„ä»¶ï¼šå¤„ç†LLMçš„ç»„ä»¶çš„æŠ½è±¡ï¼›&lt;/li&gt;
&lt;li&gt;å®šåˆ¶é“¾ï¼šæŠŠç»„ä»¶æ‹¼èµ·æ¥ï¼Œå®ç°ä¸€ä¸ªç‰¹å®šç”¨ä¾‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å¯¹äºé˜…è¯»PDFï¼Œç›®å‰æœ‰ä¸¤ä¸ªæƒ³æ³•ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å°†PDFè½¬ä¸ºJSONï¼Œç„¶åè¾“å…¥åˆ°LLMä¸­ï¼›&lt;/li&gt;
&lt;li&gt;æ„å»ºRAGã€‚ä½¿ç”¨LangChainèƒ½å¤Ÿæ¯”è¾ƒæ–¹ä¾¿åœ°å®ç°è¿™ä¸ªåŠŸèƒ½ï¼Œå¬ZLBè¯´è¿™ä¸ªä¹Ÿä¸æ˜¯å¾ˆéš¾ã€‚æˆ‘ä¹‹å‰çš„ç•éš¾æƒ…ç»ªå¯èƒ½å¤ªé‡äº†ï¼Œç°åœ¨å†™ä¸€ä¸ªæ–‡æ¡£ï¼Œæ¿€åŠ±å’Œè®°å½•ä¸€ä¸‹è‡ªå·±å­¦ä¹ ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
    &lt;summary&gt;RAGæ˜¯ä»€ä¹ˆï¼Ÿ&lt;/summary&gt;
    &lt;p&gt;è™½ç„¶LLMéå¸¸å¼ºå¤§ï¼Œä½†å®ƒä»¬å¯¹äºå®ƒä»¬æœªç»è®­ç»ƒçš„ä¿¡æ¯ä¸€æ— æ‰€çŸ¥ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨LLMæ¥å›ç­”å®ƒæœªç»è®­ç»ƒçš„æ–‡æ¡£ç›¸å…³é—®é¢˜ï¼Œæ‚¨éœ€è¦å‘å…¶æä¾›è¿™äº›æ–‡æ¡£çš„ä¿¡æ¯ã€‚æœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯é€šè¿‡â€œæ£€ç´¢å¢å¼ºç”Ÿæˆâ€ï¼ˆ retrieval augmented generationï¼ŒRAG ï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ€æƒ³æ˜¯ï¼Œåœ¨ç»™å®šä¸€ä¸ªé—®é¢˜æ—¶ï¼Œé¦–å…ˆè¿›è¡Œæ£€ç´¢æ­¥éª¤ä»¥è·å–ä»»ä½•ç›¸å…³æ–‡æ¡£ã€‚ç„¶åå°†è¿™äº›æ–‡æ¡£ä¸åŸå§‹é—®é¢˜ä¸€èµ·ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œå¹¶è®©å®ƒç”Ÿæˆä¸€ä¸ªå›ç­”ã€‚ç„¶è€Œï¼Œä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œé¦–å…ˆéœ€è¦å°†æ–‡æ¡£ä»¥é€‚åˆè¿›è¡Œæ­¤ç±»æŸ¥è¯¢çš„æ ¼å¼å‘ˆç°ã€‚&lt;/p&gt;

&lt;/details&gt;

&lt;h2 id=&#34;æ„é€ ä¸€ä¸ªè¯­ä¹‰æœç´¢å¼•æ“&#34;&gt;æ„é€ ä¸€ä¸ªè¯­ä¹‰æœç´¢å¼•æ“
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/tutorials/retrievers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Build a semantic search engine | ğŸ¦œï¸ğŸ”— LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;è¯»å–pdf&#34;&gt;è¯»å–PDF
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to load PDFs | ğŸ¦œï¸ğŸ”— LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;è¿™é‡Œï¼Œæ–‡æ¡£ä¸­æ¨èä½¿ç”¨äº†pypdfåº“ã€‚è¿™é‡Œ&lt;/p&gt;
&lt;p&gt;åœ¨å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨å…¶ä»–æå–æ•ˆæœæ›´å¥½çš„åº“ã€‚LangChainæ”¯æŒçš„PDFæ ¼å¼å¾ˆå¤šï¼Œå¯ä»¥é€‰æ‹©ä¸€ä¸‹ã€‚&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Document Loader&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
          &lt;th&gt;Package/API&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfloader&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses &lt;code&gt;pypdf&lt;/code&gt; to load and parse PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/unstructured_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Unstructured&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses Unstructured&amp;rsquo;s open source library to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/amazon_textract&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazon Textract&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses AWS API to load PDFs&lt;/td&gt;
          &lt;td&gt;API&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/mathpix&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MathPix&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses MathPix to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfplumber&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFPlumber&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFPlumber&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfdirectory&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFDirectry&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load a directory with PDF files&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfium2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFium2&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyPDFium2&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pymupdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyMuPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyMuPDF&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfminer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFMiner&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFMiner&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;æ­¤å¤–ï¼Œå¯¼å¸ˆä¹‹å‰è¿˜ç»™æˆ‘æ¨èäº†&lt;a class=&#34;link&#34; href=&#34;https://github.com/titipata/scipdf_parser&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;titipata/scipdf_parser&lt;/a&gt;åº“ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å›¾åƒå’Œæ‰«ææ–‡æœ¬ï¼Œå¹¶ä¸”è¿è¡Œåœ¨dockerä¸Šï¼Œä¾¿äºéƒ¨ç½²ã€‚&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;pypdfçš„ä»‹ç»&lt;/summary&gt;
    &lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pypdf.readthedocs.io/en/stable/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Welcome to pypdf â€” pypdf 5.1.0 documentation&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;PyPDF æ˜¯ä¸€ä¸ªç”¨äºå¤„ç† PDF æ–‡ä»¶çš„ Pythonåº“ã€‚å®ƒæä¾›äº†ä¸€ç»„å·¥å…·å’ŒåŠŸèƒ½ï¼Œç”¨äºè¯»å–ã€è§£æå’Œæ“ä½œ PDF æ–‡ä»¶çš„å†…å®¹ã€‚&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&#34;splitting&#34;&gt;Splitting
&lt;/h3&gt;&lt;details&gt;
    &lt;summary&gt;åŸæ–‡&lt;/summary&gt;
    &lt;p&gt;For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve &lt;code&gt;Document&lt;/code&gt; objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not &amp;ldquo;washed out&amp;rdquo; by surrounding text.&lt;/p&gt;
&lt;p&gt;We can use &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/concepts/text_splitters/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;text splitters&lt;/a&gt; for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/recursive_text_splitter/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RecursiveCharacterTextSplitter&lt;/a&gt;, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.&lt;/p&gt;
&lt;p&gt;We set &lt;code&gt;add_start_index=True&lt;/code&gt; so that the character index where each split Document starts within the initial Document is preserved as metadata attribute â€œstart_indexâ€.&lt;/p&gt;
&lt;p&gt;See &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this guide&lt;/a&gt; for more detail about working with PDFs, including how to extract text from specific sections and images.&lt;/p&gt;

&lt;/details&gt;

&lt;p&gt;å¯¹äºé—®é¢˜æé—®çš„æ–‡æœ¬æ¥è¯´ï¼Œç›´æ¥å›ç­”ä¸€æ•´é¡µè‚¯å®šæ˜¯å¤ªç²—ç•¥äº†ã€‚æˆ‘ä»¬æœ€ç»ˆçš„ç›®æ ‡æ˜¯æ£€ç´¢å›ç­”è¾“å…¥æŸ¥è¯¢çš„æ–‡æ¡£å¯¹è±¡ï¼Œè¿›ä¸€æ­¥æ‹†åˆ† PDF å°†æœ‰åŠ©äºç¡®ä¿æ–‡æ¡£ç›¸å…³éƒ¨åˆ†çš„å«ä¹‰ä¸ä¼šè¢«å‘¨å›´çš„æ–‡æœ¬â€œå†²æ·¡â€ã€‚&lt;/p&gt;
&lt;p&gt;æ‰€ä»¥æ¥ä¸‹æ¥åº”è¯¥ç”¨æ–‡æœ¬åˆ†å‰²å™¨æ¥è¿›è¡Œåˆ†å‰²ï¼ˆSplittingï¼‰å¤„ç†ã€‚è¿™é‡Œç”¨ä¸€ä¸ª&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;è¿›è¡Œåˆ†å‰²ã€‚è¿™é‡Œä½¿ç”¨å¸¸è§åˆ†éš”ç¬¦æ¥å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å‰²ï¼Œé€‚ç”¨äºä¸€èˆ¬çš„æ–‡æœ¬ã€‚&lt;/p&gt;

&lt;div class=&#34;notice notice-warning&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 576 512&#34;Â fill=&#34;#704343&#34;&gt;&lt;path d=&#34;M570 440c18 32-5 72-42 72H48c-37 0-60-40-42-72L246 24c19-32 65-32 84 0l240 416zm-282-86a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;ä½¿ç”¨&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;æ— æ³•è¯»å–å›¾åƒæˆ–ç‰¹å®šåŒºåŸŸçš„æ–‡æœ¬ã€‚&lt;/p&gt;&lt;/div&gt;

&lt;h3 id=&#34;embeddings&#34;&gt;Embeddings
&lt;/h3&gt;&lt;p&gt;æ¥ä¸‹æ¥å°†æ–‡æœ¬åµŒå…¥åˆ°å‘é‡ä¸­å»ï¼Œä¾¿äºè¿›è¡Œç›¸ä¼¼åº¦æŒ‡æ ‡æ¥è¯†åˆ«ç›¸å…³æ–‡æœ¬ã€‚&lt;/p&gt;
&lt;p&gt;è¿™é‡ŒLangChainæ”¯æŒæ•°åç§Embeddingsæ–¹æ³•ã€‚è¿™é‡Œæˆ‘é€‰æ‹©äº†ä½¿ç”¨Hugging Faceï¼Œå¯ä»¥é€‰æ‹©å°†æ¨¡å‹ä¸‹è½½è‡³æœ¬åœ°æˆ–è€…ä½¿ç”¨&lt;code&gt;Hugging Face Inference API&lt;/code&gt;æ¥è°ƒç”¨æ¥å£ã€‚è¿™é‡Œå¯ä»¥ç›´æ¥ä½¿ç”¨&lt;code&gt;HuggingFaceEmbeddings&lt;/code&gt;æ¥è¿›è¡Œå¤„ç†ã€‚éå¸¸æ–¹ä¾¿ã€‚&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_huggingface&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sentence-transformers/all-mpnet-base-v2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Generated vectors of length &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;vector-stores&#34;&gt;Vector Stores
&lt;/h3&gt;&lt;p&gt;LangChainçš„Vector Storeså¯¹è±¡åŒ…æ‹¬äº†ä¸€äº›æŠŠæ–‡æœ¬å’ŒDocumentå¯¹è±¡åŠ å…¥åˆ°Storesä¸­çš„æ–¹æ³•ï¼Œç„¶åé€šè¿‡ç›¸ä¼¼æ€§è¿›è¡Œä¸€ä¸ªæ’åˆ—ã€‚&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.vectorstores&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_documents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;documents&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;æ­¤æ—¶å°±å®Œæˆäº†å­˜å‚¨å’Œæ’åˆ—ã€‚&lt;/p&gt;
&lt;p&gt;è¿™é‡Œå‘é‡å­˜å‚¨ä¸€èˆ¬æ¥è¯´æ˜¯å¯ä»¥è¿æ¥åˆ°ç°æœ‰çš„Vector Storesä¸­çš„ã€‚&lt;/p&gt;
&lt;h3 id=&#34;usage&#34;&gt;Usage
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;æŸ¥è¯¢å’Œè¿™å¥è¯ç›¸ä¼¼çš„å¥å­&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Diffusion is a image generation method.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;å¼‚æ­¥æŸ¥è¯¢ï¼ˆç”¨äºæµç¨‹æ§åˆ¶ï¼‰&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asimilarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;è¿”å›åˆ†æ•°&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Note that providers implement different scores; &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# the score here is a distance metric that varies inversely with similarity.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_with_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is Diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Score: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;é€šè¿‡å’Œembedded queryçš„ç›¸ä¼¼åº¦è¿›è¡ŒæŸ¥è¯¢&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_by_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;retrievers&#34;&gt;Retrievers
&lt;/h3&gt;&lt;p&gt;æ£€ç´¢å™¨ï¼ˆRetrieverï¼‰å¯ä»¥ä»å‘é‡å­˜å‚¨ä¸­è¿›è¡Œæ„å»ºï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥å’Œéå‘é‡å½¢å¼è¿›è¡Œäº¤äº’ã€‚å¦‚æœæˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªèƒ½å¤Ÿæ£€ç´¢æ–‡æ¡£çš„æ–¹æ³•çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªrunnableçš„æ£€ç´¢å™¨ã€‚&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;typing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.documents&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.runnables&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is forward process?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;è‡³æ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿè¯»å¤šç¯‡PDFæ–‡ç« çš„ã€èƒ½å¤Ÿå¯¹PDFæ–‡ç« è¿›è¡ŒæŸ¥è¯¢çš„è¯­ä¹‰æœç´¢å¼•æ“ã€‚&lt;/p&gt;
&lt;h2 id=&#34;chat-modelså’Œpromptæ¨¡æ¿&#34;&gt;Chat Modelså’ŒPromptæ¨¡æ¿
&lt;/h2&gt;&lt;p&gt;è¿™é‡Œé€šè¿‡Vllmå¯åŠ¨LLMï¼Œä»¥Qwen2.5-7B-Instructæ¨¡å‹ä¸ºä¾‹ã€‚&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_community.llms&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/home/ubuntu/jjq/Qwen/Qwen2.5-7B-Instruct/&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;trust_remote_code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_new_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_model_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is the capital of France ?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;æ¥ä¸‹æ¥è®¾è®¡Promptæ¨¡æ¿ã€‚&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LLMChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.memory&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.chains&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts.chat&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ChatPromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SystemMessagePromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HumanMessagePromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;template&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        ã€ä»»åŠ¡æè¿°ã€‘
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        è¯·ä»”ç»†é˜…è¯»è®ºæ–‡ï¼Œå›ç­”ç”¨æˆ·ç»™å‡ºçš„é—®é¢˜ï¼Œå°½é‡å…·æœ‰æ‰¹åˆ¤æ€§ã€‚
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        ã€è®ºæ–‡ã€‘
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        {{context}}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        -----------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{question}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# æ£€ç´¢å™¨&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;as_retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# è®°å¿†&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;chat_history&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# æ„å»ºAgent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;question&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;èƒ½ä¸èƒ½ç”¨ä¸­æ–‡ç»™å‡ºè®ºæ–‡çš„ä¼˜åŠ¿æˆ–è€…å‰æ™¯ï¼Ÿ&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
