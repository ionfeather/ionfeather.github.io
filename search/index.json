[{"content":"论文阅读 | 多智能体协作机制：大语言模型综述\r[2306.03314] Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents\n摘要\r随着大语言模型（LLMs）的最新进展，代理式人工智能（Agentic AI）在现实应用中取得了显著进展，朝着基于多个大语言模型的智能体迈进，实现感知、学习、推理和协同行动。这些基于大语言模型的多智能体系统（MASs）使得一组智能体能够协作解决复杂任务，并以大规模方式实现集体行动，从孤立的模型转向以协作为核心的方法。\n本文提供了关于多智能体系统协作方面的广泛综述，并提出了一个可扩展的框架来指导未来的研究。我们的框架根据关键维度对协作机制进行表征：参与者（涉及的智能体）、类型（例如，合作、竞争或合作竞争）、结构（例如，点对点、集中式或分布式）、策略（例如，基于角色或基于模型）以及协调协议。通过对现有方法的回顾，我们的研究成果为揭示和推动基于大语言模型的多智能体系统向更加智能和协作的解决方案发展，特别是在复杂的现实应用中，提供了基础。\n此外，本文还探讨了多智能体系统在不同领域的各种应用，包括5G/6G网络、工业5.0、问答系统、以及社会文化环境，展示了它们的广泛应用和更深远的影响。最后，我们总结了关键经验教训，分析了多智能体系统面临的开放挑战，并指出了朝着人工集体智能发展的潜在研究方向。\n文章大纲\r应用\r方法 领域 主要贡献 优点 缺点 参考文献 LLM-SC 物联网 作为知识生成器增强语义解码器 利用大语言模型，实现显著的编码增益 由于使用大语言模型，计算资源需求高 [130] LaMoSC 物联网 提出一种大语言模型驱动的多模态融合语义通信 在低信噪比条件下表现稳健 由于使用大语言模型和视觉 Transformer，计算资源需求高 [157] LAM-MSC 物联网 为多模态数据设计联合编码器；大语言模型作为知识生成器 一个编码器和解码器可处理多种类型的数据；实现更好的编码率和重建误差 由于使用大语言模型，计算资源需求高 [65] GMAC 物联网 利用大语言模型实现观察状态与自然语言之间的语义对齐，并压缩语义信息 提高收敛速度；实现无通信的多智能体协作 由于使用大语言模型，计算资源需求高 [160] LLM-Blender 自然语言生成 采用多种大语言模型代理的集成方法进行候选排序 能够生成比现有候选更好的输出 为实现最优解，需要进行 O (n) 次推理，导致计算开销大 [64] SOT 自然语言生成 并行生成每个答案框架；完成答案内容（需要规划结构） 通过并行加速推理速度；适用于需要长结构答案的问题 答案质量评估远非完美，由于提示集有限；不同代理的并行请求可能会影响服务吞吐量 [95] Meta-Prompting 自然语言生成 构建高级元提示来指导大语言模型 保持连贯的推理思路；挖掘各种专家角色 多次模型调用成本较高；需要大量的规模和相当大的上下文窗口 [119] MAD 自然语言生成 两个代理表达各自的论点；一个评判者监控和管理辩论 减少偏差和扭曲的认知；鼓励无限的外部反馈 由于辩论时间长，计算成本高；大语言模型在长场景中难以保持连贯性和相关性 [77] FORD 自然语言生成 包括三个阶段的辩论：公平辩论、不匹配辩论、圆桌辩论 通过辩论让大语言模型探索自身理解与他人概念化之间的差异 除常识推理外，无法涵盖各种任务；严重依赖多项选择任务，限制了其泛化能力 [140] ChatDev 自然语言生成 采用聊天链将每个阶段分解为更小的子任务，实现代理之间的多轮通信，以协作开发解决方案 最大限度减少代码幻觉（提供的源代码缺失的情况） 没有清晰、详细的要求时，代理难以理解任务想法；通用软件的自动化评估非常复杂；多个代理需要更多的令牌和时间，导致计算需求大 [105] AgentVerse 自然语言生成 由专家招募、协作决策、行动执行、评估四个阶段组成 提高大语言模型在不确定情况下的泛化能力；提高代理的适应性 协作决策过程中代理之间的通信存在挑战 [24] AgentCoord 社会与文化领域 为协调策略提供结构化表示；采用三阶段方法将一般目标转化为可执行策略 简化协调策略的表示和探索；最小化代理的重复实例 仅支持在纯文本环境中协调代理协作；仅支持静态协调策略设计 [97] OpenAI\u0026rsquo;s Swarm 自然语言生成 用于多智能体编排的例程和交接；轻量级协调与执行框架 适用于需要可扩展性的应用；交接机制允许在专门代理之间实现无缝过渡 主要关注基于角色的协议和集中式 / 分布式结构；尚未准备好投入生产 见原文 TE 社会与文化领域 在主题研究中模拟人类参与者的代表性样本 能够模拟不同的人类行为，并揭示模拟中的一致偏差 需要研究更多的人类行为和额外的大语言模型，以确保关键发现的准确性 [36] AgentInstruct 社会与文化领域 通过迭代的跨代理细化生成多样化的自然语言数据，包括文化数据 能够通过工具使用、代理能力等从生成的数据中训练更强大的模型 需要人工构建生成流程 [88] SocialMind 社会与文化领域 整合言语、非言语和社交线索，通过增强现实眼镜生成现场建议 设计并利用多模态、多层协作代理系统 需要先进的边缘硬件来处理复杂系统 [144] CulturePark 社会与文化领域 促使基于大语言模型的代理进行跨文化交流模拟 生成的数据可用于训练具有不同文化背景的模型，减少偏差并实现民主化 仍然依赖大语言模型对每种文化的了解，因此对资源较少的文化效果有限 [73] Mango 社会与文化领域 通过对概念和文化的提示，从基于大语言模型的代理中提取高质量知识 自动化方法可生成大量资源 人类评估需要来自更多样化的背景 [94] 六个思考帽的设计\r白色思考帽\r功能：收集客观信息。 实现方式 对论文进行解析。 从论文文本中抽取结构化数据。 从网络中搜索作者之前的研究成果。 从网络中搜索同类研究的对比数据。 绿色思考帽\r功能：对论文提出创新性改进，探索论文的可能性 实现方式 未定。 黄色思考帽\r功能：积极角度评估论文，找出论文的优点和贡献。 实现方式 用优点和创新点微调后的大模型。 黑色思考帽\r功能：批判性思考，找出论文的问题和不足。 实现方式 用批判性数据集微调后的大模型。 红色思考帽\r功能：主观感受和直觉判断。 实现方式 让智能体多阅读论文，找到好的论文之间的共性和形成自己的「偏好」。 蓝色思考帽\r功能：控制评审流程。 实现方式 未定。 蓝色思考帽智能体应该如何控制？\r基于工作流管理的集中式控制方法。蓝色智能体明确规定了其他智能体的工作顺序、时间和交互方式。 基于协商机制的分布式控制方法。在评审开始时，蓝色智能体发起评审任务，各思考帽智能体根据自身能力和状态反馈可承担的工作及预计时间。比如白色告诉蓝色需要5分钟完成，绿色说在白色完成后需要10分钟\u0026hellip;通过这些反馈，蓝色智能体来制定计划。 基于事件驱动的动态控制方法。不同的智能体换成之后会触发不同的事件，如白色完成后让绿色工作，黑色和黄色在辩论后无法达成共识，就再次进行辩论等。这个事件定义较难。 ","date":"2025-02-15T21:58:31+08:00","permalink":"https://ionfeather.github.io/p/multiagentcollaboration/","title":"论文阅读 | 多智能体协作机制：大语言模型综述"},{"content":"雨水：表示降水开始，雨量逐步增多。雨水节气天气变化不定，是全年寒潮过程出现最多的时节之一，忽冷忽热，天气乍暖还寒。\n北京最近的天气确实是这样。在北京能感受到24节气的准确，能感受到四季分明是什么感觉。\n但是！！雨水，雨水，北京来点儿雨吧。自从去年的12月以来，我没有见过一滴雨落到北京的地表，这里的晴天就像是默认背景，太阳和月亮每天都是固定角色出现在地平线和天空中。北京的「雨水」是艳阳高照。\n絮絮叨叨\r上了研究生学术没有做多少，兴趣爱好培养了不少——台球、博客、摄影、健身…可能还打算学个吉他和乒乓球。忙不过来，实在是忙不过来了。还是得多放点时间在学习上呀。\n今天是情人节，这么一想，晚上的健身房应该会比较空，可惜昨天跑步跑太狠，把脚掌磨出了一个水泡，走路都有点儿疼，今晚回去可以做做力量训练，就先不做有氧了。\n好羡慕甜甜的爱情。\n2025-02-14 15:02\n买了辆电瓶车，之后出行方便多了。 终于不用来回奔波那么久了。 去地铁站终于不用思考用共享单车还是公交车了。\n2025-02-14 21:58\n今天把原先的房子里的东西全部打扫干净，让它恢复成原来的样子。我才意识到，虽然住了半年，但是我们在这个房子里的印记能在一天之内被打扫得无影无踪。原来人是流动的水。\n和室友买了一些做饭的家伙，之后可能会在出租房里（我其实也愿意称它为「家」）做一些简单的菜。室友的女友可能过两天会来，到时候可以期待一下她的厨艺（好像听说也是新手，那还是期待我自己的进步吧\n上了称，感觉自己胖得不行了。但是过两天又是组会，头疼，我这周什么也没干。\n2025-02-15 19:26\n房东来看房，她（果然）嫌弃我们打扫得不干净，表示要找保洁来清理。MSY、SH和我商量了一下，最后让她扣了300元。我该怎么说——其实这个人还算好说话。反正扣完了之后也没说什么，现场就转了钱。我本来还以为她会拿门钥匙这件事说事。\n帽子到啦！我的MBTI帽子到了，我直接往上贴了一个「ENFP」，然后周游工位告诉每个见到我的人，可惜今天是周日，没见到几个人。大家都去哪儿啦？\n不过感觉自己也不用担心（什么担心，我这叫好奇）大家都去哪儿了。明天就是组会，目前还没有进展，现在就开始看论文吧！\n2025-02-16 13:35\n","date":"2025-02-14T14:36:39+08:00","permalink":"https://ionfeather.github.io/p/rainwater/","title":"雨水 | 北京的「雨水」是艳阳高照"},{"content":"春节快乐！\n工科研究生的假期有点短暂了。我已经回校了。\n到学校了感觉自己好多东西需要购置。Apple Watch的表带现在明显太松了，但是官方太贵，第三方又有点儿硬，计划看一下Bilibili上的测评，进行一波购置。还有看上了影视飓风的一款帽子，上面可以贴上你的mbti，这对我这个enfp根本无法拒绝。\n又来到了北方，又遇到了高铁上一望无际的平原，感觉是另一种大海，在这片海里，有冰封的河流，有枯黄的树枝，还有炊烟和蜗居的人们。有一种说法是南方人向往雪，北方人向往海，这么一看，我应该是个不那么彻底的南方人。我两个都很向往。\n今天是元宵节，我本科的时候是灯谜社社长。元宵节，英语叫Lantern festival，也就是灯节，是灯谜社最重要的节日。在传统文化节里，我会张贴灯谜，擂起鼓，在鼓声滚滚中，同学需要猜出我出的谜题——有些是我们社团自己写的，所以很难猜，需要脑子有点儿回路，特别是与英雄联盟或者是与本科学校相关的那种谜题。\n虽然现在天气还很冷，但是感觉春意渐浓，即便树梢仍然枯枝，阳光灿烂的时候也能把寒意给驱散。\n我已经开始期待春天了。玉兰、银柳、山茶、樱花、樱桃花、木绣球、垂丝海棠。我要抄起我的相机，出门拍花拍鸟。\n不管怎么说，虽然已经上了几年（学校一年，外界一天）班了，现在还是春节期间，我一会儿说不定可以出门，去颐和园旁边拍花灯。\n","date":"2025-02-12T17:51:19+08:00","image":"https://ionfeather.github.io/p/lanternfestival/cover_hu10283662063726621985.jpg","permalink":"https://ionfeather.github.io/p/lanternfestival/","title":"元宵节 | 东风夜放花千树，更吹落、星如雨"},{"content":"之前一直在用Typora来写文章，发现有的时候也太难用了，不仅插件少，还要付费。这个时候看到很多的博客都用Obsidian来写，不得不心动了。\nObsidian的插件\rLinter\rObsidian Linter插件：打造统一、美观的笔记环境 - 知乎\n我不得不赞赏一下这个Linter，真的很好用，格式化目前的Markdown内容一直是我的心头痒，对于我这个强迫症来说，现在只需要按一下Ctrl+S就可以让我的敲击的内容都非常规范化，这实在是伟大的发明。\nExcalidraw\r这个插件还挺好看的，可以绘制手绘风格的图像，我绘制一些想法会更加方便。\n其他\rAdvanced Tables：对写表格比较有帮助。 Customizable Menu：自定义右键快捷键。 ","date":"2025-02-12T15:59:30+08:00","permalink":"https://ionfeather.github.io/p/obsidian/","title":"使用Obsidian来写博客"},{"content":"全书结构\r预备知识\r张量\r张量表示一个由数值组成的数组，这个数组可能有多个维度。\n具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。\n张量的创建\rimport torch x = torch.arange(12) x.shape x.numel() X = x.reshape(3, 4) torch.zeros((2, 3, 4)) torch.ones((2, 3, 4)) torch.randn(3, 4) torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) 运算符\r按元素运算\r常见的运算符这里用作按元素运算。\nx = torch.tensor([1.0, 2, 4, 8]) y = torch.tensor([2, 2, 2, 2]) x + y, x - y, x * y, x / y, x ** y # **运算符是求幂运算 可以得到\n(tensor([ 3., 4., 6., 10.]), tensor([-1., 0., 2., 6.]), tensor([ 2., 4., 8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1., 4., 16., 64.])) 还有很多的一元运算符都可以用在按元素运算。\n线性代数运算\r求和/平均值\r直接调用sum函数，会将其变成一个标量，也可以指定axis = 1维度来指定轴来进行降维。\nA.sum() A.sum(axis = 1) A.sum(axis = [0, 1])# 对于矩阵来说，相当于A.sum() 同理，A.mean()也是一样的。\n如果希望能够在求和或者平均值的时候保持轴数不变，可以使用keepdims = True。\n如果希望能够沿着某个轴计算A元素的累计总和，可以使用cumsum函数。\nsum_A = A.sum(axis=1, keepdims=True) A.cumsum(axis=0) 点积\rx = torch.arange(4) y = torch.ones(4, dtype = torch.float32) torch.dot(x, y) 矩阵-向量积\r当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。 注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n矩阵-矩阵乘法\r我们可以将矩阵-矩阵乘法AB看作简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n×m矩阵。\n在下面的代码中，我们在A和B上执行矩阵乘法。 这里的A是一个5行4列的矩阵，B是一个4行3列的矩阵。 两者相乘后，我们得到了一个5行3列的矩阵。\nB = torch.ones(4, 3) torch.mm(A, B) 张量连结\r在这里，dim=0说明是第一个维度进行拼接；dim=1说明是第二个维度进行拼接。\nX = torch.arange(12, dtype=torch.float32).reshape((3,4)) Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1) 广播机制\r特别需要注意这个，可能会导致错误发生。\na = torch.arange(3).reshape((3, 1)) b = torch.arange(2).reshape((1, 2)) a, b 由于a和b分别是3×1和1×2矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵广播为一个更大的3×2矩阵，如下所示：矩阵a将复制列， 矩阵b将复制行，然后再按元素相加。\n索引和切片\r与Dataframe中相似。\n节省内存\r如果直接使用X = X + Y就是重新创建一个元素。但是，有些时候希望执行原地操作。\n如果希望执行原地操作的话，可以使用两种方式，此时不会占用新的空间：\nX[:] = X + Y X += Y 转换为其他对象\r转换为Numpy非常容易：A = X.numpy()\n转换为Python标量：a.item()或者使用内置函数float(a)等。\n自动求导\r自动求导是计算一个函数在指定值上的导数。\n如何实现？ 计算图：将代码分解成操作子，将计算表示成一个无环图。 关于计算图，有显式构造 vs 隐式构造两种构造方式。\n特性 显式构造 隐式构造 计算图构建方式 显式定义 隐式定义 计算图类型 静态图 动态图 典型框架 TensorFlow 1.x, Theano PyTorch, TensorFlow 2.x (Eager) 有两种求导的方式，对于一个链式法则，我们可以采取正向累积和反向累积（也称反向传递）。\n**使用反向传递的时候，在我们计算y关于x的梯度之前，需要一个地方来存储梯度。**重要的是，我们不会在每次对一个参数求导时都分配新的内存。 因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。 注意，一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。\n","date":"2025-01-08T16:00:34+08:00","image":"https://ionfeather.github.io/p/d2l-01/pics/cover_hu3492737127834985036.png","permalink":"https://ionfeather.github.io/p/d2l-01/","title":"课程学习 | 《动手学深度学习》"},{"content":"虚拟环境配置经历\r我之前配置好了一个虚拟环境名为vllm，专门用于vllm的启动，我还特意将其中的虚拟环境中的所有包的版本保存到vllm_requirements.txt文件中。\n但是我一顿操作之后，原本配置好的环境现在也没办法使用了。此时我庆幸自己想到用vllm_requirements.txt文件保存。但是在进行pip install -r vllm_requirements.txt的时候，出现了报错的情况，竟然说里面有一个包的版本是yanked version（撤回版本），无法下载，给我气晕了。\n吃一堑，长一智。配置好的环境就不要变了，应该另外复制一个环境，在复制的环境上进行修改。\n此外，我每次进行配置环境我都会忘记怎么配置和删除。是我最近记性变得太差了吗？总之我写一个文档，记不住就查一下。\n配置环境\r使用conda配置虚拟环境\r创建新的环境\r使用Terminal创建新的环境。\nconda create -n \u0026lt;new_env_name\u0026gt; python=3.10.0 激活虚拟环境\nconda activate \u0026lt;new_env_name\u0026gt; 安装包\nconda install \u0026lt;package\u0026gt; pip install \u0026lt;package\u0026gt; 从已有的文件中安装包/虚拟环境\r如果想要安装requirements.txt文件，就可以直接\npip install -r requirements.txt 如果想要安装的是environment.yml文件，应该改用conda来创建虚拟环境\nconda env create -f environment.yml 查看虚拟环境列表\nconda env list 复制原来已有的虚拟环境\r如果有一个环境已经配置好，我不希望破坏它，可以复制一个一模一样的环境，再在上面进行修改，这样就不会导致原来那个环境产生问题。\nconda create --name \u0026lt;new_env_name\u0026gt; --clone \u0026lt;old_env_name\u0026gt; 删除虚拟环境\r删除指定的虚拟环境\nconda activate base conda remove -n \u0026lt;env_name\u0026gt; --all 在conda中配置Jupyter内核\r安装Jupyter内核\r总是忘记Jupyter内核如何配置。记录一下：\n安装ipykernel。\nconda install ipykernel 将虚拟内核添加到jupyter内核中。\npython -m ipykernel install --user --name \u0026lt;your_env_name\u0026gt; 删除jupyter内核\r查看目前有的jupyter内核\njupyter kernelspec list 删除指定的jupyter内核\njupyter kernelspec remove \u0026lt;your_kernel_name\u0026gt; 照片\r照片是2024/12/7的时候同门团建的时候我拿大疆Pocket3拍的。拍的建筑是东郊民巷的圣弥厄尔大教堂。非常开心的一天。\n","date":"2024-12-15T20:24:19+08:00","image":"https://ionfeather.github.io/p/virtual-environment-config/cover_hu15097618714508979196.jpg","permalink":"https://ionfeather.github.io/p/virtual-environment-config/","title":"配置记录 | 虚拟环境配置操作记录"},{"content":"为什么要学习LangChain\r我希望能够构建一个能阅读PDF论文的Agent，并且能够输出对论文优缺点的评价。\n导师\u0026nbsp;\u0026nbsp;\u0026nbsp;2024-10-12 14:30\r做一个论文阅读的大模型。 2024-10-12 14:45\u0026nbsp;\u0026nbsp;\u0026nbsp;我\r好的老师。 使用LangChain听说比较方便。\nLangChain是用来做什么的？\rLangChain是一个用于开发由LLM驱动的应用程序的框架。也就是说我们可以把LLM作为内核，LangChain作为外壳，搭建一个程序出来。\nLangChain提供了\n组件：处理LLM的组件的抽象； 定制链：把组件拼起来，实现一个特定用例。 对于阅读PDF，目前有两个想法：\n将PDF转为JSON，然后输入到LLM中； 构建RAG。使用LangChain能够比较方便地实现这个功能，听ZLB说这个也不是很难。我之前的畏难情绪可能太重了，现在写一个文档，激励和记录一下自己学习。 RAG是什么？\r虽然LLM非常强大，但它们对于它们未经训练的信息一无所知。如果您想使用LLM来回答它未经训练的文档相关问题，您需要向其提供这些文档的信息。最常用的方法是通过“检索增强生成”（ retrieval augmented generation，RAG ）。\n检索增强生成的思想是，在给定一个问题时，首先进行检索步骤以获取任何相关文档。然后将这些文档与原始问题一起传递给语言模型，并让它生成一个回答。然而，为了做到这一点，首先需要将文档以适合进行此类查询的格式呈现。\n构造一个语义搜索引擎\rBuild a semantic search engine | 🦜️🔗 LangChain\n读取PDF\rHow to load PDFs | 🦜️🔗 LangChain\n这里，文档中推荐使用了pypdf库。这里\n在实际应用中可以使用其他提取效果更好的库。LangChain支持的PDF格式很多，可以选择一下。\nDocument Loader Description Package/API PyPDF Uses pypdf to load and parse PDFs Package Unstructured Uses Unstructured\u0026rsquo;s open source library to load PDFs Package Amazon Textract Uses AWS API to load PDFs API MathPix Uses MathPix to load PDFs Package PDFPlumber Load PDF files using PDFPlumber Package PyPDFDirectry Load a directory with PDF files Package PyPDFium2 Load PDF files using PyPDFium2 Package PyMuPDF Load PDF files using PyMuPDF Package PDFMiner Load PDF files using PDFMiner Package 此外，导师之前还给我推荐了titipata/scipdf_parser库，能够更好地处理图像和扫描文本，并且运行在docker上，便于部署。\npypdf的介绍\rWelcome to pypdf — pypdf 5.1.0 documentation\nPyPDF 是一个用于处理 PDF 文件的 Python库。它提供了一组工具和功能，用于读取、解析和操作 PDF 文件的内容。\nSplitting\r原文\rFor both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve Document objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not \u0026ldquo;washed out\u0026rdquo; by surrounding text.\nWe can use text splitters for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\nWe set add_start_index=True so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”.\nSee this guide for more detail about working with PDFs, including how to extract text from specific sections and images.\n对于问题提问的文本来说，直接回答一整页肯定是太粗略了。我们最终的目标是检索回答输入查询的文档对象，进一步拆分 PDF 将有助于确保文档相关部分的含义不会被周围的文本“冲淡”。\n所以接下来应该用文本分割器来进行分割（Splitting）处理。这里用一个RecursiveCharacterTextSplitter进行分割。这里使用常见分隔符来对文档进行分割，适用于一般的文本。\n使用RecursiveCharacterTextSplitter无法读取图像或特定区域的文本。\nEmbeddings\r接下来将文本嵌入到向量中去，便于进行相似度指标来识别相关文本。\n这里LangChain支持数十种Embeddings方法。这里我选择了使用Hugging Face，可以选择将模型下载至本地或者使用Hugging Face Inference API来调用接口。这里可以直接使用HuggingFaceEmbeddings来进行处理。非常方便。\nfrom langchain_huggingface import HuggingFaceEmbeddings embeddings_model = HuggingFaceEmbeddings(model_name=\u0026#34;sentence-transformers/all-mpnet-base-v2\u0026#34;) embeddings = embeddings_model vector_1 = embeddings.embed_query(all_splits[0].page_content) vector_2 = embeddings.embed_query(all_splits[1].page_content) assert len(vector_1) == len(vector_2) print(f\u0026#34;Generated vectors of length {len(vector_1)}\\n\u0026#34;) print(vector_1[:10]) Vector Stores\rLangChain的Vector Stores对象包括了一些把文本和Document对象加入到Stores中的方法，然后通过相似性进行一个排列。\nfrom langchain_core.vectorstores import InMemoryVectorStore vector_store = InMemoryVectorStore(embeddings) ids = vector_store.add_documents(documents=all_splits) 此时就完成了存储和排列。\n这里向量存储一般来说是可以连接到现有的Vector Stores中的。\nUsage\r查询和这句话相似的句子 results = vector_store.similarity_search( \u0026#34;Diffusion is a image generation method.\u0026#34; ) ) print(results[0]) 异步查询（用于流程控制） results = await vector_store.asimilarity_search(\u0026#34;What is diffusion?\u0026#34;) print(results[0]) 返回分数 # Note that providers implement different scores; # the score here is a distance metric that varies inversely with similarity. results = vector_store.similarity_search_with_score(\u0026#34;What is Diffusion?\u0026#34;) doc, score = results[0] print(f\u0026#34;Score: {score}\\n\u0026#34;) print(doc) 通过和embedded query的相似度进行查询 embedding = embeddings.embed_query(\u0026#34;What is diffusion\u0026#34;) results = vector_store.similarity_search_by_vector(embedding) print(results[0]) Retrievers\r检索器（Retriever）可以从向量存储中进行构建，但是也可以和非向量形式进行交互。如果我们要构建一个能够检索文档的方法的话，我们可以创建一个runnable的检索器。\nfrom typing import List from langchain_core.documents import Document from langchain_core.runnables import chain @chain def retriever(query: str) -\u0026gt; List[Document]: return vector_store.similarity_search(query, k=1) retriever.batch( [ \u0026#34;What is diffusion?\u0026#34;, \u0026#34;What is forward process?\u0026#34;, ], ) 至此，我们构建了一个能够读多篇PDF文章的、能够对PDF文章进行查询的语义搜索引擎。\nChat Models和Prompt模板\r这里通过Vllm启动LLM，以Qwen2.5-7B-Instruct模型为例。\nfrom langchain_community.llms import VLLM llm = VLLM(model=\u0026#34;/home/ubuntu/jjq/Qwen/Qwen2.5-7B-Instruct/\u0026#34;, trust_remote_code=True, max_new_tokens=512, top_k=10, top_p=0.95, temperature=0.8, max_model_len = 30000, ) print(llm(\u0026#34;What is the capital of France ?\u0026#34;)) 接下来设计Prompt模板。\nfrom langchain import LLMChain from langchain.prompts import PromptTemplate from langchain.memory import ConversationBufferMemory from langchain.chains import ConversationalRetrievalChain from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate template = \u0026#39;\u0026#39;\u0026#39; 【任务描述】 请仔细阅读论文，回答用户给出的问题，尽量具有批判性。 【论文】 {{context}} ----------- {question} \u0026#39;\u0026#39;\u0026#39; # 检索器 retriever = db.as_retriever() # 记忆 memory = ConversationBufferMemory(memory_key=\u0026#34;chat_history\u0026#34;, return_messages=True) # 构建Agent qa = ConversationalRetrievalChain.from_llm(llm, retriever, memory=memory) qa({\u0026#34;question\u0026#34;: \u0026#34;能不能用中文给出论文的优势或者前景？\u0026#34;}) ","date":"2024-11-26T13:45:58+08:00","image":"https://ionfeather.github.io/p/langchain-learning/cover_hu13968487782357828171.png","permalink":"https://ionfeather.github.io/p/langchain-learning/","title":"学习笔记 | LangChain学习笔记"},{"content":"梦\r这是一个英雄辈出的时代。所谓阴阳师，就是使用牌组与其他人对战来决定胜负的职业。在这里，国之阴阳师是一国中最强的阴阳师，中日韩三国每年都会选拔国之阴阳师，并且对战，决出最后的冠军。\n我和梦梦是青梅竹马，从小便展露了阴阳师的天赋。所谓“绕床弄青梅，郎骑竹马来”，我和梦梦那就是“绕床打牌组，郎打牌组来”。从小与其他人对战，胜利了之后可以选择是否获取一张新卡\n牌放进自己的卡组，最终打一个最强者之间的对战。这个对战从来都是我和梦梦之间的私人聊天与沟通时间。\n随着我们渐渐长大，我和梦梦之间也互生情愫。但是，认真打牌，赢得中日韩三国之间的对战，获得至高无上的荣耀是我们的最大目标。儿女情长，英雄气短，阴阳师需要克制。\n……\n梦梦要去日本打探消息了。她去那里，是为了我们中国能够更了解日本的特殊卡牌。可是，一个人在异国他乡，离开最亲近的人，是那么容易的事情吗？\n终于到了中日韩会赛的时间。\n我期待着到达了梦梦的住所，敲门，迎接我的果然是笑靥如花的梦梦。我们见到对方，思念已久的澎湃难抑制，但我们都克制住了自己，只是眼睛里互相诉说着彼此。\n但梦梦的房间里有股不详的气息。她好像被监视了。“你的房间里曾经有过一个男人躲在里面”，我说。\n梦梦害怕极了，但为了国家能够去刺探信息的人必然非常坚强，她脸色发白，不住地颤抖，但声音很小：“还在吗……这怎么办…”\n我安慰她：“这没什么，这是日本人监视你的手段，但梦梦你肯定也有没被看破的地方。”随后我离开了梦梦的家，脸色发青。\n……\n接下来就是我和八重岛神子最终对战了。近几年韩国式微，只剩中日交战。日本去年赢过了我国。去年对战使用的是30张左右的小牌组，打到后面基本就是6张左右一个循环，对方的强度比我们高。\n八重岛神子太强了，所有人都不相信我能打败他，包括我自己。我用尽心血，准备了一套120张卡牌的超大牌组进行对战。奇妙的是，八重岛神子也拿出来120张的卡组。这极其少见。我们来了一场古典的交锋。\n……\n突然，我想起之前在什么地方，在很久很久的从前，有个人和我说我会赢的，于是我便充满了信心，我的阴霾一扫而空。\n我尽量诚实地描述了我的梦境，可惜忘记了太多。我感觉里面有蛮多意象的。围棋中日韩会战、恋爱、谍战监视、杀戮尖塔烧牌循环、炉石传说对战\u0026hellip;很有意思的一个梦，醒来之后回味了很久。但是看起来可能没有那么有趣，或许我应该加一点戏剧性要素？\n照片\r照片是我2024/11/3的时候在地坛拍的。我想那一天是北京秋天最美的一天。北京的秋天是短暂的，11/3之前雾霾太重，看什么都朦胧；11/3那天的风很大，无数灿烂的叶子不断地落下来，在这一天之后，树梢上就稍微有一些秃了。\n","date":"2024-10-20T13:45:58+08:00","image":"https://ionfeather.github.io/p/dream/cover_hu13768060218741915990.jpg","permalink":"https://ionfeather.github.io/p/dream/","title":"一个有趣的梦 | 三国阴阳师"}]