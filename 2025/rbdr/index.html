<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="Reasoning-based drug repurposing\r问题&amp;回答\r问题\rLLM在Repurposing中的应用情况 是否有基于文本结构，引入大模型知识作为一部分特征？ 测试集是什么 传统模型/基于网络的模型的准确率 回答\r有两种情况。第一种，引入LLM后的文本信息作为向量嵌入到GNN中；第二种，LLM作为筛选数据的方法，从数据层面提升最终效果。 有的。将文本以特定的形式组织，如&quot;药物A[SEP]疾病B&quot;，然后将其变成向量，嵌入到GNN中。 阅读了几篇，测试集有 B-dataset（SCMFDD-S/L）：来自于 Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了 SCMFDD-S 和 SCMFDD-L 数据集，其中的前者是这里的 B-dataset，适用于常规场景。 C-dataset：来自于 Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic，由 Dndataset 和 F-dataset 整合而成，结合了药物的 ATC 编码和疾病的 DO 术语。包含 963 种药物、1263 种疾病和 54921 个药物-疾病关系。适用于多源数据融合场景。 F-dataset：来自于 PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology，侧重于模型对文本知识的分析能力。 R-dataset：整合 C-dataset、F-dataset 和 KEGG 数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。 模型准确率在不同的数据集上不同。这里的B、C、F数据集使用得比较多，一般来说衡量标准是AUC、AUPR、F1-score和Precision。 Action\rWeek\rweek1\n">
<title>AIDR | Reasoning-based Drug Repurposing</title>

<link rel='canonical' href='https://ionfeather.github.io/2025/rbdr/'>

<link rel="stylesheet" href="/scss/style.min.2cfa7d4d97708a53c06f556ef76da6ee0bc81f123ed7faedca445f99cd866bde.css"><meta property='og:title' content="AIDR | Reasoning-based Drug Repurposing">
<meta property='og:description' content="Reasoning-based drug repurposing\r问题&amp;回答\r问题\rLLM在Repurposing中的应用情况 是否有基于文本结构，引入大模型知识作为一部分特征？ 测试集是什么 传统模型/基于网络的模型的准确率 回答\r有两种情况。第一种，引入LLM后的文本信息作为向量嵌入到GNN中；第二种，LLM作为筛选数据的方法，从数据层面提升最终效果。 有的。将文本以特定的形式组织，如&quot;药物A[SEP]疾病B&quot;，然后将其变成向量，嵌入到GNN中。 阅读了几篇，测试集有 B-dataset（SCMFDD-S/L）：来自于 Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了 SCMFDD-S 和 SCMFDD-L 数据集，其中的前者是这里的 B-dataset，适用于常规场景。 C-dataset：来自于 Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic，由 Dndataset 和 F-dataset 整合而成，结合了药物的 ATC 编码和疾病的 DO 术语。包含 963 种药物、1263 种疾病和 54921 个药物-疾病关系。适用于多源数据融合场景。 F-dataset：来自于 PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology，侧重于模型对文本知识的分析能力。 R-dataset：整合 C-dataset、F-dataset 和 KEGG 数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。 模型准确率在不同的数据集上不同。这里的B、C、F数据集使用得比较多，一般来说衡量标准是AUC、AUPR、F1-score和Precision。 Action\rWeek\rweek1\n">
<meta property='og:url' content='https://ionfeather.github.io/2025/rbdr/'>
<meta property='og:site_name' content='ionfeather&#39;Log'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='AI4Science' /><meta property='article:tag' content='AIDR' /><meta property='article:published_time' content='2025-06-10T14:24:22&#43;08:00'/><meta property='article:modified_time' content='2025-06-10T14:24:22&#43;08:00'/>
<meta name="twitter:title" content="AIDR | Reasoning-based Drug Repurposing">
<meta name="twitter:description" content="Reasoning-based drug repurposing\r问题&amp;回答\r问题\rLLM在Repurposing中的应用情况 是否有基于文本结构，引入大模型知识作为一部分特征？ 测试集是什么 传统模型/基于网络的模型的准确率 回答\r有两种情况。第一种，引入LLM后的文本信息作为向量嵌入到GNN中；第二种，LLM作为筛选数据的方法，从数据层面提升最终效果。 有的。将文本以特定的形式组织，如&quot;药物A[SEP]疾病B&quot;，然后将其变成向量，嵌入到GNN中。 阅读了几篇，测试集有 B-dataset（SCMFDD-S/L）：来自于 Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了 SCMFDD-S 和 SCMFDD-L 数据集，其中的前者是这里的 B-dataset，适用于常规场景。 C-dataset：来自于 Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic，由 Dndataset 和 F-dataset 整合而成，结合了药物的 ATC 编码和疾病的 DO 术语。包含 963 种药物、1263 种疾病和 54921 个药物-疾病关系。适用于多源数据融合场景。 F-dataset：来自于 PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology，侧重于模型对文本知识的分析能力。 R-dataset：整合 C-dataset、F-dataset 和 KEGG 数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。 模型准确率在不同的数据集上不同。这里的B、C、F数据集使用得比较多，一般来说衡量标准是AUC、AUPR、F1-score和Precision。 Action\rWeek\rweek1\n">
    <link rel="shortcut icon" href="/ion.ico" />

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap"
    onload="this.media='all'" onError="this.media='none'">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@callmebill/lxgw-wenkai-web@latest/style.css"
    onload="this.media='all'" onError="this.media='none'">

  <style>
     
    :root {
      --sys-font-family: 'LXGW WenKai', 'Noto Serif SC', serif;
      --zh-font-family: 'LXGW WenKai', 'Noto Serif SC', serif;
      --base-font-family: 'LXGW WenKai', 'Noto Serif SC', serif;
      --code-font-family: 'Consolas', monospace; 
      --article-font-family: 'Noto Serif SC', serif; 
      --heading-font-family: 'LXGW WenKai', serif; 
    }

     
    body {
      font-family: var(--base-font-family);
      font-weight: normal;
    }
  </style>
</head>

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu_7d702df343b40e37.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">🌳</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">ionfeather&#39;Log</a></h1>
            <h2 class="site-description">十年饮冰，难凉热血</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/ionfeather'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg t="1732597946058" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3746" width="24" height="24"><path d="M850.346667 155.008a42.666667 42.666667 0 0 0-22.741334-23.509333c-8.704-3.754667-85.717333-33.322667-200.32 39.168H396.714667c-114.773333-72.618667-191.701333-42.922667-200.32-39.168a42.88 42.88 0 0 0-22.741334 23.466666c-26.197333 66.218667-18.048 136.448-7.850666 176.896C134.272 374.016 128 413.098667 128 469.333333c0 177.877333 127.104 227.882667 226.730667 246.272a189.568 189.568 0 0 0-13.013334 46.549334A44.373333 44.373333 0 0 0 341.333333 768v38.613333c-19.498667-4.138667-41.002667-11.946667-55.168-26.112C238.08 732.416 188.330667 682.666667 128 682.666667v85.333333c25.002667 0 65.365333 40.362667 97.834667 72.832 51.029333 51.029333 129.066667 55.253333 153.386666 55.253333 3.114667 0 5.376-0.085333 6.528-0.128A42.666667 42.666667 0 0 0 426.666667 853.333333v-82.090666c4.266667-24.746667 20.224-49.621333 27.946666-56.362667a42.666667 42.666667 0 0 0-23.125333-74.581333C293.333333 624.554667 213.333333 591.488 213.333333 469.333333c0-53.12 5.632-70.741333 31.573334-99.285333 11.008-12.117333 14.08-29.568 7.978666-44.8-4.821333-11.904-18.773333-65.450667-6.485333-117.546667 20.650667-1.578667 59.904 4.565333 113.706667 40.96C367.104 253.44 375.466667 256 384 256h256a42.666667 42.666667 0 0 0 23.936-7.338667c54.016-36.522667 92.970667-41.770667 113.664-41.130666 12.330667 52.224-1.578667 105.770667-6.4 117.674666a42.666667 42.666667 0 0 0 8.021333 44.928C805.077333 398.464 810.666667 416.085333 810.666667 469.333333c0 122.581333-79.957333 155.52-218.069334 170.922667a42.666667 42.666667 0 0 0-23.125333 74.709333c19.797333 17.066667 27.861333 32.469333 27.861333 53.034667v128h85.333334v-128c0-20.437333-3.925333-38.101333-9.770667-53.12C769.92 695.765333 896 643.712 896 469.333333c0-56.362667-6.272-95.530667-37.76-137.514666 10.197333-40.405333 18.261333-110.506667-7.893333-176.810667z" fill="currentColor" p-id="3747"></path></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='mailto:lizishadowmay@gmail.com'
                        target="_blank"
                        title="Email"
                        rel="me"
                    >
                        
                        
                            <svg t="1732597869588" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23464" width="24" height="24"><path d="M926.47619 355.644952V780.190476a73.142857 73.142857 0 0 1-73.142857 73.142857H170.666667a73.142857 73.142857 0 0 1-73.142857-73.142857V355.644952l73.142857 62.000762V780.190476h682.666666V417.645714l73.142857-62.000762zM853.333333 170.666667a74.044952 74.044952 0 0 1 26.087619 4.778666 72.704 72.704 0 0 1 30.622477 22.186667 73.508571 73.508571 0 0 1 10.678857 17.67619c3.169524 7.509333 5.12 15.652571 5.607619 24.210286L926.47619 243.809524v24.380952L559.469714 581.241905a73.142857 73.142857 0 0 1-91.306666 2.901333l-3.632762-2.925714L97.52381 268.190476v-24.380952a72.899048 72.899048 0 0 1 40.155428-65.292191A72.97219 72.97219 0 0 1 170.666667 170.666667h682.666666z m-10.971428 73.142857H181.638095L512 525.58019 842.361905 243.809524z" p-id="23465" fill="currentColor"></path></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='index.xml'
                        target="_blank"
                        title="RSS"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 1024 1024" width="200" height="200">
  <path 
    d="M170.666667 426.666667c-25.6 0-42.666667 17.066667-42.666667 42.666666s17.066667 42.666667 42.666667 42.666667c187.733333 0 341.333333 153.6 341.333333 341.333333 0 25.6 17.066667 42.666667 42.666667 42.666667s42.666667-17.066667 42.666666-42.666667c0-234.666667-192-426.666667-426.666666-426.666666z"
    stroke="currentColor"
    fill="currentColor"
    stroke-width="0"
  ></path>
  <path 
    d="M170.666667 128c-25.6 0-42.666667 17.066667-42.666667 42.666667s17.066667 42.666667 42.666667 42.666666c354.133333 0 640 285.866667 640 640 0 25.6 17.066667 42.666667 42.666666 42.666667s42.666667-17.066667 42.666667-42.666667c0-401.066667-324.266667-725.333333-725.333333-725.333333z"
    stroke="currentColor"
    fill="currentColor"
    stroke-width="0"
  ></path>
  <path 
    d="M213.333333 810.666667m-85.333333 0a85.333333 85.333333 0 1 0 170.666667 0 85.333333 85.333333 0 1 0-170.666667 0Z"
    stroke="currentColor"
    fill="currentColor"
    stroke-width="0"
  ></path>
</svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%85%B3%E4%BA%8E/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>关于</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>归档</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%8F%8B%E9%93%BE/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>友链</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            

                
                    <span id="dark-mode-toggle">
                        <svg  xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left"   width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828a4 4 0 1 0 -5.656 -5.656a4 4 0 0 0 5.656 5.656z" /><path d="M6.343 17.657l-1.414 1.414" /><path d="M6.343 6.343l-1.414 -1.414" /><path d="M17.657 6.343l1.414 -1.414" /><path d="M17.657 17.657l1.414 1.414" /><path d="M4 12h-2" /><path d="M12 4v-2" /><path d="M20 12h2" /><path d="M12 20v2" /></svg>
                        <svg  xmlns="http://www.w3.org/2000/svg"  class="icon icon-tabler icon-tabler-toggle-right"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-moon"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" /></svg>
                    </span>
                
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#reasoning-based-drug-repurposing">Reasoning-based drug repurposing</a>
      <ol>
        <li><a href="#问题回答">问题&amp;回答</a>
          <ol>
            <li><a href="#问题">问题</a></li>
            <li><a href="#回答">回答</a></li>
          </ol>
        </li>
        <li><a href="#action">Action</a>
          <ol>
            <li><a href="#week">Week</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#相关论文调研">相关论文调研</a>
      <ol>
        <li><a href="#llm-dda">LLM-DDA</a>
          <ol>
            <li><a href="#问题与回答">问题与回答</a></li>
            <li><a href="#解决的问题">解决的问题</a></li>
            <li><a href="#面临挑战">面临挑战</a></li>
            <li><a href="#核心方法">核心方法</a></li>
            <li><a href="#数据集">数据集</a></li>
            <li><a href="#指标结果">指标结果</a></li>
          </ol>
        </li>
        <li><a href="#lbmff">LBMFF</a>
          <ol>
            <li><a href="#问题与回答-1">问题与回答</a></li>
            <li><a href="#解决的问题-1">解决的问题</a></li>
            <li><a href="#面临的挑战">面临的挑战</a></li>
            <li><a href="#核心方法-1">核心方法</a></li>
            <li><a href="#研究结果">研究结果</a></li>
          </ol>
        </li>
        <li><a href="#llm进行阴性数据标注">LLM进行阴性数据标注</a>
          <ol>
            <li><a href="#问题与回答-2">问题与回答</a></li>
            <li><a href="#解决的问题-2">解决的问题</a></li>
            <li><a href="#面临的挑战-1">面临的挑战</a></li>
            <li><a href="#核心方法-2">核心方法</a></li>
            <li><a href="#研究结果-1">研究结果</a></li>
          </ol>
        </li>
        <li><a href="#其他">其他</a>
          <ol>
            <li><a href="#druggen">DrugGen</a></li>
            <li><a href="#drugrealign">DrugReAlign</a></li>
            <li><a href="#benchmarkllm在八项化学任务中的表现">Benchmark：LLM在八项化学任务中的表现</a></li>
            <li><a href="#biobert">BioBERT</a></li>
          </ol>
        </li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="background-color: #5DB9AE; color: #fff;">
                学习札记
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/2025/rbdr/">AIDR | Reasoning-based Drug Repurposing</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2025-06-10</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 14 分钟
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h2 id="reasoning-based-drug-repurposing">Reasoning-based drug repurposing
</h2><h3 id="问题回答">问题&amp;回答
</h3><h4 id="问题">问题
</h4><ol>
<li>LLM在Repurposing中的应用情况</li>
<li>是否有基于文本结构，引入大模型知识作为一部分特征？</li>
<li>测试集是什么</li>
<li>传统模型/基于网络的模型的准确率</li>
</ol>
<h4 id="回答">回答
</h4><ol>
<li>有两种情况。第一种，引入LLM后的文本信息作为向量嵌入到GNN中；第二种，LLM作为筛选数据的方法，从数据层面提升最终效果。</li>
<li>有的。将文本以特定的形式组织，如&quot;药物A[SEP]疾病B&quot;，然后将其变成向量，嵌入到GNN中。</li>
<li>阅读了几篇，测试集有
<ol>
<li><a class="link" href="https://github.com/xiangyue9607/SCMFDD"  target="_blank" rel="noopener"
    >B-dataset</a>（SCMFDD-S/L）：来自于 <a class="link" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4"  target="_blank" rel="noopener"
    >Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text</a>，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了 SCMFDD-S 和 SCMFDD-L 数据集，其中的前者是这里的 B-dataset，适用于常规场景。</li>
<li>C-dataset：来自于 <a class="link" href="https://academic.oup.com/bioinformatics/article/32/17/2664/2450730"  target="_blank" rel="noopener"
    >Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic</a>，由 Dndataset 和 F-dataset 整合而成，结合了药物的 ATC 编码和疾病的 DO 术语。包含 963 种药物、1263 种疾病和 54921 个药物-疾病关系。适用于多源数据融合场景。</li>
<li>F-dataset：来自于 <a class="link" href="https://www.embopress.org/doi/full/10.1038/msb.2011.26"  target="_blank" rel="noopener"
    >PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology</a>，侧重于模型对文本知识的分析能力。</li>
<li>R-dataset：整合 C-dataset、F-dataset 和 KEGG 数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。</li>
</ol>
</li>
<li>模型准确率在不同的数据集上不同。这里的B、C、F数据集使用得比较多，一般来说衡量标准是AUC、AUPR、F1-score和Precision。</li>
</ol>
<h3 id="action">Action
</h3><h4 id="week">Week
</h4><p>week1</p>
<p>相关论文调研： 是否有用大模型推理在repurposing里做的？ 是否有基于文本&amp;结构特征做repurposing，然后把大模型reasoning的知识作为一部分feature加入，能够提升其效果，<strong>找出可复现的工作</strong>。</p>
<p>week2</p>
<p><strong>找出可复现的工作（上周遗留）</strong>， repurposing任务的测试集是什么？ 在这个测试集上 传统大模型是多少准确率，基于网络的方式是多少准确率？</p>
<hr>
<h2 id="相关论文调研">相关论文调研
</h2><h3 id="llm-dda">LLM-DDA
</h3><blockquote>
<p><a class="link" href="https://pubmed.ncbi.nlm.nih.gov/39325266/"  target="_blank" rel="noopener"
    >Empowering Graph Neural Network-Based Computational Drug Repositioning with Large Language Model-Inferred Knowledge Representation - PubMed</a></p></blockquote>
<h4 id="问题与回答">问题与回答
</h4><blockquote>
<p>Q1. LLM在Repurposing中的应用情况</p></blockquote>
<p>LLM的推理信息在这里被引入了GNN中作为一部分特征</p>
<blockquote>
<p>Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？</p></blockquote>
<p>文本结构经过LLM编码后的向量，引入到GNN网络中</p>
<blockquote>
<p>Q3. 测试集是什么</p></blockquote>
<p>见下面的数据集部分。一共使用了四个数据集。</p>
<blockquote>
<p>Q4. 传统模型/基于网络的模型的准确率</p></blockquote>
<ul>
<li>与下面四种baseline进行比较
<ol>
<li><strong>机器学习方法</strong>：DDA-SKF、NIMCGCN；</li>
<li><strong>矩阵分解方法</strong>：SCPMF、DRWBNCF；</li>
<li><strong>深度学习/GNN方法</strong>：REDDA、LAGCN、HDGAT</li>
<li><strong>LLM</strong> <strong>直接预测</strong>DirectPred</li>
</ol>
</li>
</ul>
<p>这里的前三种就是传统模型等其他方法。在下方的结果处说明了AUC、AUPR、F1-score和Precision的值。</p>
<h4 id="解决的问题">解决的问题
</h4><p>现有图神经网络（GNN）方法过度依赖网络拓扑结构，受限于不完整、含噪声的网络数据，且忽略生物医学领域丰富知识的问题。通过整合大语言模型（LLM）推断的知识表示，提升 DDA 预测的准确性和可靠性。</p>
<h4 id="面临挑战">面临挑战
</h4><ul>
<li>数据层面：传统GNN方法以来药物-疾病异构网络存在稀疏性和标签不平衡的问题</li>
<li>模型层面：现有方法难以捕捉复杂关联</li>
<li>知识利用：LLM生成的离散文本如何转化为适合GNN推理的连续数值表示，并设计高效融合架构</li>
</ul>
<h4 id="核心方法">核心方法
</h4><p><img src="/2025/rbdr/assets/20250610205120.png"
	width="6581"
	height="4831"
	srcset="/2025/rbdr/assets/20250610205120_hu_6c6d8334202a82d6.png 480w, /2025/rbdr/assets/20250610205120_hu_c9f818906ad62097.png 1024w"
	loading="lazy"
	
		alt="流程图"
	
	
		class="gallery-image" 
		data-flex-grow="136"
		data-flex-basis="326px"
	
></p>
<blockquote>
<p>TL;DR：关键在于<strong>知识挖掘（LLM 提示）→ 语义编码（嵌入生成）→ 图模型融合（关联预测）</strong></p>
<p>Step1：构建异质网络</p>
<p>Step2：利用LLM的知识来拓展潜在知识</p>
<p>Step3：基于LLM的嵌入生成</p>
<p>Step4：构建LLM-DDA模型</p></blockquote>
<p><strong>一、药物-疾病异质网络构建（Drug-disease heterogeneous network construction）</strong></p>
<ul>
<li><strong>数据来源</strong>：整合 DrugBank（药物数据库 ）、OMIM（人类孟德尔遗传数据库 ）、MeSH（医学主题词表 ）等生物医学数据库 。</li>
<li><strong>构建逻辑</strong>：
<ul>
<li>先计算 <strong>药物-药物、疾病-疾病的成对相似度（Pairwise similarities）</strong>（如化学结构、基因功能相似性 ）。</li>
<li>再结合已知 <strong>药物-疾病关联（Drug-disease associations）</strong> ，构建成包含药物、疾病节点，以及相似度、关联关系边的<strong>异质图网络</strong> ，为后续分析提供拓扑结构基础。</li>
</ul>
</li>
</ul>
<p><strong>二、零样本提示工程（Zero-shot prompt engineering）</strong></p>
<ul>
<li><strong>核心动作</strong>：设计 <strong>基于化学生物特征的提示模板（Chemobiomedical characteristics-based prompt template design）</strong> ，把药物 / 疾病的专业属性（如靶点、作用通路、临床特征等 ）转化为大语言模型（LLM）可理解的指令。</li>
<li><strong>功能价值</strong>：借助 GPT-4 的知识推理能力，<strong>生成目标药物 / 疾病的详细描述</strong> ，挖掘数据库外的潜在知识关联，引入LLM知识。</li>
</ul>
<p><strong>三、基于 LLM 的嵌入生成</strong></p>
<ul>
<li><strong>双模型进行嵌入生成</strong>：
<ul>
<li>用 <strong>ChatGPT-4 Turbo</strong>（通用大模型）、<strong>BioBERTpt</strong>（生物医学专用预训练模型 ），对 GPT-4 生成的文本描述做编码。</li>
<li>输出 <strong>LLM 嵌入</strong>，把生物医学语义信息转化为数值向量，让后续图模型能 理解语言知识。</li>
</ul>
</li>
</ul>
<p><strong>四、LLM-DDA 模型构建（LLM-DDA model construction）</strong></p>
<ul>
<li><strong>多架构覆盖</strong>：提供 3 种融合策略，适配不同场景需求：
<ul>
<li><strong>LLM-DDA (node feat)</strong>：直接把 LLM 嵌入作为节点特征，融入传统图神经网络，轻量且易部署。</li>
<li><strong>LLM-DDA (graph-graph)</strong>：双图网络并行，分别处理 LLM 嵌入图与原始异质图，再融合结果，强化多源信息互补。</li>
<li><strong>LLM-DDA (graph-ae)</strong>：结合图自动编码器（Graph-AE），优化嵌入特征与拓扑结构的融合，适合挖掘深层关联。</li>
</ul>
</li>
<li><strong>输入衔接</strong>：模型输入关联两部分：
<ul>
<li><strong>Similarity features</strong>（相似度特征 ）：来自第一步异质网络的拓扑计算。</li>
<li><strong>Adjacency matrix</strong>（邻接矩阵）：刻画药物-疾病的关联结构，让模型同时学习知识语义（LLM 嵌入）和网络拓扑（图结构），提升药物-疾病关联预测精度。</li>
</ul>
</li>
</ul>
<h4 id="数据集">数据集
</h4><p>四个药物-疾病的基准数据集</p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th>Dataset</th>
          <th>Drugs</th>
          <th>Diseases</th>
          <th>Drug-disease Associations</th>
          <th>Pos-Neg Ratio</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>B-dataset</td>
          <td>269</td>
          <td>598</td>
          <td>18,416</td>
          <td>11.45%</td>
      </tr>
      <tr>
          <td>C-dataset</td>
          <td>663</td>
          <td>409</td>
          <td>2,532</td>
          <td>1.57%</td>
      </tr>
      <tr>
          <td>F-dataset</td>
          <td>593</td>
          <td>313</td>
          <td>1,933</td>
          <td>1.05%</td>
      </tr>
      <tr>
          <td>R-dataset</td>
          <td>894</td>
          <td>454</td>
          <td>2,704</td>
          <td>0.67%</td>
      </tr>
  </tbody>
</table></div>
<ul>
<li><a class="link" href="https://github.com/xiangyue9607/SCMFDD"  target="_blank" rel="noopener"
    >B-dataset</a>：来自于<a class="link" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4"  target="_blank" rel="noopener"
    >Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text</a>，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了SCMFDD-S和SCMFDD-L数据集，其中的前者是这里的B-dataset，适用于常规场景。</li>
<li>C-dataset：来自于<a class="link" href="https://academic.oup.com/bioinformatics/article/32/17/2664/2450730"  target="_blank" rel="noopener"
    >Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic</a>，由Dndataset和F-dataset整合而成，结合了药物的ATC编码和疾病的DO术语。适用于多源数据融合场景。</li>
<li>F-dataset：来自于<a class="link" href="https://www.embopress.org/doi/full/10.1038/msb.2011.26"  target="_blank" rel="noopener"
    >PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology</a>，侧重于模型对文本知识的分析能力。</li>
<li>R-dataset：本文自己提出。整合C-dataset、F-dataset和KEGG数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。</li>
</ul>
<h4 id="指标结果">指标结果
</h4><ul>
<li>AUC、AUPR、F1和五折交叉验证结果<br>
<img src="/2025/rbdr/assets/20250610223319.png"
	width="1506"
	height="988"
	srcset="/2025/rbdr/assets/20250610223319_hu_75ab593fb94ec12.png 480w, /2025/rbdr/assets/20250610223319_hu_9c85fcc86562cfbc.png 1024w"
	loading="lazy"
	
		alt="四个数据集下的三种不同方法的效果"
	
	
		class="gallery-image" 
		data-flex-grow="152"
		data-flex-basis="365px"
	
></li>
<li>与下面四种baseline进行比较
<ol>
<li><strong>机器学习方法</strong>：DDA-SKF、NIMCGCN；</li>
<li><strong>矩阵分解方法</strong>：SCPMF、DRWBNCF；</li>
<li><strong>深度学习/GNN方法</strong>：REDDA、LAGCN、HDGAT</li>
<li><strong>LLM</strong> <strong>直接预测</strong>DirectPred</li>
</ol>
</li>
</ul>
<p>分别通过AUC、AUPR、F1-score和Precision来判断效果。</p>
<p><img src="/2025/rbdr/assets/20250610223616.png"
	width="944"
	height="792"
	srcset="/2025/rbdr/assets/20250610223616_hu_a1df0349a4cb82ee.png 480w, /2025/rbdr/assets/20250610223616_hu_b6a9867fa2330ad1.png 1024w"
	loading="lazy"
	
		alt="最优模型为粗体，次优为下划线"
	
	
		class="gallery-image" 
		data-flex-grow="119"
		data-flex-basis="286px"
	
><br>
<img src="/2025/rbdr/assets/20250610224129.png"
	width="469"
	height="359"
	srcset="/2025/rbdr/assets/20250610224129_hu_32afd63a86e7361.png 480w, /2025/rbdr/assets/20250610224129_hu_253c0f489a0df0dd.png 1024w"
	loading="lazy"
	
		alt="最终平均结果"
	
	
		class="gallery-image" 
		data-flex-grow="130"
		data-flex-basis="313px"
	
></p>
<hr>
<h3 id="lbmff">LBMFF
</h3><blockquote>
<p><a class="link" href="https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2023.1205144/full"  target="_blank" rel="noopener"
    >Frontiers | Drug–disease association prediction with literature based multi-feature fusion</a></p></blockquote>
<h4 id="问题与回答-1">问题与回答
</h4><blockquote>
<p>Q1. LLM在Repurposing中的应用情况</p></blockquote>
<p>这里使用了BERT来挖掘文献中的关联关系。</p>
<blockquote>
<p>Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？</p></blockquote>
<p>BERT经过预训练和微调之后，能够学习文献中的一些关联关系，输出包含<strong>语义关联信息的向量表示</strong>，从而文献中的药物-药物相似性关系和疾病-疾病相似性关系知识。</p>
<blockquote>
<p>Q3. 测试集是什么</p></blockquote>
<p>见下面的数据集部分。一共使用了两个数据集。</p>
<blockquote>
<p>Q4. 传统模型/基于网络的模型的准确率</p></blockquote>
<p>对比的模型分为如下部分，都是各自领域的SOTA模型。</p>
<ol>
<li><strong>图神经网络（GNN）</strong>：DRHGCN、LAGCN、REDDA</li>
<li><strong>矩阵分解与正则化</strong>：BNNR、DRWBNCF</li>
<li><strong>矩阵补全与神经归纳</strong>：NIMCGCN</li>
<li><strong>核融合与传统机器学习</strong>：DDA-SKF</li>
</ol>
<p>对比结果如研究结果部分所示。</p>
<h4 id="解决的问题-1">解决的问题
</h4><p><strong>药物重定位中的关联预测问题</strong></p>
<h4 id="面临的挑战">面临的挑战
</h4><ul>
<li>文献信息利用不够充分：现在大多数计算方法都是依赖结构化数据库，但是科学文献中有很多未被充分挖掘的药物-疾病关联关系。</li>
<li>多特征难以有效融合：药物和疾病的特征具有异质性。</li>
</ul>
<h4 id="核心方法-1">核心方法
</h4><p>提出了LBMFF（基于文献的多特征融合方法）。</p>
<ul>
<li><strong>多源融合</strong>：同时用结构化数据库（Drugbank、SIDER 等）和非结构化文献（BERT 处理），挖掘更全面的药物-疾病关联。</li>
<li><strong>图网络 + 注意力</strong>：用 GCN 处理 “药物-疾病” 关联的图结构，注意力机制强化关键特征，提升预测准确性。</li>
</ul>
<p><img src="/2025/rbdr/assets/20250611145238.png"
	width="1014"
	height="778"
	srcset="/2025/rbdr/assets/20250611145238_hu_a0419756e480ffda.png 480w, /2025/rbdr/assets/20250611145238_hu_790c8b92f59e5590.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="130"
		data-flex-basis="312px"
	
></p>
<ol>
<li>相似性计算
<ul>
<li>从<strong>多源数据</strong>提取特征，计算药物、疾病的相似性，构建关联矩阵</li>
<li><strong>药物相似性</strong>（Drug-Drug）：<br>
整合 3 类结构化数据 + 文献语义：
<ul>
<li>化学结构（Drugbank 数据库，药物分子结构）</li>
<li>副作用（SIDER 数据库，药物-副作用关联）</li>
<li>靶点（Drugbank 数据库，药物-靶点关联）</li>
<li>文献语义（BERT 模型处理文献，挖掘药物间语义关联）<br>
最终加权融合（α、β、γ 为权重），输出<strong>药物相似性矩阵</strong>。</li>
</ul>
</li>
<li><strong>疾病相似性</strong>（Disease-Disease）：<br>
整合 2 类数据：
-MeSH 数据库（疾病树编号，疾病分类体系）
<ul>
<li>文献语义（BERT 模型处理文献，挖掘疾病间语义关联）<br>
输出<strong>疾病相似性矩阵</strong>。</li>
</ul>
</li>
<li><strong>药物-疾病关联</strong>（Drug-Disease）：<br>
直接从 CTD 数据库（比较毒理学数据库）获取<strong>已知关联矩阵</strong>，标记已验证的药物-疾病对。</li>
</ul>
</li>
<li>特征表示
<ul>
<li>将上一步得到的 <strong>药物相似性矩阵、疾病相似性矩阵、已知关联矩阵</strong> 拼接，形成模型输入的<strong>融合特征矩阵</strong>，统一表征药物和疾病的多源信息。</li>
</ul>
</li>
<li>编码器
<ul>
<li>用<strong>带注意力机制的图卷积网络（GCN）</strong> 学习药物、疾病的嵌入表示：</li>
<li>两层 GCN（Graph Convolution Encoder Layer）逐层提取特征，ReLU 激活增加非线性。</li>
<li>注意力机制（Attention mechanism）动态分配权重，突出关键特征（比如强关联的药物-疾病对）。</li>
<li>最终输出 <strong>药物 + 疾病的嵌入向量</strong>（维度 (m + n)×d ，m 是药物数，n 是疾病数，d 是嵌入维度 ）。</li>
</ul>
</li>
<li>解码器
<ul>
<li>通过<strong>矩阵乘法</strong>还原关联预测：
<ul>
<li>药物嵌入（$Eₘₓ×d$ ）、权重矩阵（$W_d×d$ ）、疾病嵌入（$Eₙₓ×d $）相乘，重建药物-疾病关联得分。</li>
</ul>
</li>
</ul>
</li>
<li>预测输出<strong>潜在关联</strong>
<ul>
<li>实线：已知关联（来自 CTD 数据库）。</li>
<li>虚线：模型预测的<strong>潜在关联</strong>（未被验证，但算法判定有高可能性的药物-疾病对 ），可辅助药物重定位研究。</li>
</ul>
</li>
</ol>
<h5 id="bert在文中">BERT在文中
</h5><p><img src="/2025/rbdr/assets/20250611151737.png"
	width="1010"
	height="482"
	srcset="/2025/rbdr/assets/20250611151737_hu_78901334681f4864.png 480w, /2025/rbdr/assets/20250611151737_hu_989e86a68a8680fd.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="209"
		data-flex-basis="502px"
	
></p>
<p><strong>预训练</strong></p>
<ul>
<li><strong>数据准备</strong>
<ul>
<li>筛选包含药物、疾病名称的科学文献（如从 PubMed 获取，文中提到的 673,665 篇相关文献 ），这些文献包含药物-疾病关联的语义描述（如治疗、关联、机制等表述 ）。</li>
<li>将文献中疾病、药物相关文本构建为“药物文本-疾病文本” 对作为输入序列。</li>
</ul>
</li>
<li><strong>Masked LM</strong>
<ul>
<li>让BERT预测被遮盖内容，如[MASK]可以治疗糖尿病，需要推断出是药物X。</li>
</ul>
</li>
<li><strong>NSP</strong>
<ul>
<li>真实对：药物A[SEP]疾病B</li>
<li>虚假对：药物C[SEP] 疾病D</li>
<li>需要判断文本对是否是真实对</li>
</ul>
</li>
</ul>
<p><strong>模型微调</strong></p>
<ul>
<li><strong>数据</strong>
<ul>
<li>使用CTD等数据库中已知的药物-疾病关联对。存在关联为正例，无关联为负例</li>
</ul>
</li>
<li><strong>输出语义特征</strong>
<ul>
<li>经过预训练 + 微调后，BERT 对输入的 “药物-疾病文本对”，会输出包含<strong>语义关联信息的向量表示</strong></li>
</ul>
</li>
</ul>
<h4 id="研究结果">研究结果
</h4><h5 id="测试集">测试集
</h5><ul>
<li>Zhang（SCMFDD-S）：来自于<a class="link" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4"  target="_blank" rel="noopener"
    >Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text</a>，在上面被称为B-dataset。包含269种药物、598种疾病和18416个药物-疾病关系。本文中还从其他数据库中填充了化学结构、药物-靶点关系和药物副作用、疾病树作为药物-药物相似性度量的数据。</li>
<li>TL-HGBI：来自于<a class="link" href="https://academic.oup.com/bioinformatics/article/30/20/2923/2422178"  target="_blank" rel="noopener"
    >Drug repositioning by integrating target information through a heterogeneous network model | Bioinformatics | Oxford Academic</a>。包含963种药物、1263种疾病和54921个药物-疾病关系。同样地，也进行了信息填充来进行相似性度量。</li>
</ul>
<h5 id="指标表现">指标表现
</h5><p>和SOTA模型进行比较，分别是</p>
<ol>
<li><strong>图神经网络（GNN）</strong>：DRHGCN、LAGCN、REDDA</li>
<li><strong>矩阵分解与正则化</strong>：BNNR、DRWBNCF</li>
<li><strong>矩阵补全与神经归纳</strong>：NIMCGCN</li>
<li><strong>核融合与传统机器学习</strong>：DDA-SKF</li>
</ol>
<p>LBMFF在所有指标上都体现出了领先。</p>
<p><img src="/2025/rbdr/assets/20250611153556.png"
	width="1620"
	height="603"
	srcset="/2025/rbdr/assets/20250611153556_hu_9a785be424d4ae99.png 480w, /2025/rbdr/assets/20250611153556_hu_c4246ac65e7a8d75.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="268"
		data-flex-basis="644px"
	
></p>
<p>此外，LBMFF在TL-HGBI在多数指标上仍优于对比方法，证明方法在<strong>大规模数据集上的泛化能力</strong>。</p>
<p><img src="/2025/rbdr/assets/20250611154234.png"
	width="1659"
	height="589"
	srcset="/2025/rbdr/assets/20250611154234_hu_8a504edeb9650d6c.png 480w, /2025/rbdr/assets/20250611154234_hu_237ef5a787bfd481.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="281"
		data-flex-basis="675px"
	
></p>
<hr>
<h3 id="llm进行阴性数据标注">LLM进行阴性数据标注
</h3><blockquote>
<p><a class="link" href="https://pubmed.ncbi.nlm.nih.gov/39905466/"  target="_blank" rel="noopener"
    >Improving drug repositioning with negative data labeling using large language models-PubMed</a></p></blockquote>
<h4 id="问题与回答-2">问题与回答
</h4><blockquote>
<p>Q1. LLM在Repurposing中的应用情况</p></blockquote>
<p>LLM引入了自己的推理能力来修改训练数据。</p>
<blockquote>
<p>Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？</p></blockquote>
<p>没有。这里大模型的作用是通过自身的知识，在文本中筛选出更好的数据来提升最终效果的。</p>
<blockquote>
<p>Q3. 测试集是什么</p></blockquote>
<p>测试集是由AACT 数据库得到。作者手动选择了一部分数据（5 阳性 + 11 阴性 ）作为测试集验证泛化能力。</p>
<blockquote>
<p>Q4. 传统模型/基于网络的模型的准确率</p></blockquote>
<p>见研究结果。本文通过<strong>提升数据集中真阴性数据的质量</strong>来提高了最终的模型效果。具体来说，提升的效果还是比较显著的。</p>
<h4 id="解决的问题-2">解决的问题
</h4><p>在药物重新定位中，监督机器学习模型因缺乏可靠的<strong>阴性数据</strong>（即因无效或毒性失败的药物）而预测准确性和泛化能力不足。</p>
<p>传统的 Positive-Unlabeled（PU）学习方法通过随机采样或简单分类未标记数据作为阴性，存在误分类或决策边界简化的问题，导致模型性能受限。</p>
<p><strong>LLM通过进行分析文献和数据，系统挖掘真阴性数据，提升了阴性数据的质量。</strong></p>
<h4 id="面临的挑战-1">面临的挑战
</h4><ul>
<li><strong>阴性数据获取困难</strong>：多数数据库会把试验中止就等同于阴性，但终止原因可能并不是因为药物疗效/毒性问题，而是资金不足等原因。</li>
<li><strong>PU学习方法的局限性</strong>：随机采样未标记数据作为阴性会引入分类偏差，而基于聚类等策略的阴性筛选假设正负样本边界清晰，与真实场景不符，导致模型泛化能力差。</li>
<li><strong>临床数据处理复杂性</strong>：临床试验文本存在表述不规范、结果不完整等问题，传统方法难以准确解析并识别真正的阴性药物。</li>
</ul>
<h4 id="核心方法-2">核心方法
</h4><p><strong>GPT-4 系统性挖掘真阴性数据</strong>，为药物重定位提供 “高质量标注 + 精准模型” 方案，可扩展到其他疾病。</p>
<p><img src="/2025/rbdr/assets/20250610231108.png"
	width="1056"
	height="314"
	srcset="/2025/rbdr/assets/20250610231108_hu_bb6cc8baf67ab024.png 480w, /2025/rbdr/assets/20250610231108_hu_52714faad2411ffc.png 1024w"
	loading="lazy"
	
		alt="临床试验药物标注流程"
	
	
		class="gallery-image" 
		data-flex-grow="336"
		data-flex-basis="807px"
	
></p>
<ul>
<li><strong>临床数据获取</strong>：从 AACT 数据库获取 2539 个前列腺癌相关临床试验，排除未公布结果和因非疗效原因终止的试验后，剩余 1442 个试验由 GPT-4 分析。</li>
<li><strong>GPT-4的训练和验证</strong>：使用 22 个手动策划的试验对 GPT-4 进行验证，其中包括 14 个无关试验、4 个阳性试验和 4 个阴性试验，GPT-4 成功正确分类所有试验。</li>
<li><strong>特征构建</strong>：
<ul>
<li><strong>知识-based 特征</strong>：从 DrugBank 获取药物-基因、药物-靶点、药物-通路相互作用、结构特性和靶点类别等，转换为独热编码。</li>
<li><strong>network-based 特征</strong>：构建包含药物-药物相似性、蛋白质-蛋白质相互作用和基因本体论的多层生物网络，提取拓扑特征。</li>
</ul>
</li>
<li><strong>对比策略</strong>：
<ul>
<li><strong>GPT-4 标注</strong>：使用 GPT-4 识别的 26 个阳性和 54 个阴性药物。</li>
<li><strong>无采样 PU</strong>：将所有未标记药物视为阴性，导致类别不平衡。</li>
<li><strong>下采样 PU</strong>：从未标记药物中随机采样 43 个阴性，重复 100 次以控制类别不平衡。<br>
<img src="/2025/rbdr/assets/20250610234019.png"
	width="720"
	height="650"
	srcset="/2025/rbdr/assets/20250610234019_hu_da1098ceace0f516.png 480w, /2025/rbdr/assets/20250610234019_hu_cabf59ededa6f174.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="110"
		data-flex-basis="265px"
	
></li>
</ul>
</li>
</ul>
<p>训练集和测试集来自于作者自己收集和整理。</p>
<h4 id="研究结果-1">研究结果
</h4><p>使用六种机器学习算法和5折交叉验证训练模型，测试集验证泛化能力（5 阳性 + 11 阴性 ）。</p>
<p><img src="/2025/rbdr/assets/20250610232517.png"
	width="1442"
	height="600"
	srcset="/2025/rbdr/assets/20250610232517_hu_88b2c5cdb4fef3fe.png 480w, /2025/rbdr/assets/20250610232517_hu_ebaa126e63836e49.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="240"
		data-flex-basis="576px"
	
></p>
<h5 id="1-训练集表现图-a">1. 训练集表现（图 A）：
</h5><ul>
<li><strong>GPT-4（🔴）</strong>：多数算法（如 LogL1、RF、SVM ）平衡准确率接近 0.9，说明用 GPT-4 标注的高质量数据，模型在训练集上 “学的好”，分类稳定。</li>
<li><strong>No sampling（🟢）</strong>：部分算法（如 ANN、NB ）准确率暴跌，因阴性样本太多，学不到有效模式。</li>
<li><strong>Under sampling（🔵）</strong>：表现居中，虽平衡了类别，但随机丢数据，训练效果不如 GPT-4 标注。</li>
</ul>
<h5 id="2-测试集表现图-b">2. 测试集表现（图 B）：
</h5><ul>
<li><strong>GPT-4（🔴）</strong>：多数算法（如 LogL1、RF、SVM ）MCC 显著高于其他策略，尤其是 LogL1、RF，说明模型泛化能力强，用 GPT-4 标注数据训练的模型，在真实测试集上 “预测准”。</li>
<li><strong>No sampling（🟢）</strong>：MCC 普遍低（如 NB 甚至接近 0 ），模型被类别不平衡拖垮。</li>
<li><strong>Under sampling（🔵）</strong>：MCC 比 GPT-4 低，因下采样丢了很多真实阴性信息，模型学到的规律不完整。</li>
</ul>
<hr>
<h3 id="其他">其他
</h3><h4 id="druggen">DrugGen
</h4><blockquote>
<p><a class="link" href="https://www.nature.com/articles/s41598-025-98629-1"  target="_blank" rel="noopener"
    >DrugGen enhances drug discovery with large language models and reinforcement learning | Scientific Reports</a></p></blockquote>
<p>这篇文章介绍了一个基于DrugGPT的模型DrugGen，通过监督微调、近端策略优化和强化学习来引导模型生成更高质量的分子。</p>
<h4 id="drugrealign">DrugReAlign
</h4><blockquote>
<p><a class="link" href="https://pubmed.ncbi.nlm.nih.gov/39379930/"  target="_blank" rel="noopener"
    >DrugReAlign: a multisource prompt framework for drug repurposing based on large language models - PubMed</a></p></blockquote>
<p>提出了一个多源提示的LLM药物重定位框架。</p>
<p><img src="/2025/rbdr/assets/20250611164032.png"
	width="1944"
	height="1430"
	srcset="/2025/rbdr/assets/20250611164032_hu_20997968172a8920.png 480w, /2025/rbdr/assets/20250611164032_hu_f551cf6e5e853017.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="135"
		data-flex-basis="326px"
	
></p>
<h4 id="benchmarkllm在八项化学任务中的表现">Benchmark：LLM在八项化学任务中的表现
</h4><blockquote>
<p><a class="link" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/bbb330189ce02be00cf7346167028ab1-Paper-Datasets_and_Benchmarks.pdf"  target="_blank" rel="noopener"
    >What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks</a></p></blockquote>
<p>评估了LLM在八项具体的化学任务中的表现，采用零样本、少样本上下文学习设置，最后得出GPT-4最佳，Davinci-003次之，GPT-3.5第三。</p>
<h4 id="biobert">BioBERT
</h4><blockquote>
<p><a class="link" href="https://academic.oup.com/bioinformatics/article/36/4/1234/5566506"  target="_blank" rel="noopener"
    >BioBERT: a pre-trained biomedical language representation model for biomedical text mining | Bioinformatics | Oxford Academic</a></p></blockquote>
<p>介绍了一个用于生物医学领域的预训练语言表示模型，其在BERT的基础上使用生物医学领域语料库进行预训练。</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/ai4science/">AI4Science</a>
        
            <a href="/tags/aidr/">AIDR</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>All rights reserved.</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    


<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/2025/aidr-network-method/">
        
        

        <div class="article-details">
            <h2 class="article-title">AIDR | 基于网络的方法</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/2025/moleculerepurposing-2/">
        
        

        <div class="article-details">
            <h2 class="article-title">AIDR | 综述与论文</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/2025/moleculerepurposing/">
        
        

        <div class="article-details">
            <h2 class="article-title">AIDR | 数据库探索</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2024 - 
        
        2026 ionfeather&#39;Log
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.29.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


<script>
    (function(u, c) {
      var d = document, t = 'script', o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function(e) { c(e); }); }
      s.parentNode.insertBefore(o, s);
    })('//cdn.bootcss.com/pangu/3.3.0/pangu.min.js', function() {
      pangu.spacingPage();
    });
</script>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<script src="https://npm.elemecdn.com/nprogress@0.2.0/nprogress.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://npm.elemecdn.com/nprogress@0.2.0/nprogress.css" crossorigin="anonymous" />
<script>
    NProgress.start();
    document.addEventListener("readystatechange", () => {
        if (document.readyState === "interactive") NProgress.inc(0.8);
        if (document.readyState === "complete") NProgress.done();
    });
</script>


    </body>
</html>
