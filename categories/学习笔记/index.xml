<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>学习札记 on ionfeather&#39;Log</title>
        <link>https://ionfeather.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
        <description>Recent content in 学习札记 on ionfeather&#39;Log</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>ionfeather&#39;Log</copyright>
        <lastBuildDate>Thu, 28 Aug 2025 19:28:49 +0800</lastBuildDate><atom:link href="https://ionfeather.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>书籍阅读 | Speech and Language Processing</title>
        <link>https://ionfeather.github.io/2025/speech-and-language-processing/</link>
        <pubDate>Thu, 28 Aug 2025 19:28:49 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/speech-and-language-processing/</guid>
        <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction
&lt;/h2&gt;&lt;p&gt;阅读&lt;a class=&#34;link&#34; href=&#34;https://web.stanford.edu/~jurafsky/slp3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Speech and Language Processing&lt;/a&gt;这本书的一些笔记，以供后来的自己参考。&lt;/p&gt;
&lt;h2 id=&#34;words-and-tokens&#34;&gt;Words and Tokens
&lt;/h2&gt;&lt;p&gt;我们需要一个东西来建模语言，下面是我们的选择：&lt;/p&gt;
&lt;h3 id=&#34;words&#34;&gt;Words
&lt;/h3&gt;&lt;p&gt;为什么不用词？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有些语言没有orthographic words&lt;/li&gt;
&lt;li&gt;词的数量会随着文章增长，词汇表永远都会覆盖不足&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;morphemes&#34;&gt;Morphemes
&lt;/h3&gt;&lt;p&gt;语素类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;屈折语素：inflectional morphemes&lt;/li&gt;
&lt;li&gt;派生语素：derivational morphemes&lt;/li&gt;
&lt;li&gt;附着语素：clitic&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;语言类型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analytic&lt;/li&gt;
&lt;li&gt;polysynthetic&lt;/li&gt;
&lt;li&gt;fusional&lt;/li&gt;
&lt;li&gt;agglutinative&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么不用语素？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;语素很复杂，很难定义&lt;/li&gt;
&lt;li&gt;不同语言不同且难以统一&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unicode&#34;&gt;Unicode
&lt;/h3&gt;&lt;p&gt;Unicode的历史&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ASCII&lt;/li&gt;
&lt;li&gt;CJKV&lt;/li&gt;
&lt;li&gt;不断更新中，越来越多，Unicode 16.0已经包含超过150000个字符&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;code-points&#34;&gt;Code Points
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;U+：表示接下来要用Unicode十六进制表示一个code point&lt;/li&gt;
&lt;li&gt;U+0061：0x0061一个意思，也就小写字母a。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;utf-8&#34;&gt;UTF-8
&lt;/h4&gt;&lt;p&gt;目前最常用的encoding字符的方式。中文字符 “中” 的 Unicode 码点是&lt;code&gt;U+4E2D&lt;/code&gt;，UTF-8 编码后为 3 个字节：&lt;code&gt;0xE4 0xB8 0xAD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;UTF-8是一种变长编码，兼容ASCII。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如「世」，UTF-8 编码是&lt;code&gt;0xE4 B8 96&lt;/code&gt;，其中E4的二进制为&lt;code&gt;11100110H&lt;/code&gt;，开头的&lt;code&gt;1110H&lt;/code&gt;表示这是一个3字节字符的第一个字节。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subword-tokenization-byte-pair-encoding&#34;&gt;Subword Tokenization: Byte-Pair Encoding
&lt;/h3&gt;&lt;p&gt;上面的三个候选都不行，word和morpheme难以规范定义，character可以通过unicode来定义，但又对于作为tokens来说太小了。&lt;/p&gt;
&lt;p&gt;为什么要tokenize输入？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将输入转换为一组确定的、固定的单元（Token），能让不同的算法和系统在一些简单问题上达成共识。例如困惑度的计算。&lt;/li&gt;
&lt;li&gt;对可复现很重要&lt;/li&gt;
&lt;li&gt;为了消除unknown words的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了消除unknown words问题，现代tokenizers自动引入了token包含那些比words小的token，叫subword。&lt;/p&gt;
&lt;p&gt;使用&lt;a class=&#34;link&#34; href=&#34;https://platform.openai.com/tokenizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tokenizer - OpenAI API&lt;/a&gt;中的&lt;code&gt;GPT-4o &amp;amp;  GPT-4o mini&lt;/code&gt;来分词下面这一大段话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, if we had happened not to ever see the word lower, when it appears we could segment it successfully into low and er which we had already seen. In the worst case, a really unusual word (perhaps an acronym like GRPO) could be tokenized as a sequence of individual letters if necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;最终得到的是
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982.png&#34;
	width=&#34;711&#34;
	height=&#34;279&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_b760c9dcae731844.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250828205105982_hu_3812253da13ed9c0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;611px&#34;
	
&gt;
现在最流行的tokenization algorithm有两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Byte-Pair Encoding(BPE)&lt;/li&gt;
&lt;li&gt;Unigram Language modeling(ULM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;bpe&#34;&gt;BPE
&lt;/h4&gt;&lt;p&gt;通过分析训练语料，自动学习出一套子词集合（词汇表），使得高频出现的字符 / 子词组合被合并为更大的子词单位。&lt;/p&gt;
&lt;p&gt;训练方法介绍。&lt;/p&gt;
&lt;h4 id=&#34;bpe-encoder&#34;&gt;BPE encoder
&lt;/h4&gt;&lt;h4 id=&#34;bpe-in-practice&#34;&gt;BPE in practice
&lt;/h4&gt;&lt;p&gt;通常，我们会对 UTF-8 编码文本的&lt;strong&gt;单个字节&lt;/strong&gt;执行 BPE 操作。BPE 处理 “中” 时，输入并非&lt;code&gt;U+4E2D&lt;/code&gt;这个码点，而是&lt;code&gt;E4&lt;/code&gt;、&lt;code&gt;B8&lt;/code&gt;、&lt;code&gt;AD&lt;/code&gt;这三个独立字节。&lt;/p&gt;
&lt;p&gt;仅在&lt;strong&gt;预先切分出的单词内部&lt;/strong&gt;执行 BPE 操作，有助于避免潜在问题。&lt;/p&gt;
&lt;p&gt;一些英语里的小发现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大多数单词的tokens是他们自己，包含词前空格。这样可以避免独立单词和单词内部的subword。&lt;/li&gt;
&lt;li&gt;附着语素Clitics在名字后面分开单独成token，但在常见的词语后面会是token的一部分&lt;/li&gt;
&lt;li&gt;数字通常三位一组&lt;/li&gt;
&lt;li&gt;一些词，如Anyhow和anyhow会有不同的分割方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个和预处理有关系。&lt;/p&gt;
&lt;p&gt;SuperBPE会合并常规的BPE子词分词，效率更高。&lt;/p&gt;
&lt;p&gt;特别地，低资源语言的tokens更碎，就会输出边长，最终LLM的效率变低。&lt;/p&gt;
&lt;h3 id=&#34;rule-based-tokenization&#34;&gt;Rule-based tokenization
&lt;/h3&gt;&lt;p&gt;Penn Treebank Tokenization Standard）：事实性规范。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分开附着语素&lt;/li&gt;
&lt;li&gt;保留连字符连接的词&lt;/li&gt;
&lt;li&gt;分开所有的标点符号&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sentence-segmentation&#34;&gt;Sentence Segmentation
&lt;/h4&gt;&lt;p&gt;sentence tokenization可以和word tokenization联合处理。&lt;/p&gt;
&lt;h3 id=&#34;corpora&#34;&gt;Corpora
&lt;/h3&gt;&lt;p&gt;语料库和语言数量、使用者的特征都有关。&lt;/p&gt;
&lt;p&gt;code switching：在一次持续的交流）中，说话者或作者交替使用两种或多种 “语码”的现象。&lt;/p&gt;
&lt;p&gt;datasheet：存储一句话的特征，如时间、说话人性格、阶级&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;regular-expressions&#34;&gt;Regular Expressions
&lt;/h3&gt;&lt;p&gt;正则表达式的具体实现。包含字符析取、计数、可选性、通配符、锚点和边界、替换和捕获组、前向断言等。&lt;/p&gt;
&lt;h3 id=&#34;simple-unix-tools-for-word-tokenization&#34;&gt;Simple Unix Tools for Word Tokenization
&lt;/h3&gt;&lt;p&gt;可以在Unix、Linux系统中使用正则表达式。如&lt;code&gt;tr -sc &#39;A-Za-z&#39; &#39;\n&#39; &amp;lt; sh.txt&lt;/code&gt;表示从 &lt;code&gt;sh.txt&lt;/code&gt; 文件中提取所有英文字母，并将非字母字符替换为换行符，同时压缩连续的非字母字符为单个换行符。&lt;/p&gt;
&lt;h3 id=&#34;minimum-edit-distance&#34;&gt;Minimum Edit Distance
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;最小编辑距离&lt;/strong&gt;：将一个字符串通过 “插入”“删除”“替换” 三种基本操作转换为另一个字符串所需的最少操作次数&lt;/p&gt;
&lt;h4 id=&#34;the-minimum-edit-distance-algorithm&#34;&gt;The Minimum Edit Distance Algorithm
&lt;/h4&gt;&lt;p&gt;一个经典的动态规划问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;字符对齐&lt;/strong&gt;：通过回溯编辑距离矩阵中的 “最优路径”，反向推导出将一个字符串转换为另一个字符串的具体操作序列。也就是&lt;strong&gt;路径可视化&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;exercies&#34;&gt;Exercies
&lt;/h3&gt;&lt;h5 id=&#34;21&#34;&gt;2.1
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all alphabetic strings.&lt;/li&gt;
&lt;li&gt;The set of all lowercase alphabetic strings ending in &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The set of all strings from the alphabet {a, b} such that each &amp;ldquo;a&amp;rdquo; is immediately preceded by and immediately followed by a &amp;ldquo;b&amp;rdquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;22&#34;&gt;2.2
&lt;/h5&gt;&lt;p&gt;Write regular expressions for the following languages. By &amp;ldquo;word&amp;rdquo;, we mean an alphabetic string separated from other words by whitespace, relevant punctuation, line breaks, etc.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The set of all strings with two consecutive repeated words (e.g., &amp;ldquo;Humbert Humbert&amp;rdquo; and &amp;ldquo;the the&amp;rdquo; but not &amp;ldquo;the bug&amp;rdquo; or &amp;ldquo;the big bug&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;All strings that start at the beginning of the line with an integer and end at the end of the line with a word.&lt;/li&gt;
&lt;li&gt;All strings that have both the word &amp;ldquo;grotto&amp;rdquo; and the word &amp;ldquo;raven&amp;rdquo; in them (but not, e.g., words like &amp;ldquo;grottos&amp;rdquo; that merely contain &amp;ldquo;grotto&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Write a pattern that places the first word of an English sentence in a register. Deal with punctuation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;23&#34;&gt;2.3
&lt;/h5&gt;&lt;p&gt;Implement an ELIZA-like program, using substitutions such as those described on page 27. You might want to choose a different domain than a Rogerian psychologist, although keep in mind that you would need a domain in which your program can legitimately engage in a lot of simple repetition.&lt;/p&gt;
&lt;h5 id=&#34;24&#34;&gt;2.4
&lt;/h5&gt;&lt;p&gt;Compute the edit distance (using insertion cost 1, deletion cost 1, substitution cost 1) of &amp;ldquo;leda&amp;rdquo; to &amp;ldquo;deal&amp;rdquo;. Show your work (using the edit distance grid).&lt;/p&gt;
&lt;h5 id=&#34;25&#34;&gt;2.5
&lt;/h5&gt;&lt;p&gt;Figure out whether &amp;ldquo;drive&amp;rdquo; is closer to &amp;ldquo;brief&amp;rdquo; or to &amp;ldquo;divers&amp;rdquo; and what the edit distance is to each. You may use any version of distance that you like.&lt;/p&gt;
&lt;h5 id=&#34;26&#34;&gt;2.6
&lt;/h5&gt;&lt;p&gt;Now implement a minimum edit distance algorithm and use your hand-computed results to check your code.&lt;/p&gt;
&lt;h5 id=&#34;27&#34;&gt;2.7
&lt;/h5&gt;&lt;p&gt;Augment the minimum edit distance algorithm to output an alignment; you will need to store pointers and add a stage to compute the backtrace.&lt;/p&gt;
&lt;h2 id=&#34;n-gram-language-models&#34;&gt;N-gram Language Models
&lt;/h2&gt;&lt;p&gt;本章介绍最简单的语言模型：&lt;strong&gt;N元语法语言模型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;n-grams&#34;&gt;N-Grams
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;概率链式法则&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;how-to-estimate-probabilities&#34;&gt;How to estimate probabilities
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;马尔科夫假设&lt;/strong&gt;：假设一个单词的出现概率只和前面的一个单词有关。那么n-gram即只和前面的$n-1$个单词有关。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大似然估计&lt;/strong&gt;：已知前一个词$w_{n−1}$​时，当前词$w_n$​的概率&lt;/p&gt;
&lt;p&gt;终止符号（end-symbol）：所有可能句子的概率总和为 1，否则是特定长度的所有句子概率之和为 1。&lt;/p&gt;
&lt;h4 id=&#34;dealing-with-scale-in-large-n-gram-models&#34;&gt;Dealing with scale in large n-gram models
&lt;/h4&gt;&lt;p&gt;Log probabilities&lt;/p&gt;
&lt;p&gt;N元语法的计算现在甚至能达到无限元。&lt;/p&gt;
&lt;p&gt;对N元语法模型进行修剪也是很重要的。&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-training-and-test-sets&#34;&gt;Evaluating Language Models: Training and Test Sets
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;内部评估&lt;/strong&gt;和外部评估。&lt;/p&gt;
&lt;p&gt;训练集、开发集和测试集。&lt;/p&gt;
&lt;h4 id=&#34;evaluating-language-models-perplexity&#34;&gt;Evaluating Language Models: Perplexity
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Perplexity（PPL）&lt;/strong&gt;：困惑度越低，说明模型对文本的预测越准确（即模型越 “不困惑”）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;具体来说，是“联合概率倒数的几何平均值”。&lt;/li&gt;
&lt;li&gt;在计算的时候常常会取对数来将求乘积变为求和，避免数值问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;perplexity-as-weighted-average-branching-factor&#34;&gt;Perplexity as Weighted Average Branching Factor
&lt;/h5&gt;&lt;p&gt;困惑度也可以理解为&lt;strong&gt;加权平均分支系数&lt;/strong&gt;。其中，语言的 “分支系数”指的是 “任何一个词之后可能出现的下一个词的数量”。&lt;/p&gt;
&lt;h3 id=&#34;sampling-sentences-from-a-language-model&#34;&gt;Sampling sentences from a language model
&lt;/h3&gt;&lt;p&gt;“0-1 数轴 + 区间映射”来理解采样的基本原理。&lt;/p&gt;
&lt;h3 id=&#34;generalizing-vs-overfitting-the-training-set&#34;&gt;Generalizing vs. overfitting the training set
&lt;/h3&gt;&lt;p&gt;对于莎士比亚文本和华尔街日报的文本，两者差异过大以至于不能分别作为训练集和测试集。&lt;/p&gt;
&lt;p&gt;所以说要确保训练集和测试集的领域要相似。&lt;/p&gt;
&lt;h3 id=&#34;smoothing-interpolation-and-backoff&#34;&gt;Smoothing, Interpolation, and Backoff
&lt;/h3&gt;&lt;p&gt;zero probability n-grams有两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;低估了词语序可能出现的可能性，导致最终的性能变差&lt;/li&gt;
&lt;li&gt;困惑度无法计算，因为无法除以0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此需要Smoothing或者discounting&lt;/p&gt;
&lt;h4 id=&#34;laplace-smoothing&#34;&gt;Laplace Smoothing
&lt;/h4&gt;&lt;p&gt;其实也就是add one smoothing，就是对于所有的N元语法都加一。&lt;/p&gt;
&lt;p&gt;对于语言模型来说，结果并不是很好。对文本分类有效。&lt;/p&gt;
&lt;h4 id=&#34;add-k-smoothing&#34;&gt;Add-k Smoothing
&lt;/h4&gt;&lt;p&gt;也就是对所有的都加K。&lt;/p&gt;
&lt;p&gt;对语言模型来说仍然效果一般。&lt;/p&gt;
&lt;h4 id=&#34;language-model-interpolation&#34;&gt;Language Model Interpolation
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;n 元语法插值法：加权融合不同阶数 n 元语法的概率&lt;/strong&gt;，避免高阶的n元语法零概率导致的预测失效。&lt;/p&gt;
&lt;p&gt;加权的$\lambda$应该设置成多少呢？可以从预留集held-out corpus中学习。使用EM（期望最大化）算法来学习。&lt;/p&gt;
&lt;h4 id=&#34;stupid-backoff&#34;&gt;Stupid Backoff
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;回退模型&lt;/strong&gt;：高阶n阶的模型无法使用的时候，回退到低阶模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discount&lt;/strong&gt;：要让回退模型（backoff model）输出合理的概率分布，我们必须对高阶 n 元语法的概率进行 “折扣处理”（discount），从而预留出部分概率余量（probability mass），供低阶 n 元语法使用。但在实际应用中，人们常使用一种更简单的 “无折扣回退算法”—— 即名为&lt;strong&gt;Stupid Backoff&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;advanced-perplexitys-relation-to-entropy&#34;&gt;Advanced: Perplexity&amp;rsquo;s Relation to Entropy
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;熵&lt;/strong&gt;：不确定性的度量方式。可以理解是编码某个决策或某条信息所需的最小平均比特数。越不确定，熵越大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;熵率&lt;/strong&gt;：平均的不确定性。自然语言的熵率定义为 “&lt;strong&gt;无限长序列中，每个词的平均熵&lt;/strong&gt;”，反映语言的长期不确定性。例如，英文的熵率约 1-2 比特 / 词，意味着平均每个词需要 1-2 比特来编码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;平稳性&lt;/strong&gt;：序列概率不随着时间改变。自然语言不是，但是N元语法是平稳的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;遍历性&lt;/strong&gt;：长序列中包含了所有的短序列。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shannon-McMillan-Breiman theorem&lt;/strong&gt;：如果语言满足某些正则条件（准确地说，是平稳且遍历的），&lt;strong&gt;序列长度趋近于无穷大时，“序列的平均对数概率的负值” ，即经验熵率会以概率1收敛敛到该过程的理论熵率&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交叉熵（Cross-Entropy）&lt;/strong&gt;：我们虽然不知道数据的真实概率分布p，但是可以用模型m来近似p。（即我们虽然不知道自然语言的真实情况，但是可以用N元语法来近似。）&lt;strong&gt;交叉熵越小，模型越接近真实分布&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;困惑度&lt;/strong&gt;：&lt;strong&gt;困惑度是熵的指数形式&lt;/strong&gt;。比较直观。&lt;/p&gt;
&lt;h3 id=&#34;excercies&#34;&gt;Excercies
&lt;/h3&gt;&lt;h5 id=&#34;31&#34;&gt;3.1
&lt;/h5&gt;&lt;p&gt;Write out the equation for trigram probability estimation (modifying Eq. 3.11). Now write out all the non-zero trigram probabilities for the I am Sam corpus on page 40.&lt;/p&gt;
&lt;h5 id=&#34;32&#34;&gt;3.2
&lt;/h5&gt;&lt;p&gt;Calculate the probability of the sentence &lt;code&gt;i want chinese food&lt;/code&gt;. Give two probabilities, one using Fig. 3.2 and the ‘useful probabilities’ just below it on page 42, and another using the add-1 smoothed table in Fig. 3.7. Assume the additional add-1 smoothed probabilities $P(i|&amp;lt;s&amp;gt;) = 0.19$ and $P(&amp;lt;/s&amp;gt;|food) = 0.40$.&lt;/p&gt;
&lt;h5 id=&#34;33&#34;&gt;3.3
&lt;/h5&gt;&lt;p&gt;Which of the two probabilities you computed in the previous exercise is higher, unsmoothed or smoothed? Explain why.&lt;/p&gt;
&lt;h5 id=&#34;34&#34;&gt;3.4
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using a bigram language model with add-one smoothing, what is $P(Sam | am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;35&#34;&gt;3.5
&lt;/h5&gt;&lt;p&gt;Suppose we didn’t use the end-symbol $&amp;lt;/s&amp;gt;$. Train an unsmoothed bigram grammar on the following training corpus without using the end-symbol $&amp;lt;/s&amp;gt;$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b b  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; b a  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; a a
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Demonstrate that your bigram model does not assign a single probability distribution across all sentence lengths by showing that the sum of the probability of the four possible 2 word sentences over the alphabet a,b is 1.0, and the sum of the probability of all possible 3 word sentences over the alphabet a,b is also 1.0.&lt;/p&gt;
&lt;h5 id=&#34;36&#34;&gt;3.6
&lt;/h5&gt;&lt;p&gt;Suppose we train a trigram language model with add-one smoothing on a given corpus. The corpus contains V word types. Express a formula for estimating $P(w3|w1,w2)$, where $w3$ is a word which follows the bigram$ (w1,w2)$, in terms of various n-gram counts and V. Use the notation $c(w1,w2,w3)$ to denote the number of times that trigram $(w1,w2,w3)$ occurs in the corpus, and so on for bigrams and unigrams.&lt;/p&gt;
&lt;h5 id=&#34;37&#34;&gt;3.7
&lt;/h5&gt;&lt;p&gt;We are given the following corpus, modified from the one in the chapter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;lt;s&amp;gt; I do not like green eggs and Sam &amp;lt;/s&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we use linear interpolation smoothing between a maximum-likelihood bigram model and a maximum-likelihood unigram model with $λ₁ = 1/2$ and $λ₂ = 1/2,$ what is $P(Sam|am)$? Include $&amp;lt;s&amp;gt;$ and $&amp;lt;/s&amp;gt;$ in your counts just like any other token.&lt;/p&gt;
&lt;h5 id=&#34;38&#34;&gt;3.8
&lt;/h5&gt;&lt;p&gt;Write a program to compute unsmoothed unigrams and bigrams.&lt;/p&gt;
&lt;h5 id=&#34;39&#34;&gt;3.9
&lt;/h5&gt;&lt;p&gt;Run your n-gram program on two different small corpora of your choice (you might use email text or newsgroups). Now compare the statistics of the two corpora. What are the differences in the most common unigrams between the two? How about interesting differences in bigrams?&lt;/p&gt;
&lt;h5 id=&#34;310&#34;&gt;3.10
&lt;/h5&gt;&lt;p&gt;Add an option to your program to generate random sentences.&lt;/p&gt;
&lt;h5 id=&#34;311&#34;&gt;3.11
&lt;/h5&gt;&lt;p&gt;Add an option to your program to compute the perplexity of a test set.&lt;/p&gt;
&lt;h5 id=&#34;312&#34;&gt;3.12
&lt;/h5&gt;&lt;p&gt;You are given a training set of 100 numbers that consists of 91 zeros and 1 each of the other digits 1-9. Now we see the following test set: 0 0 0 0 0 3 0 0 0 0. What is the unigram perplexity?&lt;/p&gt;
&lt;h2 id=&#34;logistic-regression-and-text-classification&#34;&gt;Logistic Regression and Text Classification
&lt;/h2&gt;&lt;p&gt;经典任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sentiment analysis&lt;/li&gt;
&lt;li&gt;spam detection&lt;/li&gt;
&lt;li&gt;language id&lt;/li&gt;
&lt;li&gt;authorship attribution&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;machine-learning-and-classification&#34;&gt;Machine Learning and Classification
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;人工规则很脆弱，数据一变化就无法使用&lt;/li&gt;
&lt;li&gt;LLM的弱点：幻觉、无法解释。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此最常见的分类方法是&lt;strong&gt;有监督机器学习&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;概率分类器：输出&lt;strong&gt;样本属于每个类别的概率&lt;/strong&gt;而不是类别标签，保证在合并的系统里不过早地输出结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分类器的核心组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A feature representation of the input&lt;/li&gt;
&lt;li&gt;A classificaition function that computes $\hat{y}$&lt;/li&gt;
&lt;li&gt;An objective funcion that we want to potimize for learning
&lt;ul&gt;
&lt;li&gt;loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An algorithm for optimizing the objective function
&lt;ul&gt;
&lt;li&gt;stochastic gradient descent algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-sigmoid-function&#34;&gt;The Sigmoid Function
&lt;/h3&gt;&lt;p&gt;二分类逻辑回归的目标是：计算样本属于正类的概率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一步：计算线性得分$z=w⋅x+b$，值域为$[-\infty, +\infty ]$&lt;/li&gt;
&lt;li&gt;第二步：&lt;strong&gt;通过 Sigmoid 函数转换为概率&lt;/strong&gt;：  将线性得分 z 映射到 $[0,1] $区间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$z$常常被称作Logit（对数几率）。Logit就是Sigmoid的反函数。可以提醒我们后续要加上Sigmoid进行转换，因为$z$并不是一个真实的值。&lt;/p&gt;
&lt;h3 id=&#34;classification-with-logistic-regression&#34;&gt;Classification with Logistic Regression
&lt;/h3&gt;&lt;p&gt;当概率大于0.5的时候，就把它分类到正类里。&lt;/p&gt;
&lt;h4 id=&#34;sentiment-classification&#34;&gt;Sentiment Classification
&lt;/h4&gt;&lt;p&gt;举了一个例子。&lt;/p&gt;
&lt;h4 id=&#34;other-classification-tasks-and-features&#34;&gt;Other Classification Tasks and Features
&lt;/h4&gt;&lt;p&gt;Period disambiguation：确定句号是EOS还是其他。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Designing v.s. Learning features：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;刚刚的例子，特征都是人工设计的。此外还有：
&lt;ul&gt;
&lt;li&gt;feaure interactions：基础特征组合成的复杂特征&lt;/li&gt;
&lt;li&gt;feature templates：抽象的特征规范来定义特征。这里的特征空间是稀疏的，此外特征一般是字符串描述的Hash值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;人工设计太复杂了。因此现代的NLP系统都是用Representation Learning来解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;standardize和normalize。&lt;/p&gt;
&lt;h4 id=&#34;processing-many-examples-at-once&#34;&gt;Processing many examples at once
&lt;/h4&gt;&lt;p&gt;如果有许多的值要计算，可以使用matrix arithmetic来一次计算完。&lt;/p&gt;
&lt;h3 id=&#34;multinomial-logistic-regression&#34;&gt;Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;多项逻辑回归也称softmax regression，老的教材上也叫maxent clasifier。&lt;/p&gt;
&lt;p&gt;在多项逻辑回归中，直接输出结果而不是一个概率值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hard classification&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;softmax&#34;&gt;Softmax
&lt;/h4&gt;&lt;p&gt;Sigmoid函数在多分类情况下的推广。&lt;/p&gt;
&lt;h4 id=&#34;applying-softmax-in-logistic-regression&#34;&gt;Applying Softmax in Logistic Regression
&lt;/h4&gt;&lt;p&gt;可以使用矩阵运算方式加快计算。&lt;/p&gt;
$$\hat{y}=softmax(Wx+b)$$&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2506.11035&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Doumbouya et al., 2025&lt;/a&gt;是这么认为的：逻辑回归将矩阵的每一行 $w_k$视为&lt;strong&gt;第 $k$ 类的原型（prototype）&lt;/strong&gt;，由于两个向量的相似度越高，它们的点积（dot product）值就越大，因此点积可作为衡量向量相似度的函数。模型最终将输入分配给相似度最高的类别。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;features-in-multinomial-logistic-regression&#34;&gt;Features in Multinomial Logistic Regression
&lt;/h4&gt;&lt;p&gt;特征权重同时依赖于输入文本和输出类别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597.png&#34;
	width=&#34;744&#34;
	height=&#34;837&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_dcd37b06fe097e65.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830163440597_hu_87f8d0d9a05a6baf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;213px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;learning-in-logistic-regression&#34;&gt;Learning in Logistic Regression
&lt;/h3&gt;&lt;p&gt;逻辑回归是如何实现学习的？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使system output（classifier output）和gold output（correct output）越接近越好。两者之间的距离可以称作&lt;strong&gt;损失函数&lt;/strong&gt;或者&lt;strong&gt;代价函数&lt;/strong&gt;。下面介绍交叉熵。&lt;/li&gt;
&lt;li&gt;需要一个算法来最小化损失函数。下面介绍随机梯度下降算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-cross-entropy-loss-function&#34;&gt;The Cross-entropy Loss Function
&lt;/h3&gt;&lt;p&gt;条件最大似然估计：在给定$x$下，选择参数$w$和$b$使得$y$的对数概率最大。&lt;/p&gt;
&lt;p&gt;这里损失函数是&lt;strong&gt;负对数似然损失（negative log likelihood loss）&lt;/strong&gt;，通常也被称为&lt;strong&gt;交叉熵损失（cross-entropy loss）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;介绍了一下为什么&lt;strong&gt;最小化交叉熵损失可以使得真实分布和预测分布更加接近&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent
&lt;/h3&gt;&lt;p&gt;梯度下降算法的原理。介绍了梯度、学习率。&lt;/p&gt;
&lt;h4 id=&#34;the-gradient-for-logistic-regression&#34;&gt;The Gradient for Logistic Regression
&lt;/h4&gt;&lt;p&gt;逻辑回归的梯度就是
&lt;/p&gt;
$$\frac{\partial L_{\mathrm{CE}}(\hat{y},y)}{\partial w_{j}}=-(y-\hat{y})x_{j}$$&lt;p&gt;
也就是预测值$\hat{y}$和实际值$y$之间的差乘输入值$x_j$。&lt;/p&gt;
&lt;h4 id=&#34;the-stochastic-gradient-descent-algorithm&#34;&gt;The Stochastic Gradient Descent Algorithm
&lt;/h4&gt;&lt;p&gt;随机梯度下降算法是一种在线算法，可以边接收数据边学习。&lt;/p&gt;
&lt;p&gt;SGD每次用&lt;strong&gt;单个随机样本&lt;/strong&gt;计算梯度。&lt;/p&gt;
&lt;h4 id=&#34;mini-batch-training&#34;&gt;Mini-batch Training
&lt;/h4&gt;&lt;p&gt;batch training和mini-batch training的区别。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch gradient：所有的随机样本计算梯度。&lt;/li&gt;
&lt;li&gt;mini-batch gradient：小批量梯度下降算法。每次选择&lt;strong&gt;一小批随机样本&lt;/strong&gt;计算梯度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learning-in-multinomial-logistic-regression&#34;&gt;Learning in Multinomial Logistic Regression
&lt;/h3&gt;&lt;p&gt;多项式逻辑回归其实和二项式逻辑回归差不多。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本质是使用独热标签+概率向量的形式进行计算。&lt;/li&gt;
&lt;li&gt;核心是 “对正确类别的预测概率取负对数”，得到交叉熵损失，其越小则预测概率越高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-precision-recall-f-measure&#34;&gt;Evaluation: Precision, Recall, F-measure
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;confusion matrix&lt;/li&gt;
&lt;li&gt;accuracy&lt;/li&gt;
&lt;li&gt;precision&lt;/li&gt;
&lt;li&gt;recall&lt;/li&gt;
&lt;li&gt;F-measure
&lt;ul&gt;
&lt;li&gt;F1&lt;/li&gt;
&lt;li&gt;a weighted harmonic mean of precision and recall.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893.png&#34;
	width=&#34;928&#34;
	height=&#34;394&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_5b835770261a7097.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830172049893_hu_9163edd8010643ed.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;microaveraging v.s. macroaveraging&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微观平均：更关注 “整体样本的预测准确性”，&lt;strong&gt;少数类错判代价低于多数类&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;宏观平均：更关注所有的类的错判代价的公平，&lt;strong&gt;少数类和多数类的代价相等&lt;/strong&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005.png&#34;
	width=&#34;1084&#34;
	height=&#34;468&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_bca6ffdfb72f8971.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173257005_hu_899e55b55133737a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;555px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;test-sets-and-cross-validation&#34;&gt;Test sets and Cross-validation
&lt;/h3&gt;&lt;p&gt;Cross-validation：解决测试集不足的问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;固定训练集和测试集。&lt;/li&gt;
&lt;li&gt;训练集中进行分割。
&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382.png&#34;
	width=&#34;895&#34;
	height=&#34;462&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_4558bdf3b4166cbe.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830173844382_hu_e53d98bd5ba967c8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;statistical-significance-testing&#34;&gt;Statistical Significance Testing
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;统计显著性检验&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不只是简单地检查A在测试集上的结果$M(A,x)$好于B在测试集上的结果$M(B,x)$。如果差很小的话，其实不一定能证明A的结果比B小，不具有统计学上的显著性。&lt;/li&gt;
&lt;li&gt;设计一个效应量$\delta (x)=M(A,x)-M(B,x)$，原假设是$H_0 :\delta (x)\leq 0$。这样计算p值是否小于阈值可以得出是否显著性地A比B要好。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在NLP中，一般不用ANOVAs或者t检验，而是使用非参数检验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;近似随机化检验&lt;/strong&gt;（Approximate Randomization Test）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bootstrap 检验&lt;/strong&gt;（Bootstrap Test）&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;方差分析和t检验都需要有假设：方差齐性或数据服从正态分布。所以只能用非参数检验。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;the-paired-bootstrap-test&#34;&gt;The Paired Bootstrap Test
&lt;/h4&gt;&lt;p&gt;Bootstrap 检验的核心是 “重抽样”—— 从原始测试集&lt;code&gt;x&lt;/code&gt;中&lt;strong&gt;有放回地随机抽取&lt;/strong&gt;生成新的测试集。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970.png&#34;
	width=&#34;1097&#34;
	height=&#34;490&#34;
	srcset=&#34;https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_8f406568f15b6414.png 480w, https://ionfeather.github.io/2025/speech-and-language-processing/assets/IMG-20250830181020970_hu_c48413deb765f0e1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;
在新的测试集上，P 值等于 “重抽样测试集中，$d(x^{(i)})≥2d(x)$的数量占总重抽样次数b的比例”。&lt;strong&gt;判断此时的p值是否低于阈值就可以判断出是否是数据集本身的偏差导致了A比B要结果好。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LLM的解释：Bootstrap 重抽样，就是在 “不改变天平初始倾斜（测试集偏向）” 的前提下，反复放 “随机重量（重抽样的样本）”，看左边会比右边多低多少格 —— 如果只是天平本身歪了，随机放重量时，左边最多低 2 格左右（常规波动）；如果左边真的更重，就可能低 4 格以上（极端情况）。这种极端情况多了，超过了阈值，我们就更相信是天平本身的问题。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;avoiding-harms-in-classification&#34;&gt;Avoiding Harms in Classification
&lt;/h3&gt;&lt;p&gt;representational harms：由于对特定社会群体的贬低或刻板印象导致的伤害。&lt;/p&gt;
&lt;p&gt;toxic detection&lt;/p&gt;
&lt;p&gt;model card&lt;/p&gt;
&lt;h3 id=&#34;interpereting-models&#34;&gt;Interpereting Models
&lt;/h3&gt;&lt;p&gt;模型的可解释性也是很重要的。逻辑回归就是比较好的可解释的模型。&lt;/p&gt;
&lt;h3 id=&#34;advanced-regularization&#34;&gt;Advanced: Regularization
&lt;/h3&gt;&lt;p&gt;regularization来解决过拟合的问题，提高模型泛化能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2 regulaization&lt;/li&gt;
&lt;li&gt;L1 regulaization&lt;/li&gt;
&lt;li&gt;lasso&lt;/li&gt;
&lt;li&gt;ridge&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>AIDR | Reasoning-based Drug Repurposing</title>
        <link>https://ionfeather.github.io/2025/rbdr/</link>
        <pubDate>Tue, 10 Jun 2025 14:24:22 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/rbdr/</guid>
        <description>&lt;h2 id=&#34;reasoning-based-drug-repurposing&#34;&gt;Reasoning-based drug repurposing
&lt;/h2&gt;&lt;h3 id=&#34;问题回答&#34;&gt;问题&amp;amp;回答
&lt;/h3&gt;&lt;h4 id=&#34;问题&#34;&gt;问题
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;LLM在Repurposing中的应用情况&lt;/li&gt;
&lt;li&gt;是否有基于文本结构，引入大模型知识作为一部分特征？&lt;/li&gt;
&lt;li&gt;测试集是什么&lt;/li&gt;
&lt;li&gt;传统模型/基于网络的模型的准确率&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;回答&#34;&gt;回答
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;有两种情况。第一种，引入LLM后的文本信息作为向量嵌入到GNN中；第二种，LLM作为筛选数据的方法，从数据层面提升最终效果。&lt;/li&gt;
&lt;li&gt;有的。将文本以特定的形式组织，如&amp;quot;药物A[SEP]疾病B&amp;quot;，然后将其变成向量，嵌入到GNN中。&lt;/li&gt;
&lt;li&gt;阅读了几篇，测试集有
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/xiangyue9607/SCMFDD&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;B-dataset&lt;/a&gt;（SCMFDD-S/L）：来自于 &lt;a class=&#34;link&#34; href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text&lt;/a&gt;，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了 SCMFDD-S 和 SCMFDD-L 数据集，其中的前者是这里的 B-dataset，适用于常规场景。&lt;/li&gt;
&lt;li&gt;C-dataset：来自于 &lt;a class=&#34;link&#34; href=&#34;https://academic.oup.com/bioinformatics/article/32/17/2664/2450730&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic&lt;/a&gt;，由 Dndataset 和 F-dataset 整合而成，结合了药物的 ATC 编码和疾病的 DO 术语。包含 963 种药物、1263 种疾病和 54921 个药物-疾病关系。适用于多源数据融合场景。&lt;/li&gt;
&lt;li&gt;F-dataset：来自于 &lt;a class=&#34;link&#34; href=&#34;https://www.embopress.org/doi/full/10.1038/msb.2011.26&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology&lt;/a&gt;，侧重于模型对文本知识的分析能力。&lt;/li&gt;
&lt;li&gt;R-dataset：整合 C-dataset、F-dataset 和 KEGG 数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;模型准确率在不同的数据集上不同。这里的B、C、F数据集使用得比较多，一般来说衡量标准是AUC、AUPR、F1-score和Precision。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;action&#34;&gt;Action
&lt;/h3&gt;&lt;h4 id=&#34;week&#34;&gt;Week
&lt;/h4&gt;&lt;p&gt;week1&lt;/p&gt;
&lt;p&gt;相关论文调研： 是否有用大模型推理在repurposing里做的？ 是否有基于文本&amp;amp;结构特征做repurposing，然后把大模型reasoning的知识作为一部分feature加入，能够提升其效果，&lt;strong&gt;找出可复现的工作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;week2&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;找出可复现的工作（上周遗留）&lt;/strong&gt;， repurposing任务的测试集是什么？ 在这个测试集上 传统大模型是多少准确率，基于网络的方式是多少准确率？&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;相关论文调研&#34;&gt;相关论文调研
&lt;/h2&gt;&lt;h3 id=&#34;llm-dda&#34;&gt;LLM-DDA
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pubmed.ncbi.nlm.nih.gov/39325266/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Empowering Graph Neural Network-Based Computational Drug Repositioning with Large Language Model-Inferred Knowledge Representation - PubMed&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;问题与回答&#34;&gt;问题与回答
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Q1. LLM在Repurposing中的应用情况&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;LLM的推理信息在这里被引入了GNN中作为一部分特征&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;文本结构经过LLM编码后的向量，引入到GNN网络中&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q3. 测试集是什么&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;见下面的数据集部分。一共使用了四个数据集。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q4. 传统模型/基于网络的模型的准确率&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;与下面四种baseline进行比较
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;机器学习方法&lt;/strong&gt;：DDA-SKF、NIMCGCN；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵分解方法&lt;/strong&gt;：SCPMF、DRWBNCF；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习/GNN方法&lt;/strong&gt;：REDDA、LAGCN、HDGAT&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM&lt;/strong&gt; &lt;strong&gt;直接预测&lt;/strong&gt;DirectPred&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里的前三种就是传统模型等其他方法。在下方的结果处说明了AUC、AUPR、F1-score和Precision的值。&lt;/p&gt;
&lt;h4 id=&#34;解决的问题&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;现有图神经网络（GNN）方法过度依赖网络拓扑结构，受限于不完整、含噪声的网络数据，且忽略生物医学领域丰富知识的问题。通过整合大语言模型（LLM）推断的知识表示，提升 DDA 预测的准确性和可靠性。&lt;/p&gt;
&lt;h4 id=&#34;面临挑战&#34;&gt;面临挑战
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;数据层面：传统GNN方法以来药物-疾病异构网络存在稀疏性和标签不平衡的问题&lt;/li&gt;
&lt;li&gt;模型层面：现有方法难以捕捉复杂关联&lt;/li&gt;
&lt;li&gt;知识利用：LLM生成的离散文本如何转化为适合GNN推理的连续数值表示，并设计高效融合架构&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;核心方法&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610205120.png&#34;
	width=&#34;6581&#34;
	height=&#34;4831&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610205120_hu_6c6d8334202a82d6.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610205120_hu_c9f818906ad62097.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;流程图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;326px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TL;DR：关键在于&lt;strong&gt;知识挖掘（LLM 提示）→ 语义编码（嵌入生成）→ 图模型融合（关联预测）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Step1：构建异质网络&lt;/p&gt;
&lt;p&gt;Step2：利用LLM的知识来拓展潜在知识&lt;/p&gt;
&lt;p&gt;Step3：基于LLM的嵌入生成&lt;/p&gt;
&lt;p&gt;Step4：构建LLM-DDA模型&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;一、药物-疾病异质网络构建（Drug-disease heterogeneous network construction）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据来源&lt;/strong&gt;：整合 DrugBank（药物数据库 ）、OMIM（人类孟德尔遗传数据库 ）、MeSH（医学主题词表 ）等生物医学数据库 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建逻辑&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;先计算 &lt;strong&gt;药物-药物、疾病-疾病的成对相似度（Pairwise similarities）&lt;/strong&gt;（如化学结构、基因功能相似性 ）。&lt;/li&gt;
&lt;li&gt;再结合已知 &lt;strong&gt;药物-疾病关联（Drug-disease associations）&lt;/strong&gt; ，构建成包含药物、疾病节点，以及相似度、关联关系边的&lt;strong&gt;异质图网络&lt;/strong&gt; ，为后续分析提供拓扑结构基础。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二、零样本提示工程（Zero-shot prompt engineering）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心动作&lt;/strong&gt;：设计 &lt;strong&gt;基于化学生物特征的提示模板（Chemobiomedical characteristics-based prompt template design）&lt;/strong&gt; ，把药物 / 疾病的专业属性（如靶点、作用通路、临床特征等 ）转化为大语言模型（LLM）可理解的指令。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;功能价值&lt;/strong&gt;：借助 GPT-4 的知识推理能力，&lt;strong&gt;生成目标药物 / 疾病的详细描述&lt;/strong&gt; ，挖掘数据库外的潜在知识关联，引入LLM知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;三、基于 LLM 的嵌入生成&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;双模型进行嵌入生成&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;用 &lt;strong&gt;ChatGPT-4 Turbo&lt;/strong&gt;（通用大模型）、&lt;strong&gt;BioBERTpt&lt;/strong&gt;（生物医学专用预训练模型 ），对 GPT-4 生成的文本描述做编码。&lt;/li&gt;
&lt;li&gt;输出 &lt;strong&gt;LLM 嵌入&lt;/strong&gt;，把生物医学语义信息转化为数值向量，让后续图模型能 理解语言知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;四、LLM-DDA 模型构建（LLM-DDA model construction）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多架构覆盖&lt;/strong&gt;：提供 3 种融合策略，适配不同场景需求：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LLM-DDA (node feat)&lt;/strong&gt;：直接把 LLM 嵌入作为节点特征，融入传统图神经网络，轻量且易部署。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM-DDA (graph-graph)&lt;/strong&gt;：双图网络并行，分别处理 LLM 嵌入图与原始异质图，再融合结果，强化多源信息互补。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM-DDA (graph-ae)&lt;/strong&gt;：结合图自动编码器（Graph-AE），优化嵌入特征与拓扑结构的融合，适合挖掘深层关联。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入衔接&lt;/strong&gt;：模型输入关联两部分：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Similarity features&lt;/strong&gt;（相似度特征 ）：来自第一步异质网络的拓扑计算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adjacency matrix&lt;/strong&gt;（邻接矩阵）：刻画药物-疾病的关联结构，让模型同时学习知识语义（LLM 嵌入）和网络拓扑（图结构），提升药物-疾病关联预测精度。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据集&#34;&gt;数据集
&lt;/h4&gt;&lt;p&gt;四个药物-疾病的基准数据集&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Dataset&lt;/th&gt;
          &lt;th&gt;Drugs&lt;/th&gt;
          &lt;th&gt;Diseases&lt;/th&gt;
          &lt;th&gt;Drug-disease Associations&lt;/th&gt;
          &lt;th&gt;Pos-Neg Ratio&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;B-dataset&lt;/td&gt;
          &lt;td&gt;269&lt;/td&gt;
          &lt;td&gt;598&lt;/td&gt;
          &lt;td&gt;18,416&lt;/td&gt;
          &lt;td&gt;11.45%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;C-dataset&lt;/td&gt;
          &lt;td&gt;663&lt;/td&gt;
          &lt;td&gt;409&lt;/td&gt;
          &lt;td&gt;2,532&lt;/td&gt;
          &lt;td&gt;1.57%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;F-dataset&lt;/td&gt;
          &lt;td&gt;593&lt;/td&gt;
          &lt;td&gt;313&lt;/td&gt;
          &lt;td&gt;1,933&lt;/td&gt;
          &lt;td&gt;1.05%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;R-dataset&lt;/td&gt;
          &lt;td&gt;894&lt;/td&gt;
          &lt;td&gt;454&lt;/td&gt;
          &lt;td&gt;2,704&lt;/td&gt;
          &lt;td&gt;0.67%&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/xiangyue9607/SCMFDD&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;B-dataset&lt;/a&gt;：来自于&lt;a class=&#34;link&#34; href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text&lt;/a&gt;，这篇文章里主要介绍了一个相似性约束矩阵分解的方法，里面编制了SCMFDD-S和SCMFDD-L数据集，其中的前者是这里的B-dataset，适用于常规场景。&lt;/li&gt;
&lt;li&gt;C-dataset：来自于&lt;a class=&#34;link&#34; href=&#34;https://academic.oup.com/bioinformatics/article/32/17/2664/2450730&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Drug repositioning based on comprehensive similarity measures and Bi-Random walk algorithm | Bioinformatics | Oxford Academic&lt;/a&gt;，由Dndataset和F-dataset整合而成，结合了药物的ATC编码和疾病的DO术语。适用于多源数据融合场景。&lt;/li&gt;
&lt;li&gt;F-dataset：来自于&lt;a class=&#34;link&#34; href=&#34;https://www.embopress.org/doi/full/10.1038/msb.2011.26&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PREDICT: a method for inferring novel drug indications with application to personalized medicine | Molecular Systems Biology&lt;/a&gt;，侧重于模型对文本知识的分析能力。&lt;/li&gt;
&lt;li&gt;R-dataset：本文自己提出。整合C-dataset、F-dataset和KEGG数据库的信息，用于极端稀疏和不平衡数据下的鲁棒性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;指标结果&#34;&gt;指标结果
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;AUC、AUPR、F1和五折交叉验证结果&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610223319.png&#34;
	width=&#34;1506&#34;
	height=&#34;988&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610223319_hu_75ab593fb94ec12.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610223319_hu_9c85fcc86562cfbc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;四个数据集下的三种不同方法的效果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;365px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;与下面四种baseline进行比较
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;机器学习方法&lt;/strong&gt;：DDA-SKF、NIMCGCN；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵分解方法&lt;/strong&gt;：SCPMF、DRWBNCF；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习/GNN方法&lt;/strong&gt;：REDDA、LAGCN、HDGAT&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM&lt;/strong&gt; &lt;strong&gt;直接预测&lt;/strong&gt;DirectPred&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分别通过AUC、AUPR、F1-score和Precision来判断效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610223616.png&#34;
	width=&#34;944&#34;
	height=&#34;792&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610223616_hu_a1df0349a4cb82ee.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610223616_hu_b6a9867fa2330ad1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;最优模型为粗体，次优为下划线&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;119&#34;
		data-flex-basis=&#34;286px&#34;
	
&gt;&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610224129.png&#34;
	width=&#34;469&#34;
	height=&#34;359&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610224129_hu_32afd63a86e7361.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610224129_hu_253c0f489a0df0dd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;最终平均结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;130&#34;
		data-flex-basis=&#34;313px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;lbmff&#34;&gt;LBMFF
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2023.1205144/full&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Frontiers | Drug–disease association prediction with literature based multi-feature fusion&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;问题与回答-1&#34;&gt;问题与回答
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Q1. LLM在Repurposing中的应用情况&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这里使用了BERT来挖掘文献中的关联关系。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;BERT经过预训练和微调之后，能够学习文献中的一些关联关系，输出包含&lt;strong&gt;语义关联信息的向量表示&lt;/strong&gt;，从而文献中的药物-药物相似性关系和疾病-疾病相似性关系知识。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q3. 测试集是什么&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;见下面的数据集部分。一共使用了两个数据集。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q4. 传统模型/基于网络的模型的准确率&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对比的模型分为如下部分，都是各自领域的SOTA模型。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;图神经网络（GNN）&lt;/strong&gt;：DRHGCN、LAGCN、REDDA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵分解与正则化&lt;/strong&gt;：BNNR、DRWBNCF&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵补全与神经归纳&lt;/strong&gt;：NIMCGCN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;核融合与传统机器学习&lt;/strong&gt;：DDA-SKF&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对比结果如研究结果部分所示。&lt;/p&gt;
&lt;h4 id=&#34;解决的问题-1&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;药物重定位中的关联预测问题&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;面临的挑战&#34;&gt;面临的挑战
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;文献信息利用不够充分：现在大多数计算方法都是依赖结构化数据库，但是科学文献中有很多未被充分挖掘的药物-疾病关联关系。&lt;/li&gt;
&lt;li&gt;多特征难以有效融合：药物和疾病的特征具有异质性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;核心方法-1&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;提出了LBMFF（基于文献的多特征融合方法）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多源融合&lt;/strong&gt;：同时用结构化数据库（Drugbank、SIDER 等）和非结构化文献（BERT 处理），挖掘更全面的药物-疾病关联。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图网络 + 注意力&lt;/strong&gt;：用 GCN 处理 “药物-疾病” 关联的图结构，注意力机制强化关键特征，提升预测准确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611145238.png&#34;
	width=&#34;1014&#34;
	height=&#34;778&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611145238_hu_a0419756e480ffda.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250611145238_hu_790c8b92f59e5590.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;130&#34;
		data-flex-basis=&#34;312px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相似性计算
&lt;ul&gt;
&lt;li&gt;从&lt;strong&gt;多源数据&lt;/strong&gt;提取特征，计算药物、疾病的相似性，构建关联矩阵&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;药物相似性&lt;/strong&gt;（Drug-Drug）：&lt;br&gt;
整合 3 类结构化数据 + 文献语义：
&lt;ul&gt;
&lt;li&gt;化学结构（Drugbank 数据库，药物分子结构）&lt;/li&gt;
&lt;li&gt;副作用（SIDER 数据库，药物-副作用关联）&lt;/li&gt;
&lt;li&gt;靶点（Drugbank 数据库，药物-靶点关联）&lt;/li&gt;
&lt;li&gt;文献语义（BERT 模型处理文献，挖掘药物间语义关联）&lt;br&gt;
最终加权融合（α、β、γ 为权重），输出&lt;strong&gt;药物相似性矩阵&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;疾病相似性&lt;/strong&gt;（Disease-Disease）：&lt;br&gt;
整合 2 类数据：
-MeSH 数据库（疾病树编号，疾病分类体系）
&lt;ul&gt;
&lt;li&gt;文献语义（BERT 模型处理文献，挖掘疾病间语义关联）&lt;br&gt;
输出&lt;strong&gt;疾病相似性矩阵&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;药物-疾病关联&lt;/strong&gt;（Drug-Disease）：&lt;br&gt;
直接从 CTD 数据库（比较毒理学数据库）获取&lt;strong&gt;已知关联矩阵&lt;/strong&gt;，标记已验证的药物-疾病对。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特征表示
&lt;ul&gt;
&lt;li&gt;将上一步得到的 &lt;strong&gt;药物相似性矩阵、疾病相似性矩阵、已知关联矩阵&lt;/strong&gt; 拼接，形成模型输入的&lt;strong&gt;融合特征矩阵&lt;/strong&gt;，统一表征药物和疾病的多源信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;编码器
&lt;ul&gt;
&lt;li&gt;用&lt;strong&gt;带注意力机制的图卷积网络（GCN）&lt;/strong&gt; 学习药物、疾病的嵌入表示：&lt;/li&gt;
&lt;li&gt;两层 GCN（Graph Convolution Encoder Layer）逐层提取特征，ReLU 激活增加非线性。&lt;/li&gt;
&lt;li&gt;注意力机制（Attention mechanism）动态分配权重，突出关键特征（比如强关联的药物-疾病对）。&lt;/li&gt;
&lt;li&gt;最终输出 &lt;strong&gt;药物 + 疾病的嵌入向量&lt;/strong&gt;（维度 (m + n)×d ，m 是药物数，n 是疾病数，d 是嵌入维度 ）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;解码器
&lt;ul&gt;
&lt;li&gt;通过&lt;strong&gt;矩阵乘法&lt;/strong&gt;还原关联预测：
&lt;ul&gt;
&lt;li&gt;药物嵌入（$Eₘₓ×d$ ）、权重矩阵（$W_d×d$ ）、疾病嵌入（$Eₙₓ×d $）相乘，重建药物-疾病关联得分。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;预测输出&lt;strong&gt;潜在关联&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;实线：已知关联（来自 CTD 数据库）。&lt;/li&gt;
&lt;li&gt;虚线：模型预测的&lt;strong&gt;潜在关联&lt;/strong&gt;（未被验证，但算法判定有高可能性的药物-疾病对 ），可辅助药物重定位研究。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;bert在文中&#34;&gt;BERT在文中
&lt;/h5&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611151737.png&#34;
	width=&#34;1010&#34;
	height=&#34;482&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611151737_hu_78901334681f4864.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250611151737_hu_989e86a68a8680fd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;502px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预训练&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据准备&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;筛选包含药物、疾病名称的科学文献（如从 PubMed 获取，文中提到的 673,665 篇相关文献 ），这些文献包含药物-疾病关联的语义描述（如治疗、关联、机制等表述 ）。&lt;/li&gt;
&lt;li&gt;将文献中疾病、药物相关文本构建为“药物文本-疾病文本” 对作为输入序列。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Masked LM&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;让BERT预测被遮盖内容，如[MASK]可以治疗糖尿病，需要推断出是药物X。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NSP&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;真实对：药物A[SEP]疾病B&lt;/li&gt;
&lt;li&gt;虚假对：药物C[SEP] 疾病D&lt;/li&gt;
&lt;li&gt;需要判断文本对是否是真实对&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;模型微调&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;使用CTD等数据库中已知的药物-疾病关联对。存在关联为正例，无关联为负例&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输出语义特征&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;经过预训练 + 微调后，BERT 对输入的 “药物-疾病文本对”，会输出包含&lt;strong&gt;语义关联信息的向量表示&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;研究结果&#34;&gt;研究结果
&lt;/h4&gt;&lt;h5 id=&#34;测试集&#34;&gt;测试集
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Zhang（SCMFDD-S）：来自于&lt;a class=&#34;link&#34; href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2220-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Predicting drug-disease associations by using similarity constrained matrix factorization | BMC Bioinformatics | Full Text&lt;/a&gt;，在上面被称为B-dataset。包含269种药物、598种疾病和18416个药物-疾病关系。本文中还从其他数据库中填充了化学结构、药物-靶点关系和药物副作用、疾病树作为药物-药物相似性度量的数据。&lt;/li&gt;
&lt;li&gt;TL-HGBI：来自于&lt;a class=&#34;link&#34; href=&#34;https://academic.oup.com/bioinformatics/article/30/20/2923/2422178&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Drug repositioning by integrating target information through a heterogeneous network model | Bioinformatics | Oxford Academic&lt;/a&gt;。包含963种药物、1263种疾病和54921个药物-疾病关系。同样地，也进行了信息填充来进行相似性度量。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;指标表现&#34;&gt;指标表现
&lt;/h5&gt;&lt;p&gt;和SOTA模型进行比较，分别是&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;图神经网络（GNN）&lt;/strong&gt;：DRHGCN、LAGCN、REDDA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵分解与正则化&lt;/strong&gt;：BNNR、DRWBNCF&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵补全与神经归纳&lt;/strong&gt;：NIMCGCN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;核融合与传统机器学习&lt;/strong&gt;：DDA-SKF&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;LBMFF在所有指标上都体现出了领先。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611153556.png&#34;
	width=&#34;1620&#34;
	height=&#34;603&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611153556_hu_9a785be424d4ae99.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250611153556_hu_c4246ac65e7a8d75.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;268&#34;
		data-flex-basis=&#34;644px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;此外，LBMFF在TL-HGBI在多数指标上仍优于对比方法，证明方法在&lt;strong&gt;大规模数据集上的泛化能力&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611154234.png&#34;
	width=&#34;1659&#34;
	height=&#34;589&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611154234_hu_8a504edeb9650d6c.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250611154234_hu_237ef5a787bfd481.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;281&#34;
		data-flex-basis=&#34;675px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;llm进行阴性数据标注&#34;&gt;LLM进行阴性数据标注
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pubmed.ncbi.nlm.nih.gov/39905466/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Improving drug repositioning with negative data labeling using large language models-PubMed&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;问题与回答-2&#34;&gt;问题与回答
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Q1. LLM在Repurposing中的应用情况&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;LLM引入了自己的推理能力来修改训练数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q2. 是否有基于文本结构，引入大模型知识作为一部分特征？&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;没有。这里大模型的作用是通过自身的知识，在文本中筛选出更好的数据来提升最终效果的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q3. 测试集是什么&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;测试集是由AACT 数据库得到。作者手动选择了一部分数据（5 阳性 + 11 阴性 ）作为测试集验证泛化能力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Q4. 传统模型/基于网络的模型的准确率&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;见研究结果。本文通过&lt;strong&gt;提升数据集中真阴性数据的质量&lt;/strong&gt;来提高了最终的模型效果。具体来说，提升的效果还是比较显著的。&lt;/p&gt;
&lt;h4 id=&#34;解决的问题-2&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;在药物重新定位中，监督机器学习模型因缺乏可靠的&lt;strong&gt;阴性数据&lt;/strong&gt;（即因无效或毒性失败的药物）而预测准确性和泛化能力不足。&lt;/p&gt;
&lt;p&gt;传统的 Positive-Unlabeled（PU）学习方法通过随机采样或简单分类未标记数据作为阴性，存在误分类或决策边界简化的问题，导致模型性能受限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLM通过进行分析文献和数据，系统挖掘真阴性数据，提升了阴性数据的质量。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;面临的挑战-1&#34;&gt;面临的挑战
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;阴性数据获取困难&lt;/strong&gt;：多数数据库会把试验中止就等同于阴性，但终止原因可能并不是因为药物疗效/毒性问题，而是资金不足等原因。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PU学习方法的局限性&lt;/strong&gt;：随机采样未标记数据作为阴性会引入分类偏差，而基于聚类等策略的阴性筛选假设正负样本边界清晰，与真实场景不符，导致模型泛化能力差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;临床数据处理复杂性&lt;/strong&gt;：临床试验文本存在表述不规范、结果不完整等问题，传统方法难以准确解析并识别真正的阴性药物。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;核心方法-2&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;GPT-4 系统性挖掘真阴性数据&lt;/strong&gt;，为药物重定位提供 “高质量标注 + 精准模型” 方案，可扩展到其他疾病。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610231108.png&#34;
	width=&#34;1056&#34;
	height=&#34;314&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610231108_hu_bb6cc8baf67ab024.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610231108_hu_52714faad2411ffc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;临床试验药物标注流程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;336&#34;
		data-flex-basis=&#34;807px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;临床数据获取&lt;/strong&gt;：从 AACT 数据库获取 2539 个前列腺癌相关临床试验，排除未公布结果和因非疗效原因终止的试验后，剩余 1442 个试验由 GPT-4 分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPT-4的训练和验证&lt;/strong&gt;：使用 22 个手动策划的试验对 GPT-4 进行验证，其中包括 14 个无关试验、4 个阳性试验和 4 个阴性试验，GPT-4 成功正确分类所有试验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征构建&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;知识-based 特征&lt;/strong&gt;：从 DrugBank 获取药物-基因、药物-靶点、药物-通路相互作用、结构特性和靶点类别等，转换为独热编码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;network-based 特征&lt;/strong&gt;：构建包含药物-药物相似性、蛋白质-蛋白质相互作用和基因本体论的多层生物网络，提取拓扑特征。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对比策略&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPT-4 标注&lt;/strong&gt;：使用 GPT-4 识别的 26 个阳性和 54 个阴性药物。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无采样 PU&lt;/strong&gt;：将所有未标记药物视为阴性，导致类别不平衡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;下采样 PU&lt;/strong&gt;：从未标记药物中随机采样 43 个阴性，重复 100 次以控制类别不平衡。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610234019.png&#34;
	width=&#34;720&#34;
	height=&#34;650&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610234019_hu_da1098ceace0f516.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610234019_hu_cabf59ededa6f174.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;265px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;训练集和测试集来自于作者自己收集和整理。&lt;/p&gt;
&lt;h4 id=&#34;研究结果-1&#34;&gt;研究结果
&lt;/h4&gt;&lt;p&gt;使用六种机器学习算法和5折交叉验证训练模型，测试集验证泛化能力（5 阳性 + 11 阴性 ）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610232517.png&#34;
	width=&#34;1442&#34;
	height=&#34;600&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250610232517_hu_88b2c5cdb4fef3fe.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250610232517_hu_ebaa126e63836e49.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;240&#34;
		data-flex-basis=&#34;576px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;1-训练集表现图-a&#34;&gt;1. 训练集表现（图 A）：
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPT-4（🔴）&lt;/strong&gt;：多数算法（如 LogL1、RF、SVM ）平衡准确率接近 0.9，说明用 GPT-4 标注的高质量数据，模型在训练集上 “学的好”，分类稳定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No sampling（🟢）&lt;/strong&gt;：部分算法（如 ANN、NB ）准确率暴跌，因阴性样本太多，学不到有效模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Under sampling（🔵）&lt;/strong&gt;：表现居中，虽平衡了类别，但随机丢数据，训练效果不如 GPT-4 标注。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;2-测试集表现图-b&#34;&gt;2. 测试集表现（图 B）：
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPT-4（🔴）&lt;/strong&gt;：多数算法（如 LogL1、RF、SVM ）MCC 显著高于其他策略，尤其是 LogL1、RF，说明模型泛化能力强，用 GPT-4 标注数据训练的模型，在真实测试集上 “预测准”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No sampling（🟢）&lt;/strong&gt;：MCC 普遍低（如 NB 甚至接近 0 ），模型被类别不平衡拖垮。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Under sampling（🔵）&lt;/strong&gt;：MCC 比 GPT-4 低，因下采样丢了很多真实阴性信息，模型学到的规律不完整。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;其他&#34;&gt;其他
&lt;/h3&gt;&lt;h4 id=&#34;druggen&#34;&gt;DrugGen
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.nature.com/articles/s41598-025-98629-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DrugGen enhances drug discovery with large language models and reinforcement learning | Scientific Reports&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这篇文章介绍了一个基于DrugGPT的模型DrugGen，通过监督微调、近端策略优化和强化学习来引导模型生成更高质量的分子。&lt;/p&gt;
&lt;h4 id=&#34;drugrealign&#34;&gt;DrugReAlign
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pubmed.ncbi.nlm.nih.gov/39379930/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DrugReAlign: a multisource prompt framework for drug repurposing based on large language models - PubMed&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;提出了一个多源提示的LLM药物重定位框架。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611164032.png&#34;
	width=&#34;1944&#34;
	height=&#34;1430&#34;
	srcset=&#34;https://ionfeather.github.io/2025/rbdr/assets/20250611164032_hu_20997968172a8920.png 480w, https://ionfeather.github.io/2025/rbdr/assets/20250611164032_hu_f551cf6e5e853017.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;326px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;benchmarkllm在八项化学任务中的表现&#34;&gt;Benchmark：LLM在八项化学任务中的表现
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://proceedings.neurips.cc/paper_files/paper/2023/file/bbb330189ce02be00cf7346167028ab1-Paper-Datasets_and_Benchmarks.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;评估了LLM在八项具体的化学任务中的表现，采用零样本、少样本上下文学习设置，最后得出GPT-4最佳，Davinci-003次之，GPT-3.5第三。&lt;/p&gt;
&lt;h4 id=&#34;biobert&#34;&gt;BioBERT
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://academic.oup.com/bioinformatics/article/36/4/1234/5566506&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BioBERT: a pre-trained biomedical language representation model for biomedical text mining | Bioinformatics | Oxford Academic&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;介绍了一个用于生物医学领域的预训练语言表示模型，其在BERT的基础上使用生物医学领域语料库进行预训练。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIDR | 基于网络的方法</title>
        <link>https://ionfeather.github.io/2025/aidr-network-method/</link>
        <pubDate>Thu, 05 Jun 2025 21:24:53 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/aidr-network-method/</guid>
        <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍
&lt;/h2&gt;&lt;p&gt;基于网络的AIDR方法基本都是利用网络的拓扑结构进行探索。一般来说是在异构网络上进行处理，对于异构网络，有这么一个&lt;a class=&#34;link&#34; href=&#34;https://onlinelibrary.wiley.com/doi/10.1002/minf.202100200&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;表示图&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/2025/06-05-AIDD/index/IMG-20250605213040777.png&#34;
	width=&#34;788&#34;
	height=&#34;788&#34;
	srcset=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/2025/06-05-AIDD/index/IMG-20250605213040777_hu_ad0870a71572a414.png 480w, https://ionfeather.github.io/2025/aidr-network-method/assets/2025/06-05-AIDD/index/IMG-20250605213040777_hu_eae782122bf3141.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;异构网络表示图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;其中，绿色节点表示蛋白质、红色节点表示药物、蓝色节点表示疾病。这可以看成一个三层架构。网络可以具有多种类型的节点和多层架构。同类型节点之间的实线表示它们之间存在一定的关系。以药物层为例，关系类型可以如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;药物之间的结构相似性&lt;/li&gt;
&lt;li&gt;两种药物共享一个相同的靶点&lt;/li&gt;
&lt;li&gt;两种药物有协同作用或副作用&lt;/li&gt;
&lt;li&gt;&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虚线的双箭头线表示两种不同类型的节点之间的交互关系。同样的原理也适用于药物层以外的其他层。而右边的黑色实线箭头指的是三种类型节点的大概图。&lt;/p&gt;
&lt;p&gt;许多机器学习算法和神经网络算法都可以以这种异构网络作为数据的载体，例如随机游走、图神经网络等。异构网络将药物重定位任务带到了另一个层次，可以更高效地提取输入实体的特征并将其固定在一定维度上。&lt;/p&gt;
&lt;p&gt;对于基于网络的AIDR方法，参考&lt;a class=&#34;link&#34; href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC9599692/#sec2-biomolecules-12-01497&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Drug-Disease Association Prediction Using Heterogeneous Networks for Computational Drug Repositioning&lt;/a&gt;，将基于网络的AIDR方法分成三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图挖掘&lt;/li&gt;
&lt;li&gt;矩阵分解/填充&lt;/li&gt;
&lt;li&gt;深度学习&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220543.png&#34;
	width=&#34;1425&#34;
	height=&#34;823&#34;
	srcset=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220543_hu_7324ec1f3e8ee78d.png 480w, https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220543_hu_52415c25218cdf2e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;基于网络的方法预测药物-疾病关联的一般过程的示意图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这里有一个简单的思维导图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220431.png&#34;
	width=&#34;2000&#34;
	height=&#34;954&#34;
	srcset=&#34;https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220431_hu_dbdb1e5dbbfafc86.png 480w, https://ionfeather.github.io/2025/aidr-network-method/assets/20250605220431_hu_296037e0f01ea1a7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;基于网络的方法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;图挖掘算法&#34;&gt;图挖掘算法
&lt;/h2&gt;&lt;h2 id=&#34;矩阵分解填充&#34;&gt;矩阵分解/填充
&lt;/h2&gt;&lt;h2 id=&#34;深度学习&#34;&gt;深度学习
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>AIDR | 方向调研</title>
        <link>https://ionfeather.github.io/2025/aidr/</link>
        <pubDate>Fri, 23 May 2025 22:56:23 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/aidr/</guid>
        <description>&lt;h2 id=&#34;综述&#34;&gt;综述
&lt;/h2&gt;&lt;p&gt;打算先看一下有哪些综述，先了解一下整个工作的图景。&lt;/p&gt;
&lt;h2 id=&#34;会议&#34;&gt;会议
&lt;/h2&gt;&lt;p&gt;会议有三个人讲自己的调研。我理清一下每个人的要讲的部分。&lt;/p&gt;
&lt;h3 id=&#34;part-1&#34;&gt;Part 1
&lt;/h3&gt;&lt;p&gt;我介绍了自己调研的论文和阅读的文献。详情看我的2025-05-19的组会的PPT。&lt;/p&gt;
&lt;p&gt;我大概介绍了一下我阅读的 &lt;a class=&#34;link&#34; href=&#34;https://www.intechopen.com/books/1003850&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Repurposed Drugs - Current State and Future Perspectives | IntechOpen&lt;/a&gt;，这是一本书，其中的&lt;a class=&#34;link&#34; href=&#34;https://www.intechopen.com/chapters/1193584&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;第三章&lt;/a&gt;感觉非常有借鉴意义。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221515243.png&#34;
	width=&#34;1310&#34;
	height=&#34;1125&#34;
	srcset=&#34;https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221515243_hu_cf6751d684ada54a.png 480w, https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221515243_hu_43cb91797f949dfd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AIDD的主要数据库&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;116&#34;
		data-flex-basis=&#34;279px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221559913.png&#34;
	width=&#34;1784&#34;
	height=&#34;887&#34;
	srcset=&#34;https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221559913_hu_b046c09ba9266aba.png 480w, https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524221559913_hu_92e21c7a619529c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AIDD的主要方法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;482px&#34;
	
&gt;&lt;br&gt;
在组学、图挖掘算法和大模型部分分别介绍了看到的三篇论文：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI-powered omics-based drug pair discovery for pyroptosis therapy targeting triple-negative breast cancer | Nature Communications&lt;/li&gt;
&lt;li&gt;Biomedical knowledge graph learning for drug repurposing by extending guilt-by-association to multiple layers | Nature Communications&lt;/li&gt;
&lt;li&gt;DrugReAlign: a multisource prompt framework for drug repurposing based on large language models | BMC Biology&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;part-2&#34;&gt;Part 2
&lt;/h3&gt;&lt;p&gt;阅读的文献为：&lt;a class=&#34;link&#34; href=&#34;https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/advs.202411325&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Applications of Artificial Intelligence in Drug Repurposing - Wan - 2025 - Advanced Science - Wiley Online Library&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是师妹做的思维导图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/aidr/assets/2025/05-24-AIDD/index/IMG-20250524215614766.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;思维导图&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;part-3&#34;&gt;Part 3
&lt;/h3&gt;&lt;p&gt;师弟的PPT。&lt;/p&gt;
&lt;p&gt;阅读的论文有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multimodal Molecular Pretraining via Modality Blending | ICLR 2024&lt;/li&gt;
&lt;li&gt;Learning Multi-view Molecular Representations with Structured and Unstructured Knowledge | SIGKDD 2024&lt;/li&gt;
&lt;li&gt;Mol-AE: Auto-Encoder Based Molecular Representation Learning With 3D Cloze Test Objective | ICML 2024&lt;/li&gt;
&lt;li&gt;Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation | NeurIPS 2023&lt;/li&gt;
&lt;li&gt;Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D | ICLR 2023&lt;/li&gt;
&lt;li&gt;ESM All-Atom: Multi-scale Protein Language Model for Unified Molecular Modeling | ICML 2024&lt;/li&gt;
&lt;li&gt;On Pre-trained Language Models for Antibody | ICLR 2023&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>AIDR | 综述与论文</title>
        <link>https://ionfeather.github.io/2025/moleculerepurposing-2/</link>
        <pubDate>Fri, 04 Apr 2025 01:42:58 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/moleculerepurposing-2/</guid>
        <description>&lt;h2 id=&#34;阅读综述&#34;&gt;阅读综述
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Ai-Driven Drug Repurposing: Uncovering Hidden Potentials OfEstablished Medications For Rare Disease Treatment&lt;/li&gt;
&lt;li&gt;Structure-based drug repurposing: Traditional and advanced AI/ML-aided methods&lt;/li&gt;
&lt;li&gt;Artificial intelligence for drug repurposing against infectious diseases | &lt;em&gt;Artificial Intelligence Chemistry 2024&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Artificial intelligence in COVID-19 drug repurposing | &lt;em&gt;The Lancet Digital Health&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可用的模型&#34;&gt;可用的模型
&lt;/h3&gt;&lt;p&gt;目前的再利用方法的实例主要集中在&lt;strong&gt;网络医学和大规模的患者数据分析&lt;/strong&gt;上。这里有&lt;strong&gt;CoV-KGE、BenevolentAI、异质有向生物医学图&lt;/strong&gt;等。&lt;/p&gt;
&lt;h2 id=&#34;阅读论文&#34;&gt;阅读论文
&lt;/h2&gt;&lt;h3 id=&#34;artificial-intelligence-in-drug-development--nature-medicine&#34;&gt;Artificial intelligence in drug development | &lt;em&gt;nature medicine&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;这是一篇综述，讲解了人工智能在药物发现中的应用取得了显著进展，特别是在靶点识别、虚拟筛选、新药设计（de novo design）、ADMET预测和合成规划等方面。&lt;/p&gt;
&lt;p&gt;这里主要关注他讲的AI在药物重定位中的作用。&lt;/p&gt;
&lt;h3 id=&#34;a-foundation-model-for-clinician-centered-drug-repurposing--nature-medicine&#34;&gt;A foundation model for clinician-centered drug repurposing | &lt;em&gt;nature medicine&lt;/em&gt;
&lt;/h3&gt;&lt;h4 id=&#34;摘要&#34;&gt;摘要
&lt;/h4&gt;&lt;p&gt;文章介绍了药物再利用人工智能模型在临床应用中的局限性，并提出了本研究的核心——TxGNN模型。&lt;/p&gt;
&lt;h4 id=&#34;解决的问题&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;目前的模型过于依赖&lt;strong&gt;已有疗法&lt;/strong&gt;和&lt;strong&gt;关于此疾病详细的分子机制&lt;/strong&gt;，对于多疾病、零样本情境下的药物再利用没有好用的模型。&lt;/p&gt;
&lt;h4 id=&#34;挑战是什么&#34;&gt;挑战是什么
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;现有计算方法假设待预测疾病已有可用药物&lt;/strong&gt;，然而大量疾病（研究中 92% 的 17,080 种疾病）缺乏已知适应症，罕见病中约 95% 无 FDA 批准药物，85% 甚至无有潜力的治疗药物，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;药物重利用的适应症可能与最初研究的适应症无关&lt;/strong&gt;，现有机器学习模型对数据不完整、稀疏且无已知疗法的疾病，识别治疗候选药物的能力大幅下降。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;核心方法&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;TxGNN。图基础模型，在医学知识图谱上训练，利用图神经网络和度量学习模块，将药物再利用问题转化为零样本预测问题。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/assets/20250330192550.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;TxGNN模型主要由两个模块组成：TxGNN Predictor（预测模块）和TxGNN Explainer（解释模块）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;TxGNN Predictor（预测模块）&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：预测药物的适应症（indications）和禁忌症（contraindications）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;架构&lt;/strong&gt;：该模块基于图神经网络（GNN）构建，优化了医学知识图谱（KG）中的关系。通过大规模、自监督的&lt;strong&gt;预训练&lt;/strong&gt;，GNN为KG中的所有概念生成有意义的表示。然后，通过&lt;strong&gt;微调&lt;/strong&gt;，该预训练模型被适应于处理治疗任务，并预测跨多种疾病的药物候选适应症和禁忌症。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;度量学习模块&lt;/strong&gt;：用于零样本预测，利用疾病可以共享疾病相关的遗传和基因组网络这一见解，&lt;strong&gt;从可治疗的疾病向无治疗方法的疾病转移知识&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TxGNN Explainer（解释模块）&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：解析KG，提取并简洁地表示相关医学知识，以生成&lt;strong&gt;多跳可解释的路径&lt;/strong&gt;，这些路径解释了模型预测背后的逻辑。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;架构&lt;/strong&gt;：使用名为&lt;strong&gt;GraphMask&lt;/strong&gt;的自我解释性方法，生成一个稀疏但充分的医学概念子图，这些概念被认为是TxGNN预测的关键。它为KG中的每条边生成一个0到1之间的重要性分数，并通过组合药物-疾病子图和边重要性分数，产生多跳可解释的路径，将疾病与预测药物联系起来。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;优势&#34;&gt;优势
&lt;/h4&gt;&lt;p&gt;在零样本条件下，TxGNN预测效果相比别的模型体现出了广泛的泛化性和准确性。&lt;/p&gt;
&lt;h4 id=&#34;数据集&#34;&gt;数据集
&lt;/h4&gt;&lt;p&gt;医学知识图谱公开，包含 10 种类型的节点和 29 种类型的无向边，共有 123,527 个节点和 8,063,026 条边，涵盖 17,080 种疾病（92% 缺乏 FDA 批准药物）和 7,957 种潜在药物重利用候选药物，还包含生物过程、分子功能、蛋白质、表型等多种生物医学概念信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;知识图谱下载地址：&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.7910/DVN/IXA7BM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PrimeKG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;演示界面：&lt;a class=&#34;link&#34; href=&#34;http://txgnn.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TxGNN Explorer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github仓库：&lt;a class=&#34;link&#34; href=&#34;https://github.com/mims-harvard/TxGNN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;mims-harvard/TxGNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;in-silico-drug-repurposing-for-anti-inflammatory-therapy-virtual-search-for-dual-inhibitors-of-caspase-1-and-tnf-alpha&#34;&gt;In Silico Drug Repurposing for Anti-Inflammatory Therapy: Virtual Search for Dual Inhibitors of Caspase-1 and TNF-Alpha
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pubmed.ncbi.nlm.nih.gov/34944476/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;In Silico Drug Repurposing for Anti-Inflammatory Therapy: Virtual Search for Dual Inhibitors of Caspase-1 and TNF-Alpha - PubMed&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;摘要-1&#34;&gt;摘要
&lt;/h4&gt;&lt;p&gt;炎症与多种疾病相关，caspase-1 和 TNF-alpha 在炎症发展中起关键作用，针对二者的双重抑制剂有望治疗多种炎症性疾病。本文构建了基于定量构效关系和多层感知器神经网络的多条件模型（mtc-QSAR-MLP）用于虚拟筛选抗炎药物。经数据集处理、模型开发与评估，该模型准确性超 88%。利用此模型筛选出如 linagliptin、icariin 和 rolipram 等潜在的 caspase-1 和 TNF-alpha 双重抑制剂，为抗炎治疗提供新方向，有望用于自身免疫疾病、癌症及 COVID-19 等疾病的治疗。&lt;/p&gt;
&lt;h4 id=&#34;解决的问题-1&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;caspase-1 和 TNF-alpha&lt;/strong&gt;是炎症发展中的关键蛋白，针对它们的双重抑制剂有望治疗多种炎症性疾病。&lt;/p&gt;
&lt;h4 id=&#34;挑战是什么-1&#34;&gt;挑战是什么
&lt;/h4&gt;&lt;p&gt;通过药物再利用的方式来加速抗炎药物的发现。&lt;/p&gt;
&lt;h4 id=&#34;核心方法-1&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;构建基于定量结构 - 活性关系（QSAR）和多层感知器神经网络（MLP）的多条件模型（mtc-QSAR-MLP），用于虚拟筛选 caspase-1 和 TNF-alpha 的双重抑制剂。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据处理与分子描述符计算&lt;/strong&gt;：从 &lt;a class=&#34;link&#34; href=&#34;https://chembl.gitbook.io/chembl-interface-documentation/downloads&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChEMBL&lt;/a&gt;数据库获取 caspase-1 和 TNF-alpha 的化学及抑制数据，经筛选得到 1476 个分子案例。用&lt;a class=&#34;link&#34; href=&#34;https://insilicomoleculardesign.com/modeslab/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;code&gt;MODESLAB v1.5&lt;/code&gt;&lt;/a&gt;软件计算多种分子描述符，包括拓扑指数等。还通过 Box-Jenkins 方法融合化学和生物信息，得到能反映分子结构与实验条件关系的\(D[GTI]cj\)描述符，为模型构建提供丰富数据支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mtc-QSAR-MLP 模型构建&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据集划分&lt;/strong&gt;：将数据集按 3:1 随机分为训练集（1111 个分子案例，占 75.27%）和测试集（365 个分子案例，占 24.73%） 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;描述符筛选&lt;/strong&gt;：在训练集中，用信息增益比（IGR）对\(D[GTI]cj\)描述符排序，通过两两 Pearson 相关系数（PCC）筛选出相关性在\(-0.6 &lt; PCC &lt; 0.6\)的描述符，减少信息冗余。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型训练与选择&lt;/strong&gt;：以 MLP 神经网络为基础构建模型，利用 &lt;code&gt;STATISTICA v13.5.0.17&lt;/code&gt; 软件分析不同 MLP 网络，依据敏感性（Sn (%)）、特异性（Sp (%)）、准确性（Acc (%)）和马修斯相关系数（MCC）等指标，选择性能最佳的 MLP 网络作为 mtc-QSAR-MLP 模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型评估&lt;/strong&gt;：采用 Bounding Box 方法确定模型适用性域，计算描述符的局部适用性域分数（\(LSAD_D [GTI] cj\)）和总分数（TSAD），判断分子是否在适用性域内。通过分析模型在训练集和测试集上的性能指标，如准确率、敏感性、特异性和 MCC 等，验证模型对不同实验条件下化学物质抑制活性的分类和预测能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;虚拟筛选与结果验证&lt;/strong&gt;：使用构建好的 mtc-QSAR-MLP 模型对 8922 种机构监管化学品数据库进行虚拟筛选，考虑 8 种实验条件，计算每个分子的 FA (%)（分子在 8 种实验条件下被预测为活性的频率）和 S (TSAD)（考虑 8 种实验条件下分子的总适用性域分数）指标，筛选潜在双重抑制剂。对筛选结果，通过在科学文献中搜索相关信息，结合实验证据验证其抑制 caspase-1 和 TNF-alpha 的可能性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;优势-1&#34;&gt;优势
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;整合多源数据&lt;/strong&gt;：基于扰动理论和机器学习构建模型，能够整合不同类型的化学和生物数据。通过 Box-Jenkins 方法对传统分子描述符进行处理，得到融合化学结构与实验条件信息的描述符，使模型能综合考虑多种因素。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多靶点多终点预测&lt;/strong&gt;：可同时预测多个生物终点（如活性、毒性、药代动力学性质），并针对多个不同靶点（如 caspase-1 和 TNF-alpha）进行预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高预测准确性&lt;/strong&gt;：模型在训练集和测试集上都表现出较高的准确性。训练集准确率达 92.44%，测试集准确率为 88.49%，马修斯相关系数（MCC）在训练集和测试集分别为 0.844 和 0.764。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供理化和结构解释&lt;/strong&gt;：通过对分子描述符的分析，能够从物理化学和结构层面解释模型的预测结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据集-1&#34;&gt;数据集
&lt;/h4&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://chembl.gitbook.io/chembl-interface-documentation/downloads&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChEMBL&lt;/a&gt;开放数据库。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;machine-learningenabled-virtual-screening-indicates-the-anti-tuberculosis-activity-of-aldoxorubicin-and-quarfloxin-with-verification-by-molecular-docking-molecular-dynamics-simulations-and-biological-evaluations--briefings-bioinf&#34;&gt;Machine learning–enabled virtual screening indicates the anti-tuberculosis activity of aldoxorubicin and quarfloxin with verification by molecular docking, molecular dynamics simulations, and biological evaluations | &lt;em&gt;Briefings Bioinf&lt;/em&gt;
&lt;/h3&gt;&lt;h4 id=&#34;解决的问题-2&#34;&gt;解决的问题
&lt;/h4&gt;&lt;p&gt;目前的抗结核药物一定程度上控制了结核病的传播，但耐药结核病的出现使得这些药物的疗效大打折扣。&lt;/p&gt;
&lt;p&gt;虚拟筛选技术，为快速识别潜在的抗结核药物候选物提供了一种有效的手段。研究旨在通过结合多种机器学习和深度学习模型，开发一种虚拟筛选工作流程，以重新利用现有药物来对抗结核分枝杆菌，从而加速抗结核药物的发现进程。&lt;/p&gt;
&lt;h4 id=&#34;核心方法-2&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;研究者首先从ChEMBL数据库中收集了大量已知的抗结核药物的生物活性数据，用于训练和验证多种机器学习和深度学习模型。这些模型包括XGBoost和图神经网络（GNNs），用于预测化合物的最小抑制浓度（MIC）。接着，研究者使用这些模型对DrugBank数据库中的11,576种化合物进行虚拟筛选，筛选出具有潜在抗结核活性的化合物。通过多步过滤和实验验证，最终确定了两种具有显著抗结核活性的化合物：aldoxorubicin和quarfloxi，为了进一步验证作用机制，研究者通过分子对接、分子动力学模拟和表面等离子共振实验，确认了它们与结核分枝杆菌DNA gyrase的直接结合。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AIDR | 数据库探索</title>
        <link>https://ionfeather.github.io/2025/moleculerepurposing/</link>
        <pubDate>Sun, 23 Mar 2025 17:15:44 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/moleculerepurposing/</guid>
        <description>&lt;h2 id=&#34;数据库&#34;&gt;数据库
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/%E6%95%B0%E6%8D%AE%E5%BA%93.png&#34;
	width=&#34;2352&#34;
	height=&#34;3180&#34;
	srcset=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/%E6%95%B0%E6%8D%AE%E5%BA%93_hu_b2cef0980ff4ec10.png 480w, https://ionfeather.github.io/2025/moleculerepurposing/assets/%E6%95%B0%E6%8D%AE%E5%BA%93_hu_1df85dd03c34786e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;73&#34;
		data-flex-basis=&#34;177px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ttd&#34;&gt;TTD
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://db.idrblab.net/ttd/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TTD&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;治疗靶点数据库。它是一个专门收集和整理与&lt;strong&gt;治疗靶点&lt;/strong&gt;相关信息的数据库。&lt;/li&gt;
&lt;li&gt;下载地址：&lt;a class=&#34;link&#34; href=&#34;https://db.idrblab.net/ttd/full-data-download&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Full Data Download | Therapeutic Target Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数据库比较大，这里筛选了药物-靶点-疾病关联数据：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Target to drug mapping with mode of action&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;TargetID&lt;/code&gt;：靶点的唯一标识符。可以在数据库中找到靶点的详细信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DrugID&lt;/code&gt;：药物的唯一标识符。可以获取该药物的相关信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Highest_status&lt;/code&gt;：表示药物在研发或临床应用中的最高阶段或状态，&lt;code&gt;Approved&lt;/code&gt;说明该药物已经通过了相关监管机构的审批，被批准用于临床治疗。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MOA&lt;/code&gt;：即&lt;code&gt;Mode of Action&lt;/code&gt;，作用模式的缩写，&lt;code&gt;Modulator&lt;/code&gt;表明该药物对靶点的作用方式是作为调节剂。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Drug to disease mapping with ICD identifiers&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;TTDDRUID&lt;/code&gt;：表示 TTD 药物 ID，即该药物的唯一标识。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DRUGNAME&lt;/code&gt;：药物名称。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;INDICATI&lt;/code&gt;：适应症，即药物被用于治疗的病症。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Disease entry&lt;/code&gt;：疾病条目，这里使用了 ICD-11 编码来表示具体的疾病。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Clinical status&lt;/code&gt;：临床状态，指药物在临床试验或临床应用中的阶段或情况，如已批准、处于某一阶段的临床试验等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Target to disease mapping with ICD identifiers&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;TARGETID&lt;/code&gt;：代表 TTD 靶点 ID，为靶点在数据库内的唯一识别编号。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TARGNAME&lt;/code&gt;：靶点的具体名称。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;INDICATI&lt;/code&gt;：适应症，即药物被用于治疗的病症。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Disease entry&lt;/code&gt;：疾病条目，这里使用了 ICD-11 编码来表示具体的疾病。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Clinical status&lt;/code&gt;：临床状态。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/TTD%E6%95%B0%E6%8D%AE%E5%BA%93.png&#34;
	width=&#34;2302&#34;
	height=&#34;1356&#34;
	srcset=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/TTD%E6%95%B0%E6%8D%AE%E5%BA%93_hu_a04d204c9ca12156.png 480w, https://ionfeather.github.io/2025/moleculerepurposing/assets/TTD%E6%95%B0%E6%8D%AE%E5%BA%93_hu_dd48b28dfd14cd7c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;表一target-to-drug-mapping-with-mode-of-action&#34;&gt;表一：Target to drug mapping with mode of action
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;TargetID&lt;/th&gt;
          &lt;th&gt;DrugID&lt;/th&gt;
          &lt;th&gt;Highest_status&lt;/th&gt;
          &lt;th&gt;MOA&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;T87024&lt;/td&gt;
          &lt;td&gt;D00RRU&lt;/td&gt;
          &lt;td&gt;Approved&lt;/td&gt;
          &lt;td&gt;Modulator&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个表格表示：ID为D00RRU的药物能够以调节剂的方式作用ID为T87024的疾病，并且已经被批准。&lt;/p&gt;
&lt;h4 id=&#34;表二drug-to-disease-mapping-with-icd-identifiers&#34;&gt;表二：Drug to disease mapping with ICD identifiers
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;TTDDRUID&lt;/th&gt;
          &lt;th&gt;DRUGNAME&lt;/th&gt;
          &lt;th&gt;INDICATI&lt;/th&gt;
          &lt;th&gt;ICD-11&lt;/th&gt;
          &lt;th&gt;Clinical status&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;DZB84T&lt;/td&gt;
          &lt;td&gt;Maralixibat&lt;/td&gt;
          &lt;td&gt;Pruritus&lt;/td&gt;
          &lt;td&gt;EC90&lt;/td&gt;
          &lt;td&gt;Approved&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DZB84T&lt;/td&gt;
          &lt;td&gt;Maralixibat&lt;/td&gt;
          &lt;td&gt;Progressive familial intrahepatic cholestasis&lt;/td&gt;
          &lt;td&gt;5C58.03&lt;/td&gt;
          &lt;td&gt;Phase 3&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DZB84T&lt;/td&gt;
          &lt;td&gt;Maralixibat&lt;/td&gt;
          &lt;td&gt;Alagille syndrome&lt;/td&gt;
          &lt;td&gt;LB20.0Y&lt;/td&gt;
          &lt;td&gt;Phase 2&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个表格表示ID为DZB84T的药物，名为Maralixibat，有对应几种适应症：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;适应症为&lt;code&gt;Pruritus&lt;/code&gt;（瘙痒症），ICD-11 编码是&lt;code&gt;EC90&lt;/code&gt;，临床状态为&lt;code&gt;Approved&lt;/code&gt;（已批准）。&lt;/li&gt;
&lt;li&gt;适应症为&lt;code&gt;Progressive familial intrahepatic cholestasis&lt;/code&gt;（进行性家族性肝内胆汁淤积症），ICD-11 编码是&lt;code&gt;5C58.03&lt;/code&gt;，临床状态为&lt;code&gt;Phase 3&lt;/code&gt;（三期临床试验）。&lt;/li&gt;
&lt;li&gt;适应症为&lt;code&gt;Alagille syndrome&lt;/code&gt;（阿拉基综合征），ICD-11 编码是&lt;code&gt;LB20.0Y&lt;/code&gt;，临床状态为&lt;code&gt;Phase 2&lt;/code&gt;（二期临床试验）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;表三target-to-disease-mapping-with-icd-identifiers&#34;&gt;表三：Target to disease mapping with ICD identifiers
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;TARGETID&lt;/th&gt;
          &lt;th&gt;TARGNAME&lt;/th&gt;
          &lt;th&gt;INDICATI&lt;/th&gt;
          &lt;th&gt;INDICATI&lt;/th&gt;
          &lt;th&gt;INDICATI&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;T00033&lt;/td&gt;
          &lt;td&gt;Transforming growth factor alpha (TGFA)&lt;/td&gt;
          &lt;td&gt;Phase 1/2&lt;/td&gt;
          &lt;td&gt;Chronic kidney disease&lt;/td&gt;
          &lt;td&gt;[ICD-11: GB61]&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个表格表示 ID 为 T00033 的靶点，名为 Transforming growth factor alpha (TGFA)，有对应的临床关联信息：关联的疾病适应症为&lt;code&gt;Chronic kidney disease&lt;/code&gt;（慢性肾脏病），ICD-11 编码是&lt;code&gt;GB61&lt;/code&gt;，临床状态为&lt;code&gt;Phase 1/2&lt;/code&gt;（一期 / 二期临床试验 ）。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pubchem&#34;&gt;PubChem
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://pubchem.ncbi.nlm.nih.gov/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PubChem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;PubChem是美国国立卫生研究院的一个开放化学数据库。&lt;strong&gt;化合物信息数据库&lt;/strong&gt;，收录大量化合物的结构、生物活性等信息，为科研、药物研发等提供数据支持，也用于化学知识普及和教学。这个数据库非常大。&lt;/li&gt;
&lt;li&gt;用途参考：&lt;a class=&#34;link&#34; href=&#34;https://mp.weixin.qq.com/s/rys-1FXn5ZmqilTz1iD-pQ&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Nucleic Acids Research | 疗效药物靶标的比较性研究与数据平台构建&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;FTP下载：&lt;a class=&#34;link&#34; href=&#34;https://ftp.ncbi.nlm.nih.gov/pubchem/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Index of /pubchem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;药物-疾病关联数据
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;./Bioassay&lt;/code&gt;：生物测定数据，包含大量药物对不同生物靶点或细胞系的活性测试结果&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./Target&lt;/code&gt;：靶标数据，涵盖蛋白质、基因、通路和分类学等信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./Commpound&lt;/code&gt;和&lt;code&gt;./Compound_3D&lt;/code&gt;：化合物的数据信息包含结构信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./Other&lt;/code&gt;：&lt;code&gt;GooglePatents&lt;/code&gt;和&lt;code&gt;IBM&lt;/code&gt;中包含专利信息。寻找专利即将过期/已过期的药物，并对这些药物进行再利用评估。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面以&lt;code&gt;./Bioassay&lt;/code&gt;数据为例。&lt;/p&gt;
&lt;h4 id=&#34;表-1pubchem的bioassay的csv文件的标题行的分类和标签说明&#34;&gt;表 1：PubChem的&lt;code&gt;./Bioassay&lt;/code&gt;的CSV文件的标题行的分类和标签说明
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;分类&lt;/th&gt;
          &lt;th&gt;标签名称&lt;/th&gt;
          &lt;th&gt;说明&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_RESULT_TAG&lt;/td&gt;
          &lt;td&gt;行ID&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_SID&lt;/td&gt;
          &lt;td&gt;PubChem SID&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_CID&lt;/td&gt;
          &lt;td&gt;PubChem CID&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_ACTIVITY_OUTCOME&lt;/td&gt;
          &lt;td&gt;PubChem活性结果（即，Inactive, Active, Inconclusive, Unspecified, or Probe）&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_ACTIVITY_SCORE&lt;/td&gt;
          &lt;td&gt;PubChem活性得分，值越高表示活性越强&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_ACTIVITY_URL&lt;/td&gt;
          &lt;td&gt;测试结果特定的url&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行&lt;/td&gt;
          &lt;td&gt;PUBCHEM_ASSAYDATA_COMMENT&lt;/td&gt;
          &lt;td&gt;测试结果特定的注释&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行（可选）&lt;/td&gt;
          &lt;td&gt;测试结果名称1（如：name of test result 1）&lt;/td&gt;
          &lt;td&gt;测试结果1的数据&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;数据行（可选）&lt;/td&gt;
          &lt;td&gt;测试结果名称2（如：name of test result 2）&lt;/td&gt;
          &lt;td&gt;测试结果2的数据&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;可选标题行（测试结果）&lt;/td&gt;
          &lt;td&gt;RESULT_UNIT&lt;/td&gt;
          &lt;td&gt;单位（e.g. MICROMOLAR, NANOMOLAR和其他PubChem上传系统使用的标签）&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;可选标题行（测试结果）&lt;/td&gt;
          &lt;td&gt;RESULT_IS_ACTIVE_CONCENTRATION&lt;/td&gt;
          &lt;td&gt;如果测试结果表示有效浓度则为TRUE&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;可选标题行（测试结果）&lt;/td&gt;
          &lt;td&gt;RESULT_IS_ACTIVE_CONCENTRATION_QUALIFIER&lt;/td&gt;
          &lt;td&gt;如果测试结果表示与有效浓度相关的终点限定词（e.g. &amp;lt;, &amp;lt;=, =, &amp;gt;, &amp;gt;=）则为TRUE&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;可选标题行（测试结果）&lt;/td&gt;
          &lt;td&gt;RESULT_ATTR_CONC_MICROMOL&lt;/td&gt;
          &lt;td&gt;以微摩尔为单位的测试浓度&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;表二pubchem-csvdata0000001_00010001csv文件&#34;&gt;表二：PubChem CSV/Data/0000001_0001000/1.csv文件
&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;PUBCHEM_RESULT_TAG&lt;/th&gt;
          &lt;th&gt;PUBCHEM_SID&lt;/th&gt;
          &lt;th&gt;PUBCHEM_CID&lt;/th&gt;
          &lt;th&gt;PUBCHEM_EXT_DATASOURCE_SMILES&lt;/th&gt;
          &lt;th&gt;PUBCHEM_ACTIVITY_OUTCOME&lt;/th&gt;
          &lt;th&gt;PUBCHEM_ACTIVITY_SCORE&lt;/th&gt;
          &lt;th&gt;PUBCHEM_ACTIVITY_URL&lt;/th&gt;
          &lt;th&gt;PUBCHEM_ASSAYDATA_COMMENT&lt;/th&gt;
          &lt;th&gt;LogGI50_M&lt;/th&gt;
          &lt;th&gt;LogGI50_u&lt;/th&gt;
          &lt;th&gt;LogGI50_V&lt;/th&gt;
          &lt;th&gt;IndnGI50&lt;/th&gt;
          &lt;th&gt;StddevGI50&lt;/th&gt;
          &lt;th&gt;LogTGI_M&lt;/th&gt;
          &lt;th&gt;LogTGI_u&lt;/th&gt;
          &lt;th&gt;LogTGI_V&lt;/th&gt;
          &lt;th&gt;IndnTGI&lt;/th&gt;
          &lt;th&gt;StddevTGI&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;66954&lt;/td&gt;
          &lt;td&gt;11122&lt;/td&gt;
          &lt;td&gt;CC1=CC(=O)C=CC1=O&lt;/td&gt;
          &lt;td&gt;Inactive&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;http://dtp.nci.nih.gov/dtpstandard/servlet/doseresponse?searchtype=NSC&amp;amp;searchlist=1&amp;amp;systemname=NCI&amp;#43;Cancer&amp;amp;idn1=1&amp;amp;idn2=1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://dtp.nci.nih.gov/dtpstandard/servlet/doseresponse?searchtype=NSC&amp;searchlist=1&amp;systemname=NCI+Cancer&amp;idn1=1&amp;idn2=1&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;-4.5753&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;-4&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个表格表示数据行 ID 为 1 的记录，其中涉及的 PubChem SID 为 66954，PubChem CID 为 11122，化合物的 SMILES 表示形式为&lt;code&gt;CC1=CC(=O)C=CC1=O&lt;/code&gt;，有对应的生物活性关联信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PubChem 活性结果为&lt;code&gt;Inactive&lt;/code&gt;（无活性），PubChem 活性得分为 10，表明在此次生物测定中该化合物活性较低。&lt;/li&gt;
&lt;li&gt;测试结果特定的 url 为&lt;a class=&#34;link&#34; href=&#34;http://dtp.nci.nih.gov/dtpstandard/servlet/doseresponse?searchtype=NSC&amp;amp;searchlist=1&amp;amp;systemname=NCI&amp;#43;Cancer&amp;amp;idn1=1&amp;amp;idn2=1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;dtp.cancer.gov/services/nci60data/colordoseresponse/pdf/1&lt;/a&gt;，可通过该链接获取更多相关测试结果信息。&lt;/li&gt;
&lt;li&gt;测试结果特定的注释为空。&lt;/li&gt;
&lt;li&gt;关于 GI50（半数生长抑制浓度）的相关数据：
&lt;ul&gt;
&lt;li&gt;以摩尔为单位的 GI50 结果的对数&lt;code&gt;LogGI50_M&lt;/code&gt;为 - 4.5753。&lt;/li&gt;
&lt;li&gt;测试次数平均数量&lt;code&gt;IndnGI50&lt;/code&gt;为 1。&lt;/li&gt;
&lt;li&gt;对所有测试的 GI50 结果的对数（Log10）的标准偏差&lt;code&gt;StddevGI50&lt;/code&gt;为 0，说明该测量值较为稳定。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;关于 TGI（总生长抑制）的相关数据：
&lt;ul&gt;
&lt;li&gt;以摩尔为单位的 TGI 结果的对数&lt;code&gt;LogTGI_M&lt;/code&gt;为 - 4。&lt;/li&gt;
&lt;li&gt;测试次数平均数量&lt;code&gt;IndnTGI&lt;/code&gt;为 1。&lt;/li&gt;
&lt;li&gt;对所有测试的 TGI 结果的对数（Log10）的标准偏差&lt;code&gt;StddevTGI&lt;/code&gt;为 0，表明该测量值稳定性较好 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他的如&lt;code&gt;./Target&lt;/code&gt;、&lt;code&gt;./Commpound&lt;/code&gt;和&lt;code&gt;./Compound_3D&lt;/code&gt;等数据也呈现如此结构。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;dgidb&#34;&gt;DGIdb
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://dgidb.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DGIdb&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;药物基因相互作用数据库，主要收集和整理&lt;strong&gt;药物与基因之间相互作用&lt;/strong&gt;的相关信息。&lt;/li&gt;
&lt;li&gt;这个数据库一共就四个表格，分别存储药物-基因相互作用、基因、药物和分类相关信息，使用&lt;code&gt;tsv&lt;/code&gt;格式进行存储。数据大小约为24.9MB。
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;interactions.tsv&lt;/strong&gt;：存储所有药物-基因相互作用声明数据，包含不同药物与基因之间相互作用的信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;genes.tsv&lt;/strong&gt;：记录了基因声明相关数据，可能涵盖基因的基本信息，如基因名称、基因 ID、基因功能注释等内容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drugs.tsv&lt;/strong&gt;：存放药物声明数据，包括药物的名称、药物 ID、药物的基本属性、药理作用等信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;categories.tsv&lt;/strong&gt;：用于存储与数据分类相关的信息。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/%E8%A1%A8%E6%A0%BC%E5%86%85%E5%AE%B9%E5%88%86%E7%B1%BB.png&#34;
	width=&#34;1636&#34;
	height=&#34;632&#34;
	srcset=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/%E8%A1%A8%E6%A0%BC%E5%86%85%E5%AE%B9%E5%88%86%E7%B1%BB_hu_b5be2c0fe63c7eb8.png 480w, https://ionfeather.github.io/2025/moleculerepurposing/assets/%E8%A1%A8%E6%A0%BC%E5%86%85%E5%AE%B9%E5%88%86%E7%B1%BB_hu_46d8fe200a45204e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;258&#34;
		data-flex-basis=&#34;621px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;表一interactionstsv&#34;&gt;表一：interactions.tsv
&lt;/h4&gt;&lt;p&gt;其中的各列的意思分别是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gene_claim_name&lt;/strong&gt;：基因的声明名称。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gene_concept_id&lt;/strong&gt;：基因的唯一标识代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gene_name&lt;/strong&gt;：基因的标准正式名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interaction_source_db_name&lt;/strong&gt;：基因与药物相互作用数据的来源数据库名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interaction_source_db_version&lt;/strong&gt;：来源数据库的版本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interaction_type&lt;/strong&gt;：基因和药物间相互作用的类别。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interaction_score&lt;/strong&gt;：体现基因与药物相互作用强度的数值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drug_claim_name&lt;/strong&gt;：药物的特定称谓。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drug_concept_id&lt;/strong&gt;：药物的唯一标识代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drug_name&lt;/strong&gt;：药物的标准正式名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;approved&lt;/strong&gt;：药物是否已获批上市的标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;immunotherapy&lt;/strong&gt;：药物是否属于免疫治疗药物的标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;anti_neoplastic&lt;/strong&gt;：药物是否具有抗肿瘤作用的标识。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;gene_claim_name&lt;/th&gt;
          &lt;th&gt;gene_concept_id&lt;/th&gt;
          &lt;th&gt;gene_name&lt;/th&gt;
          &lt;th&gt;interaction_source_db_name&lt;/th&gt;
          &lt;th&gt;interaction_source_db_version&lt;/th&gt;
          &lt;th&gt;interaction_type&lt;/th&gt;
          &lt;th&gt;interaction_score&lt;/th&gt;
          &lt;th&gt;drug_claim_name&lt;/th&gt;
          &lt;th&gt;drug_concept_id&lt;/th&gt;
          &lt;th&gt;drug_name&lt;/th&gt;
          &lt;th&gt;approved&lt;/th&gt;
          &lt;th&gt;immunotherapy&lt;/th&gt;
          &lt;th&gt;anti_neoplastic&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;CYP2D6&lt;/td&gt;
          &lt;td&gt;hgnc:2625&lt;/td&gt;
          &lt;td&gt;CYP2D6&lt;/td&gt;
          &lt;td&gt;DTC&lt;/td&gt;
          &lt;td&gt;9/2/20&lt;/td&gt;
          &lt;td&gt;NULL&lt;/td&gt;
          &lt;td&gt;0.017709164&lt;/td&gt;
          &lt;td&gt;RACLOPRIDE&lt;/td&gt;
          &lt;td&gt;ncit:C152139&lt;/td&gt;
          &lt;td&gt;RACLOPRIDE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PPARG&lt;/td&gt;
          &lt;td&gt;hgnc:9236&lt;/td&gt;
          &lt;td&gt;PPARG&lt;/td&gt;
          &lt;td&gt;DTC&lt;/td&gt;
          &lt;td&gt;9/2/20&lt;/td&gt;
          &lt;td&gt;NULL&lt;/td&gt;
          &lt;td&gt;0.84012274&lt;/td&gt;
          &lt;td&gt;KALOPANAX-SAPONIN F&lt;/td&gt;
          &lt;td&gt;chembl:CHEMBL1833984&lt;/td&gt;
          &lt;td&gt;CHEMBL:CHEMBL1833984&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这个表格有两列，这里只对第一列进行解释：基因声明名称为&lt;code&gt;CYP2D6&lt;/code&gt;，基因概念 ID 是&lt;code&gt;hgnc:2625&lt;/code&gt;，基因名称同样为&lt;code&gt;CYP2D6&lt;/code&gt;。相互作用来源数据库名称是&lt;code&gt;DTC&lt;/code&gt;，数据库版本为&lt;code&gt;9/2/20&lt;/code&gt;，相互作用类型为空（&lt;code&gt;NULL&lt;/code&gt;），相互作用得分为&lt;code&gt;0.017709164&lt;/code&gt;。药物声明名称是&lt;code&gt;RACLOPRIDE&lt;/code&gt;，药物概念 ID 为&lt;code&gt;ncit:C152139&lt;/code&gt;，药物名称是&lt;code&gt;RACLOPRIDE&lt;/code&gt;。该药物未被批准（&lt;code&gt;approved&lt;/code&gt;为&lt;code&gt;FALSE&lt;/code&gt;），不是免疫疗法（&lt;code&gt;immunotherapy&lt;/code&gt;为&lt;code&gt;FALSE&lt;/code&gt;），也不是抗肿瘤药物（&lt;code&gt;anti_neoplastic&lt;/code&gt;为&lt;code&gt;FALSE&lt;/code&gt;） 。&lt;/p&gt;
&lt;h4 id=&#34;表二drugstsv&#34;&gt;表二：drugs.tsv
&lt;/h4&gt;&lt;p&gt;其中的各列的意思分别是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;drug_claim_name&lt;/strong&gt;：药物的特定称谓。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nomenclature&lt;/strong&gt;：药物命名法类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;concept_id&lt;/strong&gt;：药物的唯一标识代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drug_name&lt;/strong&gt;：药物的标准正式名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;approved&lt;/strong&gt;：药物是否已获批上市的标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;immunotherapy&lt;/strong&gt;：药物是否属于免疫治疗药物的标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;anti_neoplastic&lt;/strong&gt;：药物是否具有抗肿瘤作用的标识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_name&lt;/strong&gt;：药物数据的来源数据库名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_version&lt;/strong&gt;：来源数据库的版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;drug_claim_name&lt;/th&gt;
          &lt;th&gt;nomenclature&lt;/th&gt;
          &lt;th&gt;concept_id&lt;/th&gt;
          &lt;th&gt;drug_name&lt;/th&gt;
          &lt;th&gt;approved&lt;/th&gt;
          &lt;th&gt;immunotherapy&lt;/th&gt;
          &lt;th&gt;anti_neoplastic&lt;/th&gt;
          &lt;th&gt;source_db_name&lt;/th&gt;
          &lt;th&gt;source_db_version&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;BRAF(V600E) Kinase Inhibitor RO5212054&lt;/td&gt;
          &lt;td&gt;Primary Drug Name&lt;/td&gt;
          &lt;td&gt;ncit:C92591&lt;/td&gt;
          &lt;td&gt;BRAF(V600E) KINASE INHIBITOR RO5212054&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;FALSE&lt;/td&gt;
          &lt;td&gt;TRUE&lt;/td&gt;
          &lt;td&gt;NCIt&lt;/td&gt;
          &lt;td&gt;24.02d&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;药物声明名称为&lt;code&gt;BRAF(V600E) Kinase Inhibitor RO5212054&lt;/code&gt;，药物命名法类型是&lt;code&gt;Primary Drug Name&lt;/code&gt;，药物概念 ID 是&lt;code&gt;ncit:C92591&lt;/code&gt;，药物名称为&lt;code&gt;BRAF(V600E) KINASE INHIBITOR RO5212054&lt;/code&gt;。该药物未被批准（&lt;code&gt;approved&lt;/code&gt;为&lt;code&gt;FALSE&lt;/code&gt;），不是免疫疗法（&lt;code&gt;immunotherapy&lt;/code&gt;为&lt;code&gt;FALSE&lt;/code&gt;），是抗肿瘤药物（&lt;code&gt;anti_neoplastic&lt;/code&gt;为&lt;code&gt;TRUE&lt;/code&gt;） 。药物数据的来源数据库名称是&lt;code&gt;NCIt&lt;/code&gt;，数据库版本为&lt;code&gt;24.02d&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;表三genetsv&#34;&gt;表三：gene.tsv
&lt;/h4&gt;&lt;p&gt;其中的各列的意思分别是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gene_claim_name&lt;/strong&gt;：基因的声明名称。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nomenclature&lt;/strong&gt;：基因命名法类型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;concept_id&lt;/strong&gt;：基因的唯一标识代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gene_name&lt;/strong&gt;：基因的标准正式名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_name&lt;/strong&gt;：基因数据的来源数据库名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_version&lt;/strong&gt;：来源数据库的版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;gene_claim_name&lt;/th&gt;
          &lt;th&gt;nomenclature&lt;/th&gt;
          &lt;th&gt;concept_id&lt;/th&gt;
          &lt;th&gt;gene_name&lt;/th&gt;
          &lt;th&gt;source_db_name&lt;/th&gt;
          &lt;th&gt;source_db_version&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;NGFIBA&lt;/td&gt;
          &lt;td&gt;NCBI Gene Name&lt;/td&gt;
          &lt;td&gt;NULL&lt;/td&gt;
          &lt;td&gt;NULL&lt;/td&gt;
          &lt;td&gt;BaderLab&lt;/td&gt;
          &lt;td&gt;Feb-14&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;基因声明名称为&lt;code&gt;NGFIBA&lt;/code&gt;，基因命名法类型是&lt;code&gt;NCBI Gene Name&lt;/code&gt;，基因概念 ID 是&lt;code&gt;NULL&lt;/code&gt;，基因名称同样为&lt;code&gt;NULL&lt;/code&gt;。基因数据的来源数据库名称是&lt;code&gt;BaderLab&lt;/code&gt;，数据库版本为&lt;code&gt;Feb-14&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;表四categoriestsv&#34;&gt;表四：categories.tsv
&lt;/h4&gt;&lt;p&gt;其中的各列的意思分别是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;：某实体的名称（这里可能是基因或其他生物相关实体名称）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;name-2&lt;/strong&gt;：该实体的另一个相关名称或描述。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_name&lt;/strong&gt;：数据的来源数据库名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source_db_version&lt;/strong&gt;：来源数据库的版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;name&lt;/th&gt;
          &lt;th&gt;name-2&lt;/th&gt;
          &lt;th&gt;source_db_name&lt;/th&gt;
          &lt;th&gt;source_db_version&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;PXR&lt;/td&gt;
          &lt;td&gt;NUCLEAR HORMONE RECEPTOR&lt;/td&gt;
          &lt;td&gt;BaderLab&lt;/td&gt;
          &lt;td&gt;Feb-14&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;名称为&lt;code&gt;PXR&lt;/code&gt;，另一个相关名称或描述是&lt;code&gt;NUCLEAR HORMONE RECEPTOR&lt;/code&gt;。数据的来源数据库名称是&lt;code&gt;BaderLab&lt;/code&gt;，数据库版本为&lt;code&gt;Feb-14&lt;/code&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;drugbank&#34;&gt;DrugBank
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://go.drugbank.com/drugs&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DrugBank&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;综合药物信息数据库&lt;/strong&gt;，整合了药物的化学、药理、毒理等多方面信息。&lt;/li&gt;
&lt;li&gt;一个巨大的数据库。这个数据库免费开放给学术用户，但商业使用收费。可以在网页上进行学生/老师认证注册。药物再利用在其中是很小的一个板块，可以在&lt;a class=&#34;link&#34; href=&#34;https://go.drugbank.com/data_packages/drug_repurposing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这里&lt;/a&gt;下载。&lt;/li&gt;
&lt;li&gt;学生身份目前正在审核状态，无法下载。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;chembl&#34;&gt;ChEMBL
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ebi.ac.uk/chembl/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ChEMBL&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;ChEMBL 是一个开源的生物活性分子数据库，&lt;strong&gt;专注于小分子化合物与生物靶点之间的相互作用信息。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;数据大小大约2GB。有不同的版本，提供FTP方式下载，可以在这里下载&lt;a class=&#34;link&#34; href=&#34;https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_35/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;最新的版本ChEMBL_35&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;目录中的内容可以参考README文件。主要的部分可以见下图，组织时FASTA文件、SDF文件、HTML文件和TXT文件都有使用。数据可以加载到MySQL、PostgreSQL等数据库中。&lt;/li&gt;
&lt;li&gt;有官方的数据库结构图如下，主要分成
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;化合物信息&lt;/strong&gt;：主要以&lt;strong&gt;蓝色&lt;/strong&gt;区域呈现，记录了化合物的结构、理化性质等，像分子式、分子量和二维结构这些&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验数据&lt;/strong&gt;：用&lt;strong&gt;紫色&lt;/strong&gt;区域表示，包含化合物与靶点相互作用的活性数据，还有实验条件，比如不同化合物对特定靶点的结合亲和力数值，以及实验采用的检测方法等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;靶点和结合位点信息&lt;/strong&gt;：&lt;strong&gt;红色&lt;/strong&gt;区域代表这部分内容。靶点信息涉及蛋白质靶点的氨基酸序列、三维结构和功能分类；结合位点信息聚焦靶点与化合物结合的区域，包括氨基酸组成、空间结构和相互作用模式&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;药物代谢数据&lt;/strong&gt;：&lt;strong&gt;浅绿色&lt;/strong&gt;区域涵盖这部分，记录了药物在体内的代谢途径、产物和酶——我们可以通过这部分预测药物疗效、毒性以及药物之间的相互作用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;作用机制 / 药物注释&lt;/strong&gt;：&lt;strong&gt;浅蓝色&lt;/strong&gt;区域负责注释药物作用机制，关联化合物、靶点和生物效应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;来源和已批准药物数据&lt;/strong&gt;：&lt;strong&gt;灰色&lt;/strong&gt;区域中，来源信息保证数据可追溯，已批准药物 数据包含批准文号、适应症和生产厂家等，这个应该是用来避免专利壁垒的，可以查看专利即将到期的药物。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常规信息&lt;/strong&gt;：&lt;strong&gt;浅黄色&lt;/strong&gt;区域存放数据库的版本号、更新时间等基础信息。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/chembl_35_schema.png&#34;
	width=&#34;6139&#34;
	height=&#34;7557&#34;
	srcset=&#34;https://ionfeather.github.io/2025/moleculerepurposing/assets/chembl_35_schema_hu_12cf40ea010e7f50.png 480w, https://ionfeather.github.io/2025/moleculerepurposing/assets/chembl_35_schema_hu_5ff664ef9b0568fe.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;ChEMBL整体情况&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;81&#34;
		data-flex-basis=&#34;194px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;bindingdb&#34;&gt;BindingDB
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bindingdb.org/rwd/bind/index.jsp&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BindingDB&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;主要收集药物靶点蛋白质和类药小分子之间的相互作用亲和力数据&lt;/strong&gt;。数据库大小为484.07 MB（&lt;a class=&#34;link&#34; href=&#34;https://www.bindingdb.org/rwd/bind/chemsearch/marvin/SDFdownload.jsp?download_file=/rwd/bind/downloads/BindingDB_All_202504_tsv.zip&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;TSV&lt;/a&gt;版本）。&lt;/li&gt;
&lt;li&gt;该数据文件只有一个表格，该表总共包含117列。
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;配体标识与结构（7 列）&lt;/strong&gt;：如 “BindingDB MonomerID” 等，用于确定和描述配体，包括多种结构表示方式和自定义名称。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;靶点基础信息（2 列）&lt;/strong&gt;：“Target Name” 和 “Target Source Organism According to Curator or DataSource”，明确靶点名称及所属生物。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结合活性数据（6 列）&lt;/strong&gt;：“Ki (nM)” 等，反映配体与靶点结合的强度和速率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验环境参数（2 列）&lt;/strong&gt;：“pH” 和 “Temp (°C)”，体现结合数据测量时的环境条件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据与文献来源（7 列）&lt;/strong&gt;：“Curation/DataSource” 及各类文献标识符，用于追溯数据出处和原始研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据库交叉引用（14 列）&lt;/strong&gt;：含 “PubChem CID” 等多个数据库的配体标识，方便数据整合查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;蛋白质链详情（80 列）&lt;/strong&gt;：先以 “Number of Protein Chains in Target” 记录链数量，后续多列针对每条链，涵盖序列、结构 ID、UniProt 相关名称和 ID 等信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;表格中的信息以第一条记录（数据行 ID 为 1）为例，大概描述了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配体相关信息：BindingDB MonomerID 为 &lt;code&gt;608734&lt;/code&gt;，Ligand SMILES 为 “O [C@@H] 1C@@HC@@HN (CCCCCC (O)=O) C (=O) N (CCCCCC (O)=O)[C@@H] 1Cc1ccccc1”，其对应的 BindingDB Ligand Name 是 “6-[(4R,5S,6S,7R)-4,7 - 二苄基 - 3-(5 - 羧基戊基)-5,6 - 二羟基 - 2 - 氧代 - 1,3 - 二氮杂环庚烷 - 1 - 基] 己酸::DMPC 环脲 1”。&lt;/li&gt;
&lt;li&gt;靶点相关信息：Target Name 为 “Dimer of Gag-Pol polyprotein [501 - 599]”，表明靶点是 Gag-Pol 多聚蛋白二聚体的 501 - 599 区域；Target Source Organism 为 “Human immunodeficiency virus 1”，即靶点来源于人类免疫缺陷病毒 1。&lt;/li&gt;
&lt;li&gt;结合活性数据：Ki (nM) 为 0.24 ，显示配体与靶点的结合亲和力较强。&lt;/li&gt;
&lt;li&gt;实验条件：测量时 pH 为 5.5，温度为 37°C。&lt;/li&gt;
&lt;li&gt;数据来源：由 BindingDB 从文献整理而来，相关文献的 DOI 是 10.1021/jm9602571，PMID 为 8784449，可据此追溯原始研究。&lt;/li&gt;
&lt;li&gt;数据库交叉引用：PubChem CID 为 3009304，PubChem SID 为 483500124，方便在 PubChem 数据库中查找该配体更多信息。&lt;/li&gt;
&lt;li&gt;蛋白质链信息：靶点含 1 条蛋白质链，其序列为 “PQITLWQRPLVTIKIGGQLKEALLDTGADDTVLEEMSLPGRWKPKMIGGIGGFIKVRQYDQILIEICGHKAIGTVLVGPTPVNIIGRNLLTQIGCTLNF”，相关 PDB ID 有 “1W5Y”“1W5X” 等多个，UniProt（SwissProt）相关信息显示，其推荐名称是 “Gag-Pol polyprotein”，Entry Name 为 “POL_HV1BR”，Primary ID 为 “P03367”。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>AIDD | 论文阅读</title>
        <link>https://ionfeather.github.io/2025/ai-assist-drug-design/</link>
        <pubDate>Wed, 26 Feb 2025 22:17:58 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/ai-assist-drug-design/</guid>
        <description>&lt;p&gt;开展一些AI-assist Drug Design 的方向探索，需要进行一些论文阅读和调研，形成调研报告。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2402.08703&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2402.08703] A Survey of Generative AI for de novo Drug Design: New Frontiers in Molecule and Protein Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhouh.github.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hao Zhou（周浩)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主要解决什么问题&lt;/li&gt;
&lt;li&gt;挑战是什么&lt;/li&gt;
&lt;li&gt;我们提出的核心方法，与同类问题比较的优势在哪&lt;/li&gt;
&lt;li&gt;数据集是什么，是否公开&lt;/li&gt;
&lt;li&gt;评测方式是什么，有无数据集&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;思维导图&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/AIAssistDrugDesign.png&#34;
	width=&#34;3096&#34;
	height=&#34;2108&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/AIAssistDrugDesign_hu_7c5a69c7fd0a71dc.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/AIAssistDrugDesign_hu_19797f0e34281d11.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;AI Assist Drug Design&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;146&#34;
		data-flex-basis=&#34;352px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-survey-of-generative-ai-for-de-novo-drug-design-new-frontiers-in-molecule-and-protein-generation&#34;&gt;A Survey of Generative AI for &lt;em&gt;de novo&lt;/em&gt; Drug Design: New Frontiers in Molecule and Protein Generation
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2402.08703&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2402.08703] A Survey of Generative AI for de novo Drug Design: New Frontiers in Molecule and Protein Generation&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;摘要&#34;&gt;摘要
&lt;/h3&gt;&lt;p&gt;将从头药物设计（&lt;em&gt;de novo&lt;/em&gt; drug design）归纳为两大主题：小分子生成和蛋白质生成。在每个主题下，我们识别出多种子任务和应用，重点介绍重要的数据集、基准测试、模型架构，并比较顶尖模型的性能。&lt;/p&gt;
&lt;h3 id=&#34;引言&#34;&gt;引言
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;并非是虚拟筛选/定向进化。而是从头开始的自然界中并未存在的新的生物实体的生成。&lt;/li&gt;
&lt;li&gt;文章中分成两个部分来讲解。小分子和蛋白质。&lt;/li&gt;
&lt;li&gt;文章将介绍
&lt;ul&gt;
&lt;li&gt;生成式模型的种类：Diffusion/VAE/Flow-Based/GAN&lt;/li&gt;
&lt;li&gt;将文章分成小分子和蛋白质两个领域，分别介绍
&lt;ul&gt;
&lt;li&gt;一般背景/任务定义&lt;/li&gt;
&lt;li&gt;用于训练和测试的常见数据集&lt;/li&gt;
&lt;li&gt;常用的评估指标&lt;/li&gt;
&lt;li&gt;对过去和当前的机器学习方法的概述&lt;/li&gt;
&lt;li&gt;对SOTA方法的性能的对比分析&lt;/li&gt;
&lt;li&gt;总结&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;相关研究&#34;&gt;相关研究
&lt;/h3&gt;&lt;p&gt;其他的方法都太专业，而这篇文章对小分子和蛋白质生成进行宏观层面的分析，有助于那些想要对化学创新领域中新兴的生成式AI模型有一个高屋建瓴的了解的人。&lt;/p&gt;
&lt;h3 id=&#34;前言生成式ai模型&#34;&gt;前言：生成式AI模型
&lt;/h3&gt;&lt;p&gt;介绍了&lt;strong&gt;VAE、GAN、Flow-Based Models&lt;/strong&gt;和&lt;strong&gt;Diffusion&lt;/strong&gt;，还介绍了一些其他模型，比如GNN、EGNN等。&lt;/p&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用
&lt;/h3&gt;&lt;h4 id=&#34;小分子&#34;&gt;小分子
&lt;/h4&gt;&lt;h5 id=&#34;任务背景&#34;&gt;任务背景
&lt;/h5&gt;&lt;p&gt;分子生成聚焦于为药物设计创造新的分子化合物。这些生成的分子旨在具有 &lt;strong&gt;（1）有效性、（2）稳定性和（3）独特性&lt;/strong&gt;，总体目标是具有药物适用性。“药物适用性” 是一个宽泛的术语，用于描述分子对各种生物靶标的结合亲和力。&lt;/p&gt;
&lt;p&gt;虽然前三个任务可能看起来微不足道，但仅仅生成有效和稳定的分子就存在各种挑战。因此，&lt;strong&gt;无靶向分子生成领域&lt;/strong&gt;专注于生成有效的分子集合，而不考虑任何生物靶标。&lt;strong&gt;靶向分子生成&lt;/strong&gt;（或配体生成）侧重于针对特定蛋白质结构生成分子，因此更关注药物成分。最后，&lt;strong&gt;3D 构象生成&lt;/strong&gt;涉及在给定 2D 连接的情况下生成各种 3D 构象。&lt;/p&gt;
&lt;h5 id=&#34;无靶向分子设计&#34;&gt;无靶向分子设计
&lt;/h5&gt;&lt;p&gt;必须满足前两个特点，也就是&lt;strong&gt;有效性&lt;/strong&gt;和&lt;strong&gt;稳定性&lt;/strong&gt;。需要满足很多的复杂的条件，所以其实还是挺难的。深度学习可以帮助人们更有效率地生成有更高可能性满足有效性的分子。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务&lt;/strong&gt;：无输入，输出为生成一组新的、有效的、稳定的分子。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：QM9和GEOM-Drug&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指标&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分子生成任务指标&lt;/strong&gt;：原子稳定性、分子稳定性、有效性、独特性、（新颖性）、药物相似性度量估计值QED。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型的评估方式&lt;/strong&gt;：通过在QM9数据集上的一部分训练属性分类网络，然后对模型生成的分子进行评估，计算目标和评估属性值之间的平均绝对误差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分子在特定化学性质方面的指标&lt;/strong&gt;：极化率$α$、最高占据分子轨道能量 $\varepsilon_{HOMO}$、最低未占据分子轨道能量 $\varepsilon_{LUMO}$、$\varepsilon_{HOMO}$ 和 $\varepsilon_{LUMO}$ 的差值$\Delta_\varepsilon$、偶极矩 $\mu$、298.15K 下的摩尔热容 $C_v$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;过去几年间，分子生成任务的方法从一维的SMILES转变成二维的连接图，然后是三维的几何结构，最后到融合二维和三维信息的方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1D SMILES字符串模型&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;早期方法&lt;/strong&gt;：如CVAE、GVAE直接处理，但是SMILES因为是一维的，存在问题：两个化学结构相似的分子图可能会得到非常不同的 SMILES 字符串，这使得模型更难学习到这些相似性和模式。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2D 图生成模型&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JTVAE&lt;/strong&gt;：首个直接生成 2D 分子图的模型，通过树状骨架迭代扩展并验证结构有效性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D 结构模型&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;早期方法&lt;/strong&gt;：Flow-Based方法ENF和自回归方法G-SchNet。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EDM&lt;/strong&gt;：基于Diffusion的 3D 点云模型，利用 E (3) 等变性提升性能，避免原子排序依赖。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GCDM&lt;/strong&gt;：结合几何深度学习与Diffusion，引入注意力机制优化消息传递。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;联合2D和3D&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JODO&lt;/strong&gt;：联合2D和3D的扩散模型，使用几何图形表示来捕获 3D 空间信息和连接信息，对这种联合表示应用分数随机微分方程，同时提出扩散图变换器来参数化数据预测模型，避免在每个独立通道独立添加噪声后相关性的丢失。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MiDi&lt;/strong&gt;：应用了DDPM，提出了「松弛」的图神经网络（EGNN）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里给出了三个表格。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;表格1&lt;/strong&gt;：生成模型在&lt;strong&gt;QM9数据集&lt;/strong&gt;上的&lt;strong&gt;条件无关的分子设计任务&lt;/strong&gt;上的性能表现。Diffusion方法比之前的方法好很多，但是在GEOM-Drugs上可能表现不佳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表格2&lt;/strong&gt;：EDM、MDM、MiDi 等模型在&lt;strong&gt;GEOM-Drugs数据集&lt;/strong&gt;上的&lt;strong&gt;条件无关的分子设计任务&lt;/strong&gt;上性能表现。MiDi能生成更稳定的复杂分子，但是有效性较低。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;表格3&lt;/strong&gt;：生成模型在&lt;strong&gt;条件分子生成任务&lt;/strong&gt;上的性能表现。MDM、GCDM生成表现不错，MDM前四项较好，GCDM后两项较好。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;靶向分子设计&#34;&gt;靶向分子设计
&lt;/h5&gt;&lt;p&gt;有两种，一种是基于配体的药物设计（LBDD），另一种是基于结构的药物设计（SBDD）。LBDD利用目标蛋白质的氨基酸序列，借助已知的配体特征来构建；SBDD利用目标蛋白质的三维结构来设计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务&lt;/strong&gt;：给定氨基酸序列/蛋白质的三维结构，生成对应的有高结合亲和力以及潜在相互作用的分子。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：CrossDocked2020、ZINC20和Binding MOAD。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指标&lt;/strong&gt;：Vina Score、Vina Energy、高亲和力百分比High Affinity Percentage、合成可及性分数SAscore和多样性Diversity。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LBDD&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;结合了Transformer结构，例如DrugGPT，训练的时候输入为SMILES和蛋白质氨基酸序列，从而训练输出可行的SMILES配体。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SBDD&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LiGAN&lt;/strong&gt;：三维目标感知分子输出的概念，将分子适配到网格格式，以便利用卷积神经网络（CNN）进行学习，并在变分自编码器（VAE）框架下训练模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TargetDiff模型&lt;/strong&gt;：基于EGNN进行Diffusion，在结构上和EDM相似，目标是学习条件分布。特别地，研究人员通过原子嵌入的熵来将原子类型的灵活性降低，从而提高结合亲和力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DiffSBDD&lt;/strong&gt;：DiffSBDD-cond是一种DDPM，而在基准测试中，DiffSBDD-inpaint则进行了图像增强，使用掩蔽和替换等方法对配体-蛋白质的部分区域进行处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里给出了一个表格。展示了不同的模型的结果。&lt;/p&gt;
&lt;h4 id=&#34;蛋白质&#34;&gt;蛋白质
&lt;/h4&gt;&lt;h5 id=&#34;任务背景-1&#34;&gt;任务背景
&lt;/h5&gt;&lt;p&gt;蛋白质可以通过其3D结构或者氨基酸序列来表示，氨基酸序列类似人类的语言，可以应用于自然语言模型。可以定义几个子任务：1）&lt;strong&gt;表示学习&lt;/strong&gt;。2）&lt;strong&gt;结构预测&lt;/strong&gt;。3）&lt;strong&gt;序列生成&lt;/strong&gt;。4）&lt;strong&gt;主干设计&lt;/strong&gt;。此外还讨论了&lt;strong&gt;抗体生成&lt;/strong&gt;和&lt;strong&gt;肽生成&lt;/strong&gt;。&lt;/p&gt;
&lt;h5 id=&#34;蛋白质表示学习&#34;&gt;蛋白质表示学习
&lt;/h5&gt;&lt;p&gt;使用氨基酸序列/原子坐标学习一个嵌入从而为其他生成模型创建更丰富的数据空间以供训练。类似于自然语言处理中的word2vec。&lt;/p&gt;
&lt;h5 id=&#34;结构预测&#34;&gt;结构预测
&lt;/h5&gt;&lt;p&gt;从氨基酸序列来预测结构是极具挑战性和重要的工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务&lt;/strong&gt;：从氨基酸序列来预测蛋白质结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：主要来自蛋白质结构预测的关键评估（CASP）。有PDB、CASP14和CAMEO。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指标&lt;/strong&gt;：均方根误差RMSD、全局距离测试总得分GDT-TS、模板建模得分TM-score和局部距离差异测试LDDT。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AlphaFold2&lt;/strong&gt;：里程碑模型。采用端到端的方式集成了多层Transformer，融合多序列比对和成对表示的信息。基于氨基酸之间的成对距离探索折叠空间、氨基酸的潜在取向和整体结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;trRosetta&lt;/strong&gt;：transform-restrained Rosetta。输入MSA之后，预测残基对之间的距离和取向，然后利用Rosetta协议构建3D结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RoseTTAFlod&lt;/strong&gt;：在CASP14上表现效果比肩AlphaFold2，特别是生成速度很快，仅需10分钟，相较AlphaFold2快了100倍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ESMFold&lt;/strong&gt;：利用ESM-2的输出嵌入到自注意力「折叠块」中，并通过以哦个具有SE（3）的transformer架构的结构模块生成最中国的结构预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EigenFold&lt;/strong&gt;：应用Diffusion生成蛋白质结构的模型。它将蛋白质表示为一个谐振子系统，在正向过程中可以将结构投影到该系统的本征模式上，在反向过程中先采样粗糙的全局结构再细化局部细节。作为一种基于分数的模型，EigenFold 计算强度不高，但在准确性和范围方面仍不如其他模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;抗体结构预测&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;这里的MSA结构不能作为抗体的输入。因此通用的模型如AlphaFold2效率非常低。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;IgFlod&lt;/strong&gt;：使用来自AniBERTy的序列嵌入和不变点注意力机制来预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tFlodAb&lt;/strong&gt;：减少了对Rosetta能量函数等外部工具的依赖。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;序列生成&#34;&gt;序列生成
&lt;/h5&gt;&lt;p&gt;序列生成，也被称为反向折叠或固定骨架设计，是结构预测的逆任务。生成能折叠成目标结构的氨基酸序列，对于设计具有期望结构和功能特性的蛋白质至关重要。由于有效序列的空间巨大，且蛋白质折叠过程复杂难以预测，因此需要多种深度学习方法来解决这些挑战&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务&lt;/strong&gt;：给定固定的蛋白质骨架结构，生成能折叠成该结构的相应氨基酸序列。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：模型主要使用 &lt;strong&gt;CATH&lt;/strong&gt; 进行训练，部分会利用 &lt;strong&gt;UniRef&lt;/strong&gt; 和 &lt;strong&gt;UniParc&lt;/strong&gt; 进行数据增强，评估时常用 CATH 和 &lt;strong&gt;TS500&lt;/strong&gt;。此外，Yu 等人创建了一组 14 个已知的从头蛋白质结构，用于避免数据污染。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指标&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AAR（氨基酸恢复率）&lt;/strong&gt;：生成序列与天然序列中匹配氨基酸的比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多样性（Diversity）&lt;/strong&gt;：通过 Clustalw2 测量生成序列对之间的平均差异。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RMSD（均方根偏差）&lt;/strong&gt;：将生成序列折叠成结构后，与天然骨架结构进行比较的结构差异指标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非极性损失（Nonpolar Loss）&lt;/strong&gt;：衡量折叠结构中极性氨基酸类型合理性的指标，表面非极性氨基酸含量越高，损失越大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PPL（困惑度）&lt;/strong&gt;：交叉熵损失的指数化，代表天然序列出现在预测序列分布中的逆可能性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;初步的一类模型&lt;/strong&gt;在不考虑固定骨架目标的情况下生成蛋白质序列。但这些模型无法考虑关键的结构信息。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ProteinVAE&lt;/strong&gt; 利用 ProtBERT 将原始输入序列转化为潜表示；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ProT-VAE&lt;/strong&gt; 使用不同的预训练语言模型 ProtT5NV；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ProteinGAN&lt;/strong&gt; 则采用 GAN 架构。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;主要的模型&lt;/strong&gt;接收固定骨架目标作为输入来生成氨基酸序列。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ProteinSolver&lt;/strong&gt; 将生成骨架结构与解决数独问题联系起来，使用 GNN 架构；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PiFold&lt;/strong&gt; 引入更全面的特征表示；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anand&lt;/strong&gt; 等人设计 3D CNN 直接学习条件分布；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ABACUS-R&lt;/strong&gt; 结合预训练的 transformer 来推断残基的氨基酸类型；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ProRefiner&lt;/strong&gt; 通过引入熵分数改进预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPD&lt;/strong&gt; 使用 Graphormer 架构，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GVP-GNN&lt;/strong&gt; 采用新颖的几何表示，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ESM-IF1&lt;/strong&gt; 扩展表示并在扩展数据集上训练，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ProteinMPNN&lt;/strong&gt; 实现了顺序无关的自回归方法。&lt;/li&gt;
&lt;li&gt;在这些模型中，ProteinMPNN 在序列恢复、RMSD 和非极性损失方面表现最佳，GPD 则是最省时的方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;主干设计&#34;&gt;主干设计
&lt;/h5&gt;&lt;p&gt;生成全新的蛋白质可以直接扩充蛋白质库，实现高度复杂和多样的功能，是从头设计的核心。蛋白质设计在结构和序列上存在差异，有的模型生成 1D 氨基酸序列，有的直接生成 3D 结构，还有的同时设计两者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务&lt;/strong&gt;：从无输入或基于现有背景设计蛋白质骨干结构，即生成每个氨基酸的骨干原子（氮、$\alpha$ - 碳、羰基和氧原子）坐标，外部工具可用于侧链填充。包含上下文无关生成（生成多样的蛋白质结构）和上下文给定生成（根据天然蛋白质的基序填充缺失残基）两个子任务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集&lt;/strong&gt;：常用的数据集有 PDB、AlphaFoldDB、SCOP（及其扩展 SCOPe）和 CATH。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指标&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;scTM（自洽 TM 分数）&lt;/strong&gt;：通过将提议的结构输入序列预测模型（通常是 ProteinMPNN）生成相应氨基酸序列，再将其输入结构预测模型（通常是 AlphaFold2）生成样本结构，计算生成结构与样本结构之间的 TM 分数。分数大于 0.5 的结构通常被认为是可设计的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;scRMSD（自洽 RMSD）&lt;/strong&gt;：与 scTM 类似，但使用 RMSD 进行评估，分数小于 2 通常作为截止值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AAR（氨基酸恢复率）&lt;/strong&gt;：比较生成的氨基酸序列与真实序列的相似程度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RMSD（均方根偏差）&lt;/strong&gt;：衡量生成的残基坐标与真实值之间的距离。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;模型&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;较短蛋白质&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ProtDiff&lt;/strong&gt; 使用 3D 笛卡尔坐标表示每个残基和粒子滤波扩散方法，但 3D 笛卡尔点云不能反映蛋白质折叠过程；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FoldingDiff&lt;/strong&gt; 则使用角度表示，更接近蛋白质折叠过程中的旋转能量优化，通过 DDPM 和 BERT 架构从随机未折叠状态去噪到折叠结构；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LatentDiff&lt;/strong&gt; 先使用带 GNN 的等变蛋白质自动编码器将蛋白质嵌入潜在空间，再用等变扩散模型学习潜在分布，在潜在空间采样比在原始蛋白质空间快十倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;长蛋白结构&lt;/strong&gt;：基于框架的构建方法
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Genie&lt;/strong&gt; 使用由平移和旋转元素确定的框架云进行离散时间扩散来生成骨干结构；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FrameDiff&lt;/strong&gt; 基于框架流形参数化骨干结构，使用基于分数的生成模型；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RFDiffusion&lt;/strong&gt; 结合 RoseTTAFold 的强大结构预测方法和扩散模型，通过微调 RoseTTAFold 权重并输入掩码输入序列和随机噪声坐标来迭代生成骨干结构，还进行自我条件约束，性能优异；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPDL&lt;/strong&gt; 使用 ESMFold 代替 RoseTTAFold 作为基础结构预测模型，并结合 ESM2 语言模型提取进化信息，生成骨干结构速度比 RFDiffusion 快 10 - 20 倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同时设计蛋白质序列和结构&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GeoPro&lt;/strong&gt; 使用 EGNN 编码和预测 3D 蛋白质结构，并设计单独的解码器解码蛋白质序列；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protpardelle&lt;/strong&gt; 在反向扩散过程中对可能的侧链状态进行 “叠加” 并在每次迭代更新时进行塌缩；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ProtSeed&lt;/strong&gt; 使用三角函数感知编码器计算约束和相互作用，并通过等变解码器更新序列和结构；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anand&lt;/strong&gt; 等人使用 IPA 在框架空间中进行扩散，高效生成蛋白质序列和结构 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;抗体CDR-H3生成&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;特别地，抗体生成聚焦于一个被称为 CDR-H3 区域的生成。最开始使用的是&lt;strong&gt;LSTM&lt;/strong&gt;方法，后来转变为&lt;strong&gt;RefineGNN&lt;/strong&gt;方法。此外，一些模型超越了CDR-H3生成任务，而是一次性处理抗体生成的多个环节。&lt;strong&gt;dyMEAN&lt;/strong&gt;是一种端到端的方法将结构预测、对接和CDR-H3生成整合到一个模型中。&lt;/p&gt;
&lt;h5 id=&#34;多肽设计&#34;&gt;多肽设计
&lt;/h5&gt;&lt;p&gt;虽然已经有在蛋白质生成方面的重要、强大的模型，但是由于多肽结构的复杂和依赖于上下文已经下游应用的多样性，因此有必要为多肽的需求来定制模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多肽生成&lt;/strong&gt;：从头生成新型多肽&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MMCD&lt;/strong&gt;：基于Diffusion的治疗性多肽生成模型，它联合设计多肽序列和结构（骨干坐标），采用Transformer编码器处理序列，EGNN 处理结构，并运用对比学习策略对齐序列和结构嵌入，区分治疗性和非治疗性多肽嵌入。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多肽-蛋白质互相作用&lt;/strong&gt;：预测提议的多肽 - 蛋白质对的物理结合位点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PepGB：基于GNN的模型。它利用图注意力神经网络学习多肽和蛋白质之间的相互作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多肽表示学习&lt;/strong&gt;：将原始多肽序列转换为能捕获有价值信息的潜在表示&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PepHarmony&lt;/strong&gt;：使用序列编码器（ESM）和结构编码器（GearNet），多视图对比学习模型，集成序列和结构信息以增强多肽表示学习。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多肽测序&lt;/strong&gt;：解决质谱分析中从含噪数据提取氨基酸序列的挑战&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AdaNovo&lt;/strong&gt;：从头多肽测序模型，由质谱编码器和两个受Transformer架构启发的多肽解码器组成。它利用条件互信息和自适应训练策略，在多种物种的多肽水平和氨基酸水平精度上显著优于之前的模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;最近趋势&#34;&gt;最近趋势
&lt;/h3&gt;&lt;p&gt;生成式AI正在深刻地改变药物设计。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;生成式AI领域&lt;/strong&gt;：&lt;strong&gt;GNN&lt;/strong&gt;和&lt;strong&gt;基于图的方法&lt;/strong&gt;的出现，推动了从基于序列的方法向基于结构的方法的转变，最终促使在生成任务中实现了序列和结构的整合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分子生成领域&lt;/strong&gt;：&lt;strong&gt;基于图的Diffusion模型&lt;/strong&gt;作为主导。利用E（3）等变形来实现最先进的性能。
&lt;ul&gt;
&lt;li&gt;GeoLDM、MiDi——无靶点分子设计&lt;/li&gt;
&lt;li&gt;TargetDiff、Pocket2Mol、DiffSBDD——有靶点分子设计&lt;/li&gt;
&lt;li&gt;Torsional Diffusion——分子构象生成&lt;/li&gt;
&lt;li&gt;此外，有靶点分子设计中也出现了从基于序列的方法到基于结构的方法的出现。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;蛋白质生成领域&lt;/strong&gt;：也出现了从序列到结构的转变。
&lt;ul&gt;
&lt;li&gt;GearNET：基于结构的表示学习模型&lt;/li&gt;
&lt;li&gt;ESM-1B、UniRep：3D结构的重要性&lt;/li&gt;
&lt;li&gt;AlphaFold2：结构预测的最先进模型&lt;/li&gt;
&lt;li&gt;一些Diffusion方法也致力于蛋白质骨架构建。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战
&lt;/h3&gt;&lt;p&gt;分子生成领域：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;复杂性&lt;/li&gt;
&lt;li&gt;适用性&lt;/li&gt;
&lt;li&gt;可解释性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;蛋白质生成领域：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基准测试&lt;/li&gt;
&lt;li&gt;性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论
&lt;/h3&gt;&lt;p&gt;介绍了生成式AI在从头开始的药物设计上的全貌，特别关注分子和蛋白质生成。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;regularized-molecular-conformation-fields--neurips-2022&#34;&gt;Regularized Molecular Conformation Fields | &lt;em&gt;NeurIPS 2022&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://openreview.net/forum?id=7XCFxnG8nGS&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Regularized Molecular Conformation Fields | OpenReview&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;属于上面综述文章里里面的分子生成里面的3D构象生成的部分。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;给定2D分子图，预测有机分子能量最有利的3D构象。&lt;/p&gt;
&lt;h3 id=&#34;挑战-1&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;分子在三维欧氏空间的 SE (3) 变换下具有不变性，&lt;strong&gt;同一分子的构象在刚性运动下有无限可能&lt;/strong&gt;，增加了建模难度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分子在环境条件下存在多种动力学，导致高维且复杂的势能面&lt;/strong&gt;，使得机器学习模型难以识别局部最小值来生成能量有利的构象&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;现有方法使用的不变特征可能冗余、相互依赖&lt;/strong&gt;，导致数值不稳定和不合理的构象预测，且专门的等变层可能降低神经网络的表达能力，部分模型处理环状图存在困难&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法和优势&#34;&gt;核心方法和优势
&lt;/h3&gt;&lt;h4 id=&#34;核心方法&#34;&gt;核心方法
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250302164419.png&#34;
	width=&#34;696&#34;
	height=&#34;322&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250302164419_hu_47c88580c721a8de.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250302164419_hu_5733e9ac51df3b82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;从二维分子如何生成三维分子&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;518px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;构建正则化构象场&lt;/strong&gt;。依据&lt;strong&gt;最少内部自由度&lt;/strong&gt;（DoF）原则将分子分割。蓝色圆圈代表片段构型，一般来说是低内部柔性的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;利用MRF建模&lt;/strong&gt;。红色圆圈是二面角构型，黑色方块是相邻构型之间的相互作用。利用&lt;strong&gt;马尔可夫随机场&lt;/strong&gt;（MRF）对片段构型和二面角构型的联合概率分布进行建模。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推理和采样&lt;/strong&gt;。推理时无环RMCF采用多年&lt;strong&gt;动态规划进行最大后验解码&lt;/strong&gt;，有环使用&lt;strong&gt;LBP算法&lt;/strong&gt;。采样使用&lt;strong&gt;Gibbs采样&lt;/strong&gt;，每次采样后固定其他节点。采样后用特定距离度量样本差异，通过 &lt;strong&gt;K-means 聚类&lt;/strong&gt;，从每个聚类中随机抽取样本，提升生成构象的多样性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构象组装&lt;/strong&gt;。将片段和二面角进行组装。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;优势&#34;&gt;优势
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;通过&lt;strong&gt;分子切割&lt;/strong&gt;减少了构象空间维度，避免生产许多无关变量对模型的影响&lt;/li&gt;
&lt;li&gt;MRF更好地捕捉相邻片段间的关系并对构象不确定性进行建模&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;GEOM-QM9和GEOM-Drugs数据集。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GEOM-QM9&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分子构象的质量和多样性&lt;/strong&gt;：覆盖分数（COV-R）和匹配分数（MAT-R）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预测精度&lt;/strong&gt;：COV-P和MAT-P。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zero-shot-3d-drug-design-by-sketching-and-generating--neurips-2022&#34;&gt;Zero-Shot 3D Drug Design by Sketching and Generating | &lt;em&gt;NeurIPS 2022&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2209.13865&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2209.13865] Zero-Shot 3D Drug Design by Sketching and Generating&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文章属于综述里面的分子生成任务下的&lt;strong&gt;靶向分子设计&lt;/strong&gt;的内容。提出&lt;strong&gt;零样本3D药物设计方法DESERT（Drug dEsign by SkEtching and geneRaTing）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主要解决什么问题&lt;/li&gt;
&lt;li&gt;挑战是什么&lt;/li&gt;
&lt;li&gt;我们提出的核心方法，与同类问题比较的优势在哪&lt;/li&gt;
&lt;li&gt;数据集是什么，是否公开&lt;/li&gt;
&lt;li&gt;评测方式是什么，有无数据集&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;解决的问题-1&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;目前的药物设计中传统方法和深度学习方法都有很多局限性。&lt;/p&gt;
&lt;h3 id=&#34;挑战是什么&#34;&gt;挑战是什么
&lt;/h3&gt;&lt;p&gt;目前的方法都有一些局限性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统方法遍历大规模药物库，耗时且难以产生新的候选药物&lt;/li&gt;
&lt;li&gt;现有的深度学习方法依赖稀缺的实验数据，但是蛋白质口袋的生物活性数据大多缺乏，另一些依赖对接模拟，但是这个非常耗时，且准确性不够会影响模型的泛化能力&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-1&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303131737.png&#34;
	width=&#34;928&#34;
	height=&#34;270&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303131737_hu_7e48d2963d2d3ff2.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303131737_hu_17ab1f6ed7d43097.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;343&#34;
		data-flex-basis=&#34;824px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;这里提出的方法是DESERT。把药物设计分成草图绘制和生成两个阶段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;草图绘制阶段&lt;/strong&gt;：获取与目标口袋互补的合理的分子形状。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有参考配体时&lt;/strong&gt;，直接使用配体形状&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在无参考配体时&lt;/strong&gt;，基于生物学观察从蛋白质口袋中采样合理形状&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303134557.png&#34;
	width=&#34;726&#34;
	height=&#34;273&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303134557_hu_6c67092b4982dd19.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303134557_hu_6895cd912f11c2f3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;265&#34;
		data-flex-basis=&#34;638px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成阶段&lt;/strong&gt;：通过预训练的SHAPE2MOL模型将形状转换为具体的3D分子。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303132757.png&#34;
	width=&#34;779&#34;
	height=&#34;555&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303132757_hu_fc4ad200fb0cf1f3.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250303132757_hu_7688132e18b037f2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里SHAPE2MOL将问题形状到分子的生成问题转换为了图像到序列的生成问题。也就是输入3D图像，给出一个序列，表示3D分子。&lt;/p&gt;
&lt;p&gt;内部结构是3D拓展后的ViT结构。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;优势-1&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;减少数据和模拟依赖&lt;/strong&gt;：DESERT 不严重依赖对接模拟，仅在后期可选使用对接进行后处理，同时抛弃了昂贵的实验数据，通过在大规模分子数据库（如 ZINC 数据库）上训练模型，降低了对实验数据的需求，避免了过拟合问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效快速&lt;/strong&gt;：相比基于 MCMC 的 GEKO 模型，DESERT 利用生物知识修剪搜索空间，能更快速地找到较好的解决方案，生成速度比 GEKO 快约 20 倍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成高质量分子&lt;/strong&gt;：基于形状的设计方式使 DESERT 能够生成质量更高的分子。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-1&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;训练&lt;/strong&gt;：使用了&lt;a class=&#34;link&#34; href=&#34;https://zinc.docking.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ZINC&lt;/a&gt;数据中的数据对SHAPE2MOL模型进行训练，包含了10亿对分子及其相应形状的数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;评估模型性能&lt;/strong&gt;：12 种蛋白质（PDB IDs: 1FKG, 2RD6, 3H7W, 3VRJ, 4CG9, 4OQ3, 4PS7, 5E19, 5MKU, 3FI2, 4J71）相关的数据&lt;/p&gt;
&lt;h3 id=&#34;评测方式-1&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;设计结果覆盖的分子空间&lt;/strong&gt;：唯一性（Uniqueness）、新颖性（Novelty）、多样性（Diversity）、成功率（Success rate）和乘积（Product）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高活性分子的能力&lt;/strong&gt;：通过比较Vina评分的分布，使用 Median Vina Score（Median）来量化分布。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;on-pre-trained-language-models-for-antibody--iclr-2023&#34;&gt;On Pre-trained Language Models for Antibody | &lt;em&gt;ICLR 2023&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2301.12112&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2301.12112] On Pre-trained Language Models for Antibody&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文章属于综述里面的&lt;strong&gt;蛋白质生成里面的抗体生成部分&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主要解决什么问题&lt;/li&gt;
&lt;li&gt;挑战是什么&lt;/li&gt;
&lt;li&gt;我们提出的核心方法，与同类问题比较的优势在哪&lt;/li&gt;
&lt;li&gt;数据集是什么，是否公开&lt;/li&gt;
&lt;li&gt;评测方式是什么，有无数据集&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;解决的问题-2&#34;&gt;解决的问题
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;目前的难以探究目前不同的预训练语言模型在抗体任务中的表现。&lt;/li&gt;
&lt;li&gt;没有引入生物机制在模型之中。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;挑战-2&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;缺乏可靠的抗体特异性基准用于性能评估；&lt;/li&gt;
&lt;li&gt;对当前蛋白质预训练语言模型（PPLMs）和抗体预训练语言模型（PALMs）的综合研究不足；&lt;/li&gt;
&lt;li&gt;难以判断引入生物机制是否能真正有益于抗体表示学习；&lt;/li&gt;
&lt;li&gt;确定预训练表示在实际应用（如药物发现和免疫过程理解）中的作用存在困难&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;预训练蛋白质语言模型PPLMs&lt;/strong&gt;：&lt;br&gt;
利用蛋白质序列探索大语言模型。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如ProtTrans和ESM-1b将单个蛋白质序列作为输入，使用Transformer架构进行预训练。&lt;/li&gt;
&lt;li&gt;MSA-Transformer/MSA-1b模型通过多序列比对（MSA）作为输入。在结构预测方面，该模型优于 ESM-1b，这表明进化信息有助于蛋白质表征学习。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;预训练抗体语言模型PALMs：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AntiBERTy：提出首个抗体特异性语言模型，对在OAS数据库中的5.58亿条天然抗体序列使用Transformer架构进行预训练。&lt;/li&gt;
&lt;li&gt;Abalang-H/L：恢复抗体序列中缺失的残基上的迁移学习。&lt;/li&gt;
&lt;li&gt;AntiBERTa：在OAS数据库上预训练，并进行微调以用于抗原结合位点位置预测。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;核心方法-2&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出了&lt;strong&gt;抗体理解评估（AnTibody Understanding Evaluation，ATUE）基准&lt;/strong&gt;和包含特定进化信息的&lt;strong&gt;EATLM模型&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307170648.png&#34;
	width=&#34;1535&#34;
	height=&#34;477&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307170648_hu_c03e2673fa3ed9e6.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307170648_hu_d17a54524050df16.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;321&#34;
		data-flex-basis=&#34;772px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建了一个全面的&lt;strong&gt;抗体基准测试工具ATUE&lt;/strong&gt;。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;抗原结合预测&lt;/strong&gt;：二分类序列分类任务，确定抗体的CDR区域能否与特定抗原结合。
&lt;ul&gt;
&lt;li&gt;原因：通过对抗体 CDR 区域的分析，预测其与特定抗原的结合情况，有助于筛选出具有潜在治疗效果的抗体。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;互补决定区预测&lt;/strong&gt;：确定抗体序列上的结合位置的序列标注任务为 CDR 片段的每个残基预测 0/1 标签。
&lt;ul&gt;
&lt;li&gt;原因：确定抗体与抗原的结合位置，有助于深入理解抗体与抗原的相互作用机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B 细胞成熟分析&lt;/strong&gt;：是一个 6 分类任务，区分 B 细胞抗体序列的成熟阶段，每个序列属于 {未成熟、过渡、成熟、浆细胞、记忆 IgD+、记忆 IgD-} 中的一种。
&lt;ul&gt;
&lt;li&gt;原因：有助于理解免疫进化过程中的机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抗体发现&lt;/strong&gt;：是一个二分类序列分类任务，区分哪个抗体直接对 SARS-CoV-2 结合负责。
&lt;ul&gt;
&lt;li&gt;原因：从大量抗体中找出能与 SARS-CoV-2 结合的抗体，对于开发针对该病毒的治疗方法意义重大。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;得出了关键观察结果，提供了&lt;strong&gt;如何更好地表示抗体的一些指导方针&lt;/strong&gt;。
&lt;ul&gt;
&lt;li&gt;PPLMs 在与结构高度相关的抗体任务中表现良好，但在具有高抗体特异性的任务中表现不佳&lt;/li&gt;
&lt;li&gt;在大多数情况下，PALMs 在预训练数据较少时表现得与 PPLMs 一样好甚至更好&lt;/li&gt;
&lt;li&gt;通过结合进化过程可以改进 PALMs，但来自 MSA 的进化信息并不总是对抗体任务有益&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;探究引入生物机制对模型的影响，&lt;strong&gt;提出EATLM模型&lt;/strong&gt;。
&lt;ul&gt;
&lt;li&gt;在传统掩码语言建模（MLM）的基础上，引入&lt;strong&gt;两个新的预训练目标&lt;/strong&gt;以模拟抗体进化的生物机制。
&lt;ul&gt;
&lt;li&gt;祖先种系预测AGP&lt;/li&gt;
&lt;li&gt;突变位置预测MPP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-2&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;ATUE基准&lt;/strong&gt;涵盖了多个具有不同特异性的真实任务，能更加全面地评估模型。&lt;/p&gt;
&lt;p&gt;对于&lt;strong&gt;EATLM模型&lt;/strong&gt;来说，引入了AGP和MPP两个预训练目标之后，有以下优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;抗原结合预测：对AUC和F1指标有改进&lt;/li&gt;
&lt;li&gt;表达预测：在F1和MCC指标上优于其他模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B细胞成熟分析任务&lt;/strong&gt;：显著优于其他PALM模型&lt;/li&gt;
&lt;li&gt;抗体发现任务：是识别所有钱再结合物最有效的方法，&lt;strong&gt;确定了11种潜在的SARS-CoV-2结合抗体&lt;/strong&gt;，展示了在实际应用中的潜力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-2&#34;&gt;数据集
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;抗原结合预测
&lt;ul&gt;
&lt;li&gt;Mason等人（2021）的数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;互补决定区预测
&lt;ul&gt;
&lt;li&gt;使用从 Liberis 等人（2018）收集的包含 1662 个 CDR 片段的数据进行研究。由于只有部分抗体来自进化，所以该任务具有中等特异性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;B细胞成熟分析
&lt;ul&gt;
&lt;li&gt;数据集来自 Mroczek 等人（2014），有 6 个成熟阶段的 88094 个序列。特异性高，抗体进化与 B 细胞成熟高度耦合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;抗体发现
&lt;ul&gt;
&lt;li&gt;研究人员收集了 133 名 SARS-CoV-2 患者和 87 名健康人的抗体序列，按照特定流程处理数据，并与 CoV-AbDab 数据库中的序列匹配，以确定潜在的结合抗体。由于来自同一疾病的抗体具有强烈的趋同种系信号，所以该任务特异性高。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-2&#34;&gt;评测方式
&lt;/h3&gt;&lt;p&gt;对于不同任务，分别进行评估：准确度ACC、马修斯相关系数MCC、F1值、AUC。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;learning-harmonic-molecular-representations-on-riemannian-manifold--iclr-2023&#34;&gt;Learning Harmonic Molecular Representations on Riemannian Manifold | &lt;em&gt;ICLR 2023&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2303.15520&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2303.15520] Learning Harmonic Molecular Representations on Riemannian Manifold&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇文章所属的领域属于&lt;strong&gt;分子生成领域&lt;/strong&gt;中的&lt;strong&gt;表示学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-3&#34;&gt;解决的问题
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;现在的基于欧几里得空间的分子表示方法需要借助等变网络保证分子在表示旋转和平移的时候的一致性，这里的等距变换群就是E(3)/SE(3)。&lt;/li&gt;
&lt;li&gt;目前的分子表示学习多采用自下而上，难以提供不同分辨率的特征。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;挑战-3&#34;&gt;挑战
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;设计一种绕过等变要求，并且能够准确编码3D分子结构的表示。&lt;/li&gt;
&lt;li&gt;开发在不同分辨率下为不同任务提供合适特征的多分辨率消息传递机制，特别是复杂的大分子。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;核心方法-3&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;用分子表面的拉普拉斯 - 贝尔特拉米（Laplace - Beltrami）特征函数来表示分子，在 2D 黎曼流形上实现多分辨率的分子几何和化学特征表示，并引入谐波消息传递方法进行高效的谱消息传递。&lt;/p&gt;
&lt;blockquote&gt;
&lt;details&gt;
    &lt;summary&gt;大模型的解释：&lt;/summary&gt;
    &lt;ol&gt;
&lt;li&gt;&lt;strong&gt;改变表示空间&lt;/strong&gt;：传统方法在 3D 欧几里得空间中编码分子结构，为保证分子表示在旋转和平移时的正确性，需要借助等变网络。而该方法将分子表示在 2D 黎曼流形上。可以把黎曼流形想象成一个可以弯曲、变形，但局部性质类似欧几里得空间的特殊空间。在这个空间上，分子的表示天生就具有旋转和平移不变性。就好比把分子放在一个有弹性但又有自身规律的 “网” 上，无论分子怎么旋转、平移，这个 “网” 对分子的描述都不会改变，不需要额外的等变网络来调整，从而绕过了等变要求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;利用拉普拉斯 - 贝尔特拉米特征函数&lt;/strong&gt;：分子表面可看作黎曼流形，拉普拉斯 - 贝尔特拉米（LB）特征函数是这个流形的固有属性。不同的分子表面有不同的 LB 特征函数，它们就像分子的 “指纹”，能反映分子的形状和结构特点。这些特征函数在刚性变换下保持不变，所以可以用来准确编码分子结构。例如，我们可以把分子表面想象成一个有很多不同纹理的曲面，LB 特征函数就像是描述这些纹理分布规律的工具，不管分子怎么转动、移动，这些纹理的分布规律是不变的，通过分析这些规律就能准确编码分子结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多分辨率表示与信息传递&lt;/strong&gt;：通过对 LB 特征函数的线性组合，可以实现分子表面的多分辨率表示。不同频率的 LB 特征函数可以捕捉分子不同尺度的特征，低频部分反映分子的整体、大致的形状，高频部分则能体现分子的细节特征。在进行信息传递（类似消息在分子表面不同区域传播）时，利用基于 LB 特征函数构建的谐波消息传递机制，能在不同尺度上传播信息。这就好像在一个城市中，有不同规模的道路来传递信息，主干道（低频特征）传递整体的、大致的信息，小巷（高频特征）传递详细的、局部的信息，从而全面、准确地编码 3D 分子结构&lt;/li&gt;
&lt;/ol&gt;

&lt;/details&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;优势-3&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在2D黎曼流形上的分子天然具有旋转和平移不变性，无需依赖等变网络&lt;/li&gt;
&lt;li&gt;采用自上而下的方式，能提供多分辨率特征&lt;/li&gt;
&lt;li&gt;分子形状定义了黎曼流形，原子构型决定流形上的相关函数，更全面反映分子性质&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-3&#34;&gt;数据集
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://springernature.figshare.com/ndownloader/files/3195389&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;QM9&lt;/a&gt;：小分子性质回归任务&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://zenodo.org/record/2625420&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;配体结合口袋数据集&lt;/a&gt;，数据划分方式参考&lt;a class=&#34;link&#34; href=&#34;https://github.com/LPDI-EPFL/masif/tree/master/data/masif_ligand/lists&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这里&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/BioinfoMachineLearning/DIPS-Plus&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;刚性蛋白质对接数据集&lt;/a&gt;作为训练集，&lt;a class=&#34;link&#34; href=&#34;https://github.com/bjornwallner/DockQ/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Docking Benchmark 5.5&lt;/a&gt;作为测试集。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-3&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;QM9 小分子性质回归&lt;/strong&gt;：通过计算预测结果与真实值的平均绝对误差（MAE）来评估模型性能，对比其他不变性和等变网络模型，如 SchNet、NMP 等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;配体结合口袋分类&lt;/strong&gt;：使用平衡准确率评估模型预测蛋白质口袋结合配体类型的能力，与 MaSIF-ligand 模型对比。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;刚性蛋白质对接&lt;/strong&gt;：采用 Complex RMSD、Interface RMSD、DockQ 和成功率等指标评估对接性能。Complex RMSD 和 Interface RMSD 衡量预测结构与真实结构的偏差；DockQ 是基于多个标准化标准的综合评分；成功率表示预测结果达到 “可接受” 或更高水平的比例 。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;coarse-to-fine-a-hierarchical-diffusion-model-for-molecule-generation-in-3d--icml-2023&#34;&gt;Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D | &lt;em&gt;ICML 2023&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2305.13266&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2305.13266] Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文章属于综述里面的&lt;strong&gt;分子生成&lt;/strong&gt;中的&lt;strong&gt;3D分子生成&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-4&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;现有的3D分子生成方法在生成大尺寸分子的时候存在结构质量差的问题。&lt;/p&gt;
&lt;h3 id=&#34;挑战-4&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自回归模型&lt;/strong&gt;：按照人工设定的顺序逐个生成原子，如同语言生成过程。但分子在 3D 空间具有自然的几何结构，这种方法引入的人为顺序与分子的自然结构不匹配，并且会产生规模和误差累积问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;非自回归模型&lt;/strong&gt;：&lt;strong&gt;原先的原子级生成方法&lt;/strong&gt;虽然灵活性较高，但是在片段级生成时，由于化学价态限制，片段冲突常见，且避免片段冲突的复杂度高，随着结构尺寸增加，复杂度呈指数上升，难以获得可靠的分子结构。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-4&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出基于分层Diffusion的分子生成方法Hierarchical Diffusion-based 模型（HierDiff）。&lt;/p&gt;
&lt;p&gt;将3D分子生成问题看作约束生成问题。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307201443.png&#34;
	width=&#34;1211&#34;
	height=&#34;231&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307201443_hu_eb530aaafa37be71.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307201443_hu_ceb7df11a1227dd5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;524&#34;
		data-flex-basis=&#34;1258px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先通过&lt;strong&gt;等变Diffusion过程&lt;/strong&gt;生成粗粒度分子几何结构，其中每个粗粒度节点反映分子中的一个片段&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;消息传递过程&lt;/strong&gt;和一个新设计的&lt;strong&gt;迭代细化采样模块&lt;/strong&gt;，将粗粒度节点解码为细粒度片段&lt;/li&gt;
&lt;li&gt;将&lt;strong&gt;细粒度片段组装起来&lt;/strong&gt;，得到完整的原子分子结构&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;details&gt;
    &lt;summary&gt;详细解释&lt;/summary&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;strong&gt;粗粒度片段扩散&lt;/strong&gt;：HierDiff 将 3D 分子生成视为约束生成问题，首先定义粗粒度节点的表示，包括不变化学特征和等变位置特征。通过精心设计化学特征（如基于属性和元素的特征）和位置特征（使用中心坐标），利用扩散模型生成粗粒度片段表示及其笛卡尔坐标。在这个过程中，通过特殊设计的初始分布和转移核，保证模型的 SE (3) 不变性，从而有效生成合理的粗粒度分子几何结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;细粒度片段生成&lt;/strong&gt;：基于生成的粗粒度节点，通过一系列步骤生成细粒度片段类型和边。具体包括选择焦点节点、预测新边、确定细粒度片段类型以及迭代细化。利用消息传递神经网络和迭代细化模块，不断纠正细粒度节点中的偏差，提高生成分子的真实性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;组装成原子构象&lt;/strong&gt;：根据细粒度生成过程确定的节点和链接关系，选择合适的原子合并方式构建原子级构象。利用 RDkit 生成局部构象，并通过 Kabsch 算法计算旋转矩阵和平移向量，将局部构象对齐到采样的中心位置，逐步生成完整的原子构象。&lt;/li&gt;
&lt;/ul&gt;

&lt;/details&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;优势-4&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;与同类方法相比，HierDiff 能保持非自回归方法的全局建模特性，显著降低寻找可连接片段的复杂度，有效避免片段冲突，生成的分子更具现实性和药物样属性，在多个评估指标上优于现有方法。&lt;/p&gt;
&lt;h3 id=&#34;数据集-4&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;使用GEOM-Drugs和CrossDocked2020数据集。&lt;/p&gt;
&lt;h3 id=&#34;评测方式-4&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;药物相似性
&lt;ul&gt;
&lt;li&gt;QED&lt;/li&gt;
&lt;li&gt;逆向合成可及性RA&lt;/li&gt;
&lt;li&gt;药物化学过滤器MCF&lt;/li&gt;
&lt;li&gt;合成可及性分数SAS&lt;/li&gt;
&lt;li&gt;LogP&lt;/li&gt;
&lt;li&gt;$\Delta$LogP&lt;/li&gt;
&lt;li&gt;分子重量MW&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构象质量
&lt;ul&gt;
&lt;li&gt;计算覆盖度Cov&lt;/li&gt;
&lt;li&gt;匹配度Mat&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accelerating-antimicrobial-peptide-discovery-with-latent-structure--sigkdd-2023&#34;&gt;Accelerating Antimicrobial Peptide Discovery with Latent Structure | &lt;em&gt;SIGKDD 2023&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2212.09450&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2212.09450] Accelerating Antimicrobial Peptide Discovery with Latent Structure&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇文章属于综述下面的&lt;strong&gt;蛋白质生成&lt;/strong&gt;下的&lt;strong&gt;肽设计&lt;/strong&gt;部分。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-5&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;加速抗菌肽（AMP）的发现。现有的深度学习模型只考虑序列属性，但是忽略了结构对于活性的关系。&lt;/p&gt;
&lt;h3 id=&#34;挑战-5&#34;&gt;挑战
&lt;/h3&gt;&lt;p&gt;目前深度学习模型只考虑序列特征，忽略结构-活性关系。结构对于肽的活性具有重要影响，但是却没有应用。&lt;/p&gt;
&lt;h3 id=&#34;核心方法-5&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出 Latent Sequence-Structure 模型（LSSAMP）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将&lt;strong&gt;序列特征&lt;/strong&gt;和&lt;strong&gt;二级结构&lt;/strong&gt;映射到潜空间中&lt;/li&gt;
&lt;li&gt;采用&lt;strong&gt;VQ-VAE&lt;/strong&gt;为每个位置分配一个潜在变量&lt;/li&gt;
&lt;li&gt;通过在&lt;strong&gt;潜空间采样&lt;/strong&gt;生成理想序列组成和结构的肽&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-5&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;考虑了序列和结构信息，肽的抗菌性更强&lt;/p&gt;
&lt;h3 id=&#34;数据集-5&#34;&gt;数据集
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Universal Protein Resource（UniProt）中的蛋白质序列和通过ProSPr预测的二级结构&lt;/li&gt;
&lt;li&gt;Antimicrobial Peptide Database中的抗菌肽数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-5&#34;&gt;评测方式
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;自动评估指标&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;使用开源的AMP预测工具估计生成序列的AMP概率。&lt;/li&gt;
&lt;li&gt;依据电荷、疏水性、疏水矩这三个对AMP机制至关重要的序列属性评估生成性能。&lt;/li&gt;
&lt;li&gt;通过唯一性、多样性和相似性来衡量生成的肽的新颖性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;湿实验室实验&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;通过上面的自动评估指标从5000个肽中筛选出21个肽进行合成实验&lt;/li&gt;
&lt;li&gt;合成了之后在培养皿中采用肉汤微量稀释法测定最小抑菌浓度（MIC）,从而验证。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;equivariant-flow-matching-with-hybrid-probability-transport-for-3d-molecule-generation--neurips-2023&#34;&gt;Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation | &lt;em&gt;NeurIPS 2023&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;分子生成&lt;/strong&gt;领域中的&lt;strong&gt;3D分子生成&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-6&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;3D 分子生成需要同时确定原子类型和坐标。&lt;/p&gt;
&lt;p&gt;目前的模型，特别是Diffusion方法存在采样速度低和概率动力学不稳定的问题。&lt;/p&gt;
&lt;h3 id=&#34;挑战-6&#34;&gt;挑战
&lt;/h3&gt;&lt;p&gt;现在的扩散模型存在概率动力学不稳定和采样速度低的问题。&lt;/p&gt;
&lt;h3 id=&#34;核心方法-6&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出&lt;strong&gt;等变流匹配&lt;/strong&gt;（EquiFM）框架。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入&lt;strong&gt;等变最优传输&lt;/strong&gt;（Equivariant Optimal-Transport）引导原子坐标的生成概率路径。这方法蕴含最小化坐标变化的先验，能稳定训练并提升生成性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于信息量构建混合生成路径解决模态不一致问题&lt;/strong&gt;：根据不同组件的信息量差异，设计不同的生成概率路径，形成混合生成路径。
&lt;ul&gt;
&lt;li&gt;原子特征空间包含多种数据模态，如电荷、原子类型和坐标分别属于离散、整数和连续变量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;利用 ODE 参数化模型提升推理效率&lt;/strong&gt;：模型基于连续归一化流，由 ODE 参数化。相比Diffusion使用的SDE提高了推理效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-6&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;稳定&lt;/li&gt;
&lt;li&gt;效率高&lt;/li&gt;
&lt;li&gt;生成分子质量更好&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-6&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;QM9、GEOM-DRUG数据集&lt;/p&gt;
&lt;h3 id=&#34;评测方式-6&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分子建模与生成&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;通过预测键类型评估生成分子的化学可行性，计算原子稳定性、分子稳定性、有效性、唯一性等指标衡量生成质量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;条件分子生成&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;在 QM9 数据集上测试模型根据给定属性生成分子的能力，通过计算生成分子属性值与目标属性值的平均绝对误差（MAE）来评估性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;unified-generative-modeling-of-3d-molecules-with-bayesian-flow-networks--iclr-2024&#34;&gt;Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks | &lt;em&gt;ICLR 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;分子生成&lt;/strong&gt;领域的&lt;strong&gt;3D分子生成&lt;/strong&gt;部分。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-7&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;生成模型在应用于3D分子几何生成时面临的挑战，尤其是多模态和噪声敏感性问题。&lt;/p&gt;
&lt;h3 id=&#34;挑战-7&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;多模态
&lt;ul&gt;
&lt;li&gt;分子几何的原子级描述依赖多种数据形式，不同模态数据的统一处理较为困难。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;噪声敏感性
&lt;ul&gt;
&lt;li&gt;微小的坐标噪声就可能导致分子层面的信号急剧下降，影响模型性能&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-7&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出GeoBFN。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;贝叶斯流网络BFNs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设：数据样本的信息应沿着潜变量的马尔科夫链逐步增加，且信息变化尽可能平滑。&lt;/li&gt;
&lt;li&gt;基于&lt;strong&gt;引入噪声变量的潜变量模型&lt;/strong&gt;，通过优化变分下界学习概率分布，在&lt;strong&gt;参数空间&lt;/strong&gt;操作以保证信息变化平滑&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;统一概率建模&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;使用统一的概率建模公式处理分子几何中的不同模态。&lt;/li&gt;
&lt;li&gt;将3D分子表示为$g=&amp;lt;x,h&amp;gt;$，其中$x$为原子坐标矩阵，$h$包含原子类型和原子电荷等节点信息。&lt;/li&gt;
&lt;li&gt;通过EGNN对输出分布进行参数化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;保持SE(3)不变性&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;零质心空间约束下，通过设计满足特定条件的概率模型，使似然函数 \(p_{\phi}\) 具有平移和旋转不变性，&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;克服噪声敏感性&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;GeoBFN 在参数空间中通过贝叶斯更新过程来降低方差。在更新中，噪声程度较低的样本会被赋予更小的权重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化离散变量采样&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;NEAREST_CENTER&lt;/code&gt;函数将输入和中心桶进行比较，并为每个输入值返回值返回最近的中心。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-7&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;生成质量上表现卓越。&lt;/li&gt;
&lt;li&gt;可以在任意采样步数下达到效率和质量的最优平衡&lt;/li&gt;
&lt;li&gt;采样效率较高&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-7&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;QM9和GEOM-Drugs&lt;/p&gt;
&lt;h3 id=&#34;评测方式-7&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;无条件分子生成&lt;/li&gt;
&lt;li&gt;条件分子生成&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;multimodal-molecular-pretraining-via-modality-blending--iclr-2024&#34;&gt;Multimodal Molecular Pretraining via Modality Blending | &lt;em&gt;ICLR 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;分子生成&lt;/strong&gt;领域中的&lt;strong&gt;表示学习方向&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-8&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;现在的多模态分子预训练方法在对齐2D和3D模态时，仅进行粗粒度分子级对齐，未充分挖掘内在关系。&lt;/p&gt;
&lt;h3 id=&#34;挑战-8&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;准确捕捉2D和3D分子中原子关系的内在联系&lt;/li&gt;
&lt;li&gt;充分整合多模态信息的模型架构和训练方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-8&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出blend-then-predict自监督学习方法。&lt;br&gt;
&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307214720.png&#34;
	width=&#34;1062&#34;
	height=&#34;672&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307214720_hu_1b902d3b0bdb3a25.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307214720_hu_da52288dde63f8c1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;379px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将&lt;strong&gt;不同模态的原子关系混合成统一矩阵&lt;/strong&gt;进行联合编码，注入到Transformer的自注意力模块中&lt;/li&gt;
&lt;li&gt;再恢复特定模态信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-8&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;能在细粒度原子级别对齐和整合2D和3D模态，全面描绘分子&lt;/p&gt;
&lt;h3 id=&#34;数据集-8&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;预训练使用 PCQM4Mv2 数据集，来自 OGB Large - Scale Challenge.&lt;/p&gt;
&lt;p&gt;评估在多个公开数据集上进行&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MoleculeNet（用于 2D 分子性质预测，涵盖多种分子性质相关数据集）&lt;/li&gt;
&lt;li&gt;QM9 量子性质数据集（包含 13.4 万个小有机分子，用于 3D 任务评估）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-8&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;2D任务：使用支架分割（scaffold split）方式划分数据集
&lt;ul&gt;
&lt;li&gt;分类任务以ROC-AUC分数为指标&lt;/li&gt;
&lt;li&gt;回归任务以RMSE为指标&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3D任务：随机划分验证集和测试集
&lt;ul&gt;
&lt;li&gt;以MAE为评估指标&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;learning-multi-view-molecular-representations-with-structured-and-unstructured-knowledge--sigkdd-2024&#34;&gt;Learning Multi-view Molecular Representations with Structured and Unstructured Knowledge | &lt;em&gt;SIGKDD 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于分子生成领域的表示学习方向。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-9&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;现有分子表示学习（MRL）模型在学习多视图分子表示时存在不足&lt;/strong&gt;。难以从化学结构、生物医学文本和知识图谱等异构源中有效捕捉分子知识，且无法充分利用不同视图间的共识和互补信息，不能很好地适应不同应用场景。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;多视图分子表示指的是从不同角度捕捉分子信息，如从微观角度，分子有原子、化学键等；从宏观角度，分子的晶体结构、物理状态等。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;挑战-9&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;现有分子表示学习（MRL） 模型需将视图信息&lt;strong&gt;显式&lt;/strong&gt;融入表示中，以适应广泛应用，但此前模型多通过 “包装文本” 或微调隐式整合，影响对不同视图知识关系的理解&lt;/li&gt;
&lt;li&gt;要处理分子结构、生物医学文本和知识图谱等质量和数量各异的信息源的异质性，以往将知识图谱转换为文本的方法可能因预训练数据分布不均衡引入偏差。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-9&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250306231852.png&#34;
	width=&#34;1548&#34;
	height=&#34;738&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250306231852_hu_22d4773d0f4f744c.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250306231852_hu_5677115ae1a6f8b9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;503px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;提出 MV-Mol 模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MV-Mol 模型架构
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(a) 基于视图的分子编码器&lt;/strong&gt;：此编码器是获取视图相关分子信息的关键组件，输入为分子结构和文本提示。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;（b）分子分支&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;结构由\(M=(V, E, C)\)表示，利用预训练的 Uni-Mol 进行编码，将其转化为原子的特征表示\(z(a)\)。&lt;/li&gt;
&lt;li&gt;Q-Former 的分子分支以 K 个可训练的查询向量作为输入嵌入，借助跨注意力机制，在每隔一个 Transformer 层时，从原子表示\(z(a)\)中提取关键信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;（c）文本分支&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;提示\(T=[x_{1}, x_{2}, \cdots, x_{L}]\)代表不同的分子视图。&lt;/li&gt;
&lt;li&gt;Q-Former 的文本分支对文本提示T进行处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Q-Former 两个分支的自注意力层共享，使分子表示能够融合不同视图的信息，最终输出基于视图的分子表示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;（d）模态对齐&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;通过跨模态对比和跨模态匹配进行模态对齐。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨模态对比损失&lt;/strong&gt;用于最大化分子结构与文本表示间的互信息，&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨模态匹配损失&lt;/strong&gt;则通过预测分子结构和文本是否对应同一分子，来培养模型对两者的细粒度理解&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;（e）多视图知识融合&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;将关系建模为一种文本提示，从特定视图约束分子知识。&lt;/li&gt;
&lt;li&gt;设计知识图谱嵌入和知识图谱不全目标来实现多视图知识融合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态解码器&lt;/strong&gt;：采用 BioT5 的解码器作为多模态解码器。
&lt;ul&gt;
&lt;li&gt;输入是基于视图的分子编码器输出。&lt;/li&gt;
&lt;li&gt;通过因果生成，将输入转化为自然语言文本，实现对分子表示的自然语言解释 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-9&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;MV-Mol 能更好地捕捉不同视图的分子知识。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在分子属性预测任务上，比最先进的 Uni-Mol 模型平均绝对增益 1.24%&lt;/li&gt;
&lt;li&gt;在跨模态检索任务中，相比最佳基线模型，top-1 检索准确率平均提高 12.9%&lt;/li&gt;
&lt;li&gt;在跨模态生成任务中预测也更准确。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-9&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;预训练采用&lt;strong&gt;大规模分子-文本对和知识图谱&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分子 - 文本对通过对 350 万篇科学出版物进行命名实体识别和实体链接获得&lt;/li&gt;
&lt;li&gt;知识图谱由多个公共数据库合并构建。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下游实验使用多个数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用于分子属性预测的 MoleculeNet 中的 8 个分类数据集&lt;/li&gt;
&lt;li&gt;用于跨模态检索的 PCdes 和 MVST 数据集&lt;/li&gt;
&lt;li&gt;用于跨模态生成的 ChEBI-20 数据集等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码和数据可在&lt;a class=&#34;link&#34; href=&#34;https://github.com/PharMolix/OpenBioMed&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PharMolix/OpenBioMed&lt;/a&gt;获取。&lt;/p&gt;
&lt;h3 id=&#34;评测方式-9&#34;&gt;评测方式
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;在&lt;strong&gt;分子属性预测&lt;/strong&gt;中
&lt;ol&gt;
&lt;li&gt;采用 Scaffold split 划分数据集&lt;/li&gt;
&lt;li&gt;在多个数据集上微调模型并报告 AUROC 分数&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨模态检索&lt;/strong&gt;包含结构到文本和文本到结构检索两个子任务，
&lt;ol&gt;
&lt;li&gt;使用 PCdes 和 MVST 数据集&lt;/li&gt;
&lt;li&gt;按 Scaffold split 划分&lt;/li&gt;
&lt;li&gt;报告 MRR（平均倒数排名）和 Recall at 1/5/10&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨模态生成&lt;/strong&gt;包括结构到文本生成和文本到结构生成
&lt;ol&gt;
&lt;li&gt;在 ChEBI-20 数据集上按原始划分进行实验&lt;/li&gt;
&lt;li&gt;采用 BLEU、ROUGE、METEOR 等指标评估分子字幕任务&lt;/li&gt;
&lt;li&gt;用精确率、有效率等指标评估文本到分子生成任务&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;molcraft-structure-based-drug-design-in-continuous-parameter-space--icml-2024&#34;&gt;MolCRAFT: Structure-Based Drug Design in Continuous Parameter Space | &lt;em&gt;ICML 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;分子生成&lt;/strong&gt;领域的&lt;strong&gt;靶向药物分子设计&lt;/strong&gt;方向中的&lt;strong&gt;基于结构的药物设计（SBDD）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-10&#34;&gt;解决的问题
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;靶向分子设计有两种，一种是基于配体的药物设计（LBDD），另一种是基于结构的药物设计（SBDD）。LBDD利用目标蛋白质的氨基酸序列，借助已知的配体特征来构建；SBDD利用目标蛋白质的三维结构来设计。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;当前基于SBDD生成模型在生成分子时，常出现不符合要求的情况。&lt;/p&gt;
&lt;p&gt;生成的分子不能同时满足高亲和力、良好的类药性质和合理的 3D 构象这几个关键标准，产生假阳性结果，阻碍了 SBDD 模型在实际中的应用 。&lt;/p&gt;
&lt;h3 id=&#34;挑战-10&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分子模式坍塌&lt;/strong&gt;：自回归模型在生成分子时倾向于产生有限数量的特定（子）结构，从化学和几何角度来看，其生成的独特分子比例较低，对某些环结构存在偏好，且在模拟不同键类型的键长时表现不佳，无法有效捕捉参考分布的多模态特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;混合连续 - 离散空间&lt;/strong&gt;：Diffusion模型虽然通过非自回归生成在一定程度上缓解了模式坍塌问题，但&lt;strong&gt;混合连续 - 离散空间使得模型难以准确捕获分子的复杂数据流形&lt;/strong&gt;。在这个空间中进行去噪时，不同模态之间的不一致性会导致生成的分子存在高应变和不可行的情况，中间噪声潜在值容易超出流形范围。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-10&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出&lt;strong&gt;MolCRAFT模型&lt;/strong&gt;，是首个在连续空间运行的SBDD模型。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特点
&lt;ul&gt;
&lt;li&gt;统一的 SE-(3) 等变生成模型&lt;/li&gt;
&lt;li&gt;在连续参数空间中进行分子生成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;实现
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;统一参数化&lt;/strong&gt;：将连续原子坐标和离散原子类型分别进行参数化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不同模态噪声处理&lt;/strong&gt;：由于参数的连续性，即使对于离散原子类型也能应用连续噪声。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SE(3)等变网络&lt;/strong&gt;：使用 SE-(3) 等变网络对蛋白质 - 分子复合物的相互作用进行建模，确保模型在平移和旋转下的不变性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;噪声减少采样策略&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;传统的采样方式在每个时间步都对连续原子坐标和离散原子类型进行采样，易引入过多噪声。&lt;/li&gt;
&lt;li&gt;MolCRAFT 设计了在参数空间内的噪声减少采样策略，用估计的\(\hat{m}=[\hat{x},\hat{v}]\)（\(\hat{v}\)直接采用连续输出的类别值而不采样）直接更新下一步的参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-10&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;结合亲和力。
&lt;ul&gt;
&lt;li&gt;能达到参考水平的 Vina 评分（-6.59 kcal/mol），远超其他强基线模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构象稳定性
&lt;ul&gt;
&lt;li&gt;在模拟局部模式时表现出色，在键长和角度分布上排名第一，且生成的配体 - 蛋白质复合物中的冲突更少，重新对接后的 RMSD 表现最佳，46% 的生成分子在无需力场优化或重新对接的情况下就接近准确的对接姿势&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;采样效率更高
&lt;ul&gt;
&lt;li&gt;速度更快&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-10&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;使用 &lt;strong&gt;CrossDocked 数据集&lt;/strong&gt;，经过基于 RMSD 的过滤和 30% 序列同一性拆分后，得到 100,000 个训练对和 100 个测试蛋白质。&lt;/p&gt;
&lt;h3 id=&#34;评测方式-10&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;结合亲和力&lt;/li&gt;
&lt;li&gt;构象稳定性&lt;/li&gt;
&lt;li&gt;类药性质
&lt;ul&gt;
&lt;li&gt;QED&lt;/li&gt;
&lt;li&gt;合成可及性SA&lt;/li&gt;
&lt;li&gt;多样性Div&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;整体评估
&lt;ul&gt;
&lt;li&gt;结合可行性（合理亲和力+构象稳定的分子比例）&lt;/li&gt;
&lt;li&gt;成功率（满足Vina Dock、QED和SA阈值）&lt;/li&gt;
&lt;li&gt;生成效率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;esm-all-atom-multi-scale-protein-language-model-for-unified-molecular-modeling--icml-2024&#34;&gt;ESM All-Atom: Multi-scale Protein Language Model for Unified Molecular Modeling | &lt;em&gt;ICML 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;蛋白质生成领域&lt;/strong&gt;中的&lt;strong&gt;表示学习&lt;/strong&gt;领域。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-11&#34;&gt;解决的问题
&lt;/h3&gt;&lt;p&gt;当前蛋白质语言模型主要在残基尺度运行，无法提供原子尺度信息。&lt;/p&gt;
&lt;h3 id=&#34;挑战-11&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;统一分子建模难题&lt;/strong&gt;：残基和原子尺度使用的词汇表不兼容，直接在原子尺度对蛋白质进行表示和预训练效率低下，难以实现有效的统一分子建模。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;位置编码设计困难&lt;/strong&gt;：设计合适的位置编码来准确描述同一蛋白质中残基和原子之间的关系颇具挑战，涉及残基与残基、残基与原子、原子与原子之间的多种关系，而现有蛋白质语言模型的编码方法无法满足需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-11&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;提出ESMAA（ESM All-Atom），实现原子尺度和残基尺度统一分子建模的新方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在多尺度代码转换蛋白质序列上进行预训练&lt;/li&gt;
&lt;li&gt;利用多尺度位置编码来捕捉残基和原子之间的关系&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-11&#34;&gt;优势
&lt;/h3&gt;&lt;p&gt;ESM-AA 能同时处理残基和原子尺度信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在蛋白质 - 分子任务上表现更优。
&lt;ul&gt;
&lt;li&gt;如在酶 - 底物亲和力回归、药物 - 靶点亲和力回归等任务中超越了其他模型，实现了最先进的结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在蛋白质任务和分子基准测试中也有良好表现&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-11&#34;&gt;数据集
&lt;/h3&gt;&lt;p&gt;预训练数据集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;蛋白质
&lt;ul&gt;
&lt;li&gt;AlphaFold DB 数据集： 800 万个由 AlphaFold2 预测的高置信度（PLDDT &amp;gt; 90）蛋白质序列和结构&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;小分子
&lt;ul&gt;
&lt;li&gt;使用 Zhou 等人提供的数据集：含有 1900 万个分子和 2.09 亿个由 ETKGD 和默克分子力场生成的构象&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-11&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;蛋白质 - 分子任务&lt;/strong&gt;：在酶 - 底物亲和力回归、药物 - 靶点亲和力回归和酶 - 底物对分类任务上进行微调评估，将模型预测结果与实验数据对比，使用均方误差（MSE）、决定系数（R²）、皮尔逊相关系数、准确率（ACC）、马修斯相关系数（MCC）、受试者工作特征曲线下面积（ROC-AUC）等指标衡量性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;蛋白质任务&lt;/strong&gt;：通过二级结构预测和无监督接触预测任务测试模型对蛋白质结构的理解能力，使用准确率等指标评估，且模型输入为纯残基序列。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分子任务&lt;/strong&gt;：利用标准分子基准测试 MoleculeNet 中的任务，如分子性质分类和回归任务，使用平均绝对误差（MAE）、AUC 等指标评估模型性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;mol-ae-auto-encoder-based-molecular-representation-learning-with-3d-cloze-test-objective--icml-2024&#34;&gt;Mol-AE: Auto-Encoder Based Molecular Representation Learning With 3D Cloze Test Objective | &lt;em&gt;ICML 2024&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;这篇文章属于&lt;strong&gt;分子生成&lt;/strong&gt;领域中的&lt;strong&gt;3D分子表示学习&lt;/strong&gt;方向。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题-12&#34;&gt;解决的问题
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;encoder-only model在预训练和下游任务目标之间存在不一致性，导致预训练学到的特征在下游任务中迁移性差&lt;/li&gt;
&lt;li&gt;坐标去噪目标会引发训练不稳定以及引入不真实噪声，同时原子坐标在该过程中作为内容和标识符的双重角色产生冲突，影响模型性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挑战-12&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;克服预训练和下游任务目标不一致带来的难题，使模型在不同阶段学到的特征能有效应用于实际任务&lt;/li&gt;
&lt;li&gt;解决坐标去噪导致的训练不稳定和原子标识符混乱问题，让模型能够稳定训练并准确学习分子结构信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心方法-12&#34;&gt;核心方法
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307133620.png&#34;
	width=&#34;1494&#34;
	height=&#34;520&#34;
	srcset=&#34;https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307133620_hu_3841c968d52cfb5c.png 480w, https://ionfeather.github.io/2025/ai-assist-drug-design/assets/20250307133620_hu_657a213ac5e44cb1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;MOL-AE框架&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;287&#34;
		data-flex-basis=&#34;689px&#34;
	
&gt;&lt;br&gt;
提出 MOL-AE 模型，核心包含基于 Transformer 的 3D 信息感知自编码器结构以及 3D Cloze Test 目标。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整体架构：
&lt;ul&gt;
&lt;li&gt;MOL-AE 模型处理 3D 分子时，主要聚焦 3D 结构和原子类型信息。
&lt;ul&gt;
&lt;li&gt;原子类型建模：可借助原子 MLM 目标轻松实现&lt;/li&gt;
&lt;li&gt;3D 结构的建模：模型由编码器\(q_{\phi}\)、解码器\(p_{\theta}\)构成，且二者均以 Transformer 架构为基础。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D 信息感知自编码器&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Transformer Block&lt;/strong&gt;：Transformer 由多个 Transformer 块组成，每个块包含多头自注意力层和前馈层。此过程能有效捕捉分子信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D 感知成对特征&lt;/strong&gt;：因普通 Transformer 难以处理 3D 信息，MOL-AE 采用将&lt;strong&gt;原子对之间的欧几里得距离编码&lt;/strong&gt;为额外成对特征的方法。帮助模型更好地理解分子的3D结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编码器和解码器&lt;/strong&gt;：编码器\(q_{\phi}\)由\(L^{enc}\)层 Transformer 块构成，3D 坐标信息C经其处理后编码为\(X^{L^{enc}}\) ，并将其作为潜在表示Z 。解码器\(p_{\theta}\)由\(L^{dec}\)层 Transformer 块组成，由于 3D 结构已编码在Z中，其输入成对特征初始化为零。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3D Cloze Test 目标&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;添加位置编码（PE）到解码器&lt;/strong&gt;：为&lt;strong&gt;解决坐标去噪中原子标识符混乱问题&lt;/strong&gt;，MOL-AE 在解码器中添加 PE。
&lt;ul&gt;
&lt;li&gt;在打乱坐标时，PE 作为稳定的标识符，帮助模型区分不同原子。同时，仅在解码器添加 PE 可避免引入的顺序信息对编码器学习分子高质量表示产生影响。&lt;/li&gt;
&lt;li&gt;这里可以类比GPT会添加位置编码。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子丢弃&lt;/strong&gt;：传统去噪目标可能使模型学习不可靠的噪声分布，MOL-AE 通过&lt;strong&gt;随机丢弃部分原子及其坐标&lt;/strong&gt;（如从输入坐标C中随机移除k行得到\(D(C)\) ）来干扰数据，使模型专注于剩余无噪声的子结构，从而更好地学习原子空间关系。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优势-12&#34;&gt;优势
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;缓解了预训练和下游任务目标不一致的问题，提升了特征的迁移能力&lt;/li&gt;
&lt;li&gt;解决了坐标去噪带来的不稳定训练和原子标识符混乱问题，使模型训练更稳定&lt;/li&gt;
&lt;li&gt;在多个分子理解任务中性能显著优于当前最先进的 3D 分子建模方法，在分子分类和回归任务的基准测试中取得了优异成绩&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据集-12&#34;&gt;数据集
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;预训练数据集&lt;/strong&gt;：使用 Zhou 等人提供的大规模分子数据集，包含 1900 万个分子和 2.09 亿个构象，由 ETKGD 和 Merck 分子力场生成，每个分子有 11 个随机生成的构象，为提高计算效率，预训练时去除了氢原子，未明确该数据集是否公开。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微调数据集&lt;/strong&gt;：采用广泛使用的 MoleculeNet 基准数据集，包括 9 个分类数据集和 6 个回归数据集，该数据集公开。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;评测方式-12&#34;&gt;评测方式
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分子分类任务&lt;/strong&gt;：使用 ROC-AUC 作为评估指标，在 9 个分类数据集上进行实验，数据集为 MoleculeNet 中的相关分类数据集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分子回归任务&lt;/strong&gt;：采用平均绝对误差（MAE）和均方根误差（RMSE）作为评估指标，在 6 个回归数据集上进行实验，数据集为 MoleculeNet 中的相关回归数据集。通过与多个监督和预训练方法的对比，评估 MOL-AE 的性能。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>论文阅读 | 多智能体协作机制：大语言模型综述</title>
        <link>https://ionfeather.github.io/2025/multiagentcollaboration/</link>
        <pubDate>Sat, 15 Feb 2025 21:58:31 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/multiagentcollaboration/</guid>
        <description>&lt;h2 id=&#34;论文阅读--多智能体协作机制大语言模型综述&#34;&gt;论文阅读 | 多智能体协作机制：大语言模型综述
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2306.03314&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;[2306.03314] Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;摘要&#34;&gt;摘要
&lt;/h3&gt;&lt;p&gt;随着大语言模型（LLMs）的最新进展，代理式人工智能（Agentic AI）在现实应用中取得了显著进展，朝着基于多个大语言模型的智能体迈进，实现感知、学习、推理和协同行动。这些基于大语言模型的多智能体系统（MASs）使得一组智能体能够协作解决复杂任务，并以大规模方式实现集体行动，从孤立的模型转向以协作为核心的方法。&lt;/p&gt;
&lt;p&gt;本文提供了关于多智能体系统协作方面的广泛综述，并提出了一个可扩展的框架来指导未来的研究。我们的框架根据关键维度对协作机制进行表征：参与者（涉及的智能体）、类型（例如，合作、竞争或合作竞争）、结构（例如，点对点、集中式或分布式）、策略（例如，基于角色或基于模型）以及协调协议。通过对现有方法的回顾，我们的研究成果为揭示和推动基于大语言模型的多智能体系统向更加智能和协作的解决方案发展，特别是在复杂的现实应用中，提供了基础。&lt;/p&gt;
&lt;p&gt;此外，本文还探讨了多智能体系统在不同领域的各种应用，包括5G/6G网络、工业5.0、问答系统、以及社会文化环境，展示了它们的广泛应用和更深远的影响。最后，我们总结了关键经验教训，分析了多智能体系统面临的开放挑战，并指出了朝着人工集体智能发展的潜在研究方向。&lt;/p&gt;
&lt;h3 id=&#34;文章大纲&#34;&gt;文章大纲
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/multiagentcollaboration/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E4%BD%9C.png&#34;
	width=&#34;1220&#34;
	height=&#34;1316&#34;
	srcset=&#34;https://ionfeather.github.io/2025/multiagentcollaboration/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E4%BD%9C_hu_2cc66a817e01abcc.png 480w, https://ionfeather.github.io/2025/multiagentcollaboration/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E4%BD%9C_hu_565ccef7cbcd2d53.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;文章大纲&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;92&#34;
		data-flex-basis=&#34;222px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;方法&lt;/th&gt;
          &lt;th&gt;领域&lt;/th&gt;
          &lt;th&gt;主要贡献&lt;/th&gt;
          &lt;th&gt;优点&lt;/th&gt;
          &lt;th&gt;缺点&lt;/th&gt;
          &lt;th&gt;参考文献&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;LLM-SC&lt;/td&gt;
          &lt;td&gt;物联网&lt;/td&gt;
          &lt;td&gt;作为知识生成器增强语义解码器&lt;/td&gt;
          &lt;td&gt;利用大语言模型，实现显著的编码增益&lt;/td&gt;
          &lt;td&gt;由于使用大语言模型，计算资源需求高&lt;/td&gt;
          &lt;td&gt;[130]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LaMoSC&lt;/td&gt;
          &lt;td&gt;物联网&lt;/td&gt;
          &lt;td&gt;提出一种大语言模型驱动的多模态融合语义通信&lt;/td&gt;
          &lt;td&gt;在低信噪比条件下表现稳健&lt;/td&gt;
          &lt;td&gt;由于使用大语言模型和视觉 Transformer，计算资源需求高&lt;/td&gt;
          &lt;td&gt;[157]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LAM-MSC&lt;/td&gt;
          &lt;td&gt;物联网&lt;/td&gt;
          &lt;td&gt;为多模态数据设计联合编码器；大语言模型作为知识生成器&lt;/td&gt;
          &lt;td&gt;一个编码器和解码器可处理多种类型的数据；实现更好的编码率和重建误差&lt;/td&gt;
          &lt;td&gt;由于使用大语言模型，计算资源需求高&lt;/td&gt;
          &lt;td&gt;[65]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;GMAC&lt;/td&gt;
          &lt;td&gt;物联网&lt;/td&gt;
          &lt;td&gt;利用大语言模型实现观察状态与自然语言之间的语义对齐，并压缩语义信息&lt;/td&gt;
          &lt;td&gt;提高收敛速度；实现无通信的多智能体协作&lt;/td&gt;
          &lt;td&gt;由于使用大语言模型，计算资源需求高&lt;/td&gt;
          &lt;td&gt;[160]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LLM-Blender&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;采用多种大语言模型代理的集成方法进行候选排序&lt;/td&gt;
          &lt;td&gt;能够生成比现有候选更好的输出&lt;/td&gt;
          &lt;td&gt;为实现最优解，需要进行 O (n) 次推理，导致计算开销大&lt;/td&gt;
          &lt;td&gt;[64]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SOT&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;并行生成每个答案框架；完成答案内容（需要规划结构）&lt;/td&gt;
          &lt;td&gt;通过并行加速推理速度；适用于需要长结构答案的问题&lt;/td&gt;
          &lt;td&gt;答案质量评估远非完美，由于提示集有限；不同代理的并行请求可能会影响服务吞吐量&lt;/td&gt;
          &lt;td&gt;[95]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Meta-Prompting&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;构建高级元提示来指导大语言模型&lt;/td&gt;
          &lt;td&gt;保持连贯的推理思路；挖掘各种专家角色&lt;/td&gt;
          &lt;td&gt;多次模型调用成本较高；需要大量的规模和相当大的上下文窗口&lt;/td&gt;
          &lt;td&gt;[119]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MAD&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;两个代理表达各自的论点；一个评判者监控和管理辩论&lt;/td&gt;
          &lt;td&gt;减少偏差和扭曲的认知；鼓励无限的外部反馈&lt;/td&gt;
          &lt;td&gt;由于辩论时间长，计算成本高；大语言模型在长场景中难以保持连贯性和相关性&lt;/td&gt;
          &lt;td&gt;[77]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;FORD&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;包括三个阶段的辩论：公平辩论、不匹配辩论、圆桌辩论&lt;/td&gt;
          &lt;td&gt;通过辩论让大语言模型探索自身理解与他人概念化之间的差异&lt;/td&gt;
          &lt;td&gt;除常识推理外，无法涵盖各种任务；严重依赖多项选择任务，限制了其泛化能力&lt;/td&gt;
          &lt;td&gt;[140]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ChatDev&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;采用聊天链将每个阶段分解为更小的子任务，实现代理之间的多轮通信，以协作开发解决方案&lt;/td&gt;
          &lt;td&gt;最大限度减少代码幻觉（提供的源代码缺失的情况）&lt;/td&gt;
          &lt;td&gt;没有清晰、详细的要求时，代理难以理解任务想法；通用软件的自动化评估非常复杂；多个代理需要更多的令牌和时间，导致计算需求大&lt;/td&gt;
          &lt;td&gt;[105]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;AgentVerse&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;由专家招募、协作决策、行动执行、评估四个阶段组成&lt;/td&gt;
          &lt;td&gt;提高大语言模型在不确定情况下的泛化能力；提高代理的适应性&lt;/td&gt;
          &lt;td&gt;协作决策过程中代理之间的通信存在挑战&lt;/td&gt;
          &lt;td&gt;[24]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;AgentCoord&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;为协调策略提供结构化表示；采用三阶段方法将一般目标转化为可执行策略&lt;/td&gt;
          &lt;td&gt;简化协调策略的表示和探索；最小化代理的重复实例&lt;/td&gt;
          &lt;td&gt;仅支持在纯文本环境中协调代理协作；仅支持静态协调策略设计&lt;/td&gt;
          &lt;td&gt;[97]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;OpenAI&amp;rsquo;s Swarm&lt;/td&gt;
          &lt;td&gt;自然语言生成&lt;/td&gt;
          &lt;td&gt;用于多智能体编排的例程和交接；轻量级协调与执行框架&lt;/td&gt;
          &lt;td&gt;适用于需要可扩展性的应用；交接机制允许在专门代理之间实现无缝过渡&lt;/td&gt;
          &lt;td&gt;主要关注基于角色的协议和集中式 / 分布式结构；尚未准备好投入生产&lt;/td&gt;
          &lt;td&gt;见原文&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;TE&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;在主题研究中模拟人类参与者的代表性样本&lt;/td&gt;
          &lt;td&gt;能够模拟不同的人类行为，并揭示模拟中的一致偏差&lt;/td&gt;
          &lt;td&gt;需要研究更多的人类行为和额外的大语言模型，以确保关键发现的准确性&lt;/td&gt;
          &lt;td&gt;[36]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;AgentInstruct&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;通过迭代的跨代理细化生成多样化的自然语言数据，包括文化数据&lt;/td&gt;
          &lt;td&gt;能够通过工具使用、代理能力等从生成的数据中训练更强大的模型&lt;/td&gt;
          &lt;td&gt;需要人工构建生成流程&lt;/td&gt;
          &lt;td&gt;[88]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SocialMind&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;整合言语、非言语和社交线索，通过增强现实眼镜生成现场建议&lt;/td&gt;
          &lt;td&gt;设计并利用多模态、多层协作代理系统&lt;/td&gt;
          &lt;td&gt;需要先进的边缘硬件来处理复杂系统&lt;/td&gt;
          &lt;td&gt;[144]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CulturePark&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;促使基于大语言模型的代理进行跨文化交流模拟&lt;/td&gt;
          &lt;td&gt;生成的数据可用于训练具有不同文化背景的模型，减少偏差并实现民主化&lt;/td&gt;
          &lt;td&gt;仍然依赖大语言模型对每种文化的了解，因此对资源较少的文化效果有限&lt;/td&gt;
          &lt;td&gt;[73]&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Mango&lt;/td&gt;
          &lt;td&gt;社会与文化领域&lt;/td&gt;
          &lt;td&gt;通过对概念和文化的提示，从基于大语言模型的代理中提取高质量知识&lt;/td&gt;
          &lt;td&gt;自动化方法可生成大量资源&lt;/td&gt;
          &lt;td&gt;人类评估需要来自更多样化的背景&lt;/td&gt;
          &lt;td&gt;[94]&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;六个思考帽的设计&#34;&gt;六个思考帽的设计
&lt;/h2&gt;&lt;h3 id=&#34;白色思考帽&#34;&gt;白色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：收集客观信息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;对论文进行解析。&lt;/li&gt;
&lt;li&gt;从论文文本中抽取结构化数据。&lt;/li&gt;
&lt;li&gt;从网络中搜索作者之前的研究成果。&lt;/li&gt;
&lt;li&gt;从网络中搜索同类研究的对比数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;绿色思考帽&#34;&gt;绿色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：对论文提出创新性改进，探索论文的可能性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;未定。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;黄色思考帽&#34;&gt;黄色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：积极角度评估论文，找出论文的优点和贡献。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;用优点和创新点微调后的大模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;黑色思考帽&#34;&gt;黑色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：批判性思考，找出论文的问题和不足。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;用批判性数据集微调后的大模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;红色思考帽&#34;&gt;红色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：主观感受和直觉判断。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;让智能体多阅读论文，找到好的论文之间的共性和形成自己的「偏好」。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;蓝色思考帽&#34;&gt;蓝色思考帽
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;/strong&gt;：控制评审流程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实现方式&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;未定。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;蓝色思考帽智能体应该如何控制&#34;&gt;蓝色思考帽智能体应该如何控制？
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;基于&lt;strong&gt;工作流管理&lt;/strong&gt;的集中式控制方法。蓝色智能体明确规定了其他智能体的工作顺序、时间和交互方式。&lt;/li&gt;
&lt;li&gt;基于&lt;strong&gt;协商机制&lt;/strong&gt;的分布式控制方法。在评审开始时，蓝色智能体发起评审任务，各思考帽智能体根据自身能力和状态反馈可承担的工作及预计时间。比如白色告诉蓝色需要5分钟完成，绿色说在白色完成后需要10分钟&amp;hellip;通过这些反馈，蓝色智能体来制定计划。&lt;/li&gt;
&lt;li&gt;基于&lt;strong&gt;事件驱动&lt;/strong&gt;的动态控制方法。不同的智能体换成之后会触发不同的事件，如白色完成后让绿色工作，黑色和黄色在辩论后无法达成共识，就再次进行辩论等。这个事件定义较难。&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>学习笔记 | 《动手学深度学习》</title>
        <link>https://ionfeather.github.io/2025/d2l-01/</link>
        <pubDate>Wed, 08 Jan 2025 16:00:34 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2025/d2l-01/</guid>
        <description>&lt;img src="https://ionfeather.github.io/2025/d2l-01/assets/cover.png" alt="Featured image of post 学习笔记 | 《动手学深度学习》" /&gt;&lt;h2 id=&#34;全书结构&#34;&gt;全书结构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/d2l-01/assets/image-20250108163545542.png&#34;
	width=&#34;574&#34;
	height=&#34;438&#34;
	srcset=&#34;https://ionfeather.github.io/2025/d2l-01/assets/image-20250108163545542_hu_2c7ff3921dd865ae.png 480w, https://ionfeather.github.io/2025/d2l-01/assets/image-20250108163545542_hu_89d09c9d201057b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;全书结构&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;131&#34;
		data-flex-basis=&#34;314px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;预备知识&#34;&gt;预备知识
&lt;/h2&gt;&lt;h3 id=&#34;张量&#34;&gt;张量
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;张量表示一个由数值组成的数组，这个数组可能有多个维度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;具有一个轴的张量对应数学上的&lt;em&gt;向量&lt;/em&gt;（vector）； 具有两个轴的张量对应数学上的&lt;em&gt;矩阵&lt;/em&gt;（matrix）； 具有两个轴以上的张量没有特殊的数学名称。&lt;/p&gt;
&lt;h4 id=&#34;张量的创建&#34;&gt;张量的创建
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;numel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zeros&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ones&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;randn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;运算符&#34;&gt;运算符
&lt;/h4&gt;&lt;h5 id=&#34;按元素运算&#34;&gt;按元素运算
&lt;/h5&gt;&lt;p&gt;常见的运算符这里用作按元素运算。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# **运算符是求幂运算&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以得到&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Python&#34; data-lang=&#34;Python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;6.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;10.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;6.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;8.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;16.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.0000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;4.0000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;mf&#34;&gt;4.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;16.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;64.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;还有很多的一元运算符都可以用在按元素运算。&lt;/p&gt;
&lt;h5 id=&#34;线性代数运算&#34;&gt;线性代数运算
&lt;/h5&gt;&lt;h6 id=&#34;求和平均值&#34;&gt;求和/平均值
&lt;/h6&gt;&lt;p&gt;直接调用&lt;code&gt;sum&lt;/code&gt;函数，会将其变成一个标量，也可以指定&lt;code&gt;axis = 1&lt;/code&gt;维度来指定轴来进行降维。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 对于矩阵来说，相当于A.sum()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同理，&lt;code&gt;A.mean()&lt;/code&gt;也是一样的。&lt;/p&gt;
&lt;p&gt;如果希望能够在求和或者平均值的时候保持轴数不变，可以使用&lt;code&gt;keepdims  = True&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果希望能够沿着某个轴计算A元素的累计总和，可以使用&lt;code&gt;cumsum&lt;/code&gt;函数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sum_A&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keepdims&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cumsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;点积&#34;&gt;点积
&lt;/h5&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ones&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;矩阵-向量积&#34;&gt;矩阵-向量积
&lt;/h5&gt;&lt;p&gt;当我们为矩阵&lt;code&gt;A&lt;/code&gt;和向量&lt;code&gt;x&lt;/code&gt;调用&lt;code&gt;torch.mv(A, x)&lt;/code&gt;时，会执行矩阵-向量积。 注意，&lt;code&gt;A&lt;/code&gt;的列维数（沿轴1的长度）必须与&lt;code&gt;x&lt;/code&gt;的维数（其长度）相同。&lt;/p&gt;
&lt;h5 id=&#34;矩阵-矩阵乘法&#34;&gt;矩阵-矩阵乘法
&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;我们可以将矩阵-矩阵乘法AB看作简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n×m矩阵&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在下面的代码中，我们在&lt;code&gt;A&lt;/code&gt;和&lt;code&gt;B&lt;/code&gt;上执行矩阵乘法。 这里的&lt;code&gt;A&lt;/code&gt;是一个5行4列的矩阵，&lt;code&gt;B&lt;/code&gt;是一个4行3列的矩阵。 两者相乘后，我们得到了一个5行3列的矩阵。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ones&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;张量连结&#34;&gt;张量连结
&lt;/h4&gt;&lt;p&gt;在这里，&lt;code&gt;dim=0&lt;/code&gt;说明是第一个维度进行拼接；&lt;code&gt;dim=1&lt;/code&gt;说明是第二个维度进行拼接。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;广播机制&#34;&gt;广播机制
&lt;/h4&gt;&lt;p&gt;特别需要注意这个，可能会导致错误发生。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;b&lt;/code&gt;分别是3×1和1×2矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵&lt;em&gt;广播&lt;/em&gt;为一个更大的3×2矩阵，如下所示：矩阵&lt;code&gt;a&lt;/code&gt;将复制列， 矩阵&lt;code&gt;b&lt;/code&gt;将复制行，然后再按元素相加。&lt;/p&gt;
&lt;h4 id=&#34;索引和切片&#34;&gt;索引和切片
&lt;/h4&gt;&lt;p&gt;与Dataframe中相似。&lt;/p&gt;
&lt;h4 id=&#34;节省内存&#34;&gt;节省内存
&lt;/h4&gt;&lt;p&gt;如果直接使用&lt;code&gt;X = X + Y&lt;/code&gt;就是重新创建一个元素。但是，有些时候希望执行原地操作。&lt;/p&gt;
&lt;p&gt;如果希望执行原地操作的话，可以使用两种方式，此时不会占用新的空间：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;转换为其他对象&#34;&gt;转换为其他对象
&lt;/h4&gt;&lt;p&gt;转换为Numpy非常容易：&lt;code&gt;A = X.numpy()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;转换为Python标量：&lt;code&gt;a.item()&lt;/code&gt;或者使用内置函数&lt;code&gt;float(a)&lt;/code&gt;等。&lt;/p&gt;
&lt;h3 id=&#34;自动求导&#34;&gt;自动求导
&lt;/h3&gt;&lt;p&gt;自动求导是计算一个函数在指定值上的导数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何实现？&lt;/li&gt;
&lt;li&gt;计算图：将代码分解成操作子，将计算表示成一个无环图。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/d2l-01/assets/%E6%97%A0%E7%8E%AF%E5%9B%BE.jpg&#34;
	width=&#34;987&#34;
	height=&#34;476&#34;
	srcset=&#34;https://ionfeather.github.io/2025/d2l-01/assets/%E6%97%A0%E7%8E%AF%E5%9B%BE_hu_369313ef0052026b.jpg 480w, https://ionfeather.github.io/2025/d2l-01/assets/%E6%97%A0%E7%8E%AF%E5%9B%BE_hu_2ac197cd817af25b.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;将计算表示为一个无环图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;497px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;关于计算图，有&lt;strong&gt;显式构造 vs 隐式构造&lt;/strong&gt;两种构造方式。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;特性&lt;/th&gt;
          &lt;th&gt;显式构造&lt;/th&gt;
          &lt;th&gt;隐式构造&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;计算图构建方式&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;显式定义&lt;/td&gt;
          &lt;td&gt;隐式定义&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;计算图类型&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;静态图&lt;/td&gt;
          &lt;td&gt;动态图&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;典型框架&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;TensorFlow 1.x, Theano&lt;/td&gt;
          &lt;td&gt;PyTorch, TensorFlow 2.x (Eager)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;有两种求导的方式，对于一个链式法则，我们可以采取正向累积和反向累积（也称反向传递）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以 \( y = (x_1 + 2x_2)^2 \) 为例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;反向传递&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;前向计算 \( z=11, y=121 \)。&lt;/li&gt;
&lt;li&gt;反向计算 \( \partial y/\partial z=22 \rightarrow \partial y/\partial x_1=22, \partial y/\partial x_2=44 \)。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;正向传递&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;前向计算 \( z=11 \)，同时记录 \( \partial z/\partial x_1=1, \partial z/\partial x_2=2 \)。&lt;/li&gt;
&lt;li&gt;前向计算 \( y=121 \)，同时记录 \( \partial y/\partial z=22 \)。&lt;/li&gt;
&lt;li&gt;直接组合导数得到 \( \partial y/\partial x_1=22 \times 1=22 \)，\( \partial y/\partial x_2=22 \times 2=44 \)。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;反向累积&#34;&gt;反向累积
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://ionfeather.github.io/2025/d2l-01/assets/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92.png&#34;
	width=&#34;1055&#34;
	height=&#34;1019&#34;
	srcset=&#34;https://ionfeather.github.io/2025/d2l-01/assets/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92_hu_fc5fe943b796734d.png 480w, https://ionfeather.github.io/2025/d2l-01/assets/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92_hu_2f08d5ae5db2873d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;反向传递&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;103&#34;
		data-flex-basis=&#34;248px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;使用反向传递的时候，在我们计算$y$关于$x$的梯度之前，需要一个地方来存储梯度。&lt;/p&gt;
&lt;p&gt;重要的是，我们不会在每次对一个参数求导时都分配新的内存。 因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。 注意，一个标量函数关于向量$x$的梯度是向量，并且与$x$具有相同的形状。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>操作记录 | 虚拟环境配置操作记录</title>
        <link>https://ionfeather.github.io/2024/virtual-environment-config/</link>
        <pubDate>Sun, 15 Dec 2024 20:24:19 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2024/virtual-environment-config/</guid>
        <description>&lt;img src="https://ionfeather.github.io/2024/virtual-environment-config/cover.jpg" alt="Featured image of post 操作记录 | 虚拟环境配置操作记录" /&gt;&lt;h2 id=&#34;虚拟环境配置经历&#34;&gt;虚拟环境配置经历
&lt;/h2&gt;&lt;p&gt;我之前配置好了一个虚拟环境名为&lt;code&gt;vllm&lt;/code&gt;，专门用于vllm的启动，我还特意将其中的虚拟环境中的所有包的版本保存到&lt;code&gt;vllm_requirements.txt&lt;/code&gt;文件中。&lt;/p&gt;
&lt;p&gt;但是我一顿操作之后，原本配置好的环境现在也没办法使用了。此时我庆幸自己想到用&lt;code&gt;vllm_requirements.txt&lt;/code&gt;文件保存。但是在进行&lt;code&gt;pip install -r vllm_requirements.txt&lt;/code&gt;的时候，出现了报错的情况，竟然说里面有一个包的版本是yanked version（撤回版本），无法下载，给我气晕了。&lt;/p&gt;
&lt;p&gt;吃一堑，长一智。配置好的环境就不要变了，应该另外复制一个环境，在复制的环境上进行修改。&lt;/p&gt;
&lt;p&gt;此外，我每次进行配置环境我都会忘记怎么配置和删除。是我最近记性变得太差了吗？总之我写一个文档，记不住就查一下。&lt;/p&gt;
&lt;h2 id=&#34;配置环境&#34;&gt;配置环境
&lt;/h2&gt;&lt;h3 id=&#34;使用conda配置虚拟环境&#34;&gt;使用conda配置虚拟环境
&lt;/h3&gt;&lt;h4 id=&#34;创建新的环境&#34;&gt;创建新的环境
&lt;/h4&gt;&lt;p&gt;使用Terminal创建新的环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n &amp;lt;new_env_name&amp;gt; &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.10.0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;激活虚拟环境&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate &amp;lt;new_env_name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;安装包&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install &amp;lt;package&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install &amp;lt;package&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;从已有的文件中安装包虚拟环境&#34;&gt;从已有的文件中安装包/虚拟环境
&lt;/h4&gt;&lt;p&gt;如果想要安装&lt;code&gt;requirements.txt&lt;/code&gt;文件，就可以直接&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果想要安装的是&lt;code&gt;environment.yml&lt;/code&gt;文件，应该改用&lt;code&gt;conda&lt;/code&gt;来创建虚拟环境&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda env create -f environment.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看虚拟环境列表&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda env list
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;复制原来已有的虚拟环境&#34;&gt;复制原来已有的虚拟环境
&lt;/h4&gt;&lt;p&gt;如果有一个环境已经配置好，我不希望破坏它，可以复制一个一模一样的环境，再在上面进行修改，这样就不会导致原来那个环境产生问题。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create --name &amp;lt;new_env_name&amp;gt; --clone &amp;lt;old_env_name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;删除虚拟环境&#34;&gt;删除虚拟环境
&lt;/h4&gt;&lt;p&gt;删除指定的虚拟环境&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate base
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda remove -n &amp;lt;env_name&amp;gt; --all
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;在conda中配置jupyter内核&#34;&gt;在conda中配置Jupyter内核
&lt;/h3&gt;&lt;h4 id=&#34;安装jupyter内核&#34;&gt;安装Jupyter内核
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;总是忘记Jupyter内核如何配置。记录一下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;安装ipykernel。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install ipykernel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将虚拟内核添加到jupyter内核中。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python -m ipykernel install --user --name &amp;lt;your_env_name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;删除jupyter内核&#34;&gt;删除jupyter内核
&lt;/h4&gt;&lt;p&gt;查看目前有的jupyter内核&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;jupyter kernelspec list
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;删除指定的jupyter内核&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;jupyter kernelspec remove &amp;lt;your_kernel_name&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;照片&#34;&gt;照片
&lt;/h2&gt;&lt;p&gt;照片是2024/12/7的时候同门团建的时候我拿大疆Pocket3拍的。拍的建筑是东郊民巷的圣弥厄尔大教堂。非常开心的一天。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>学习笔记 | LangChain学习笔记</title>
        <link>https://ionfeather.github.io/2024/langchain-learning/</link>
        <pubDate>Tue, 26 Nov 2024 13:45:58 +0800</pubDate>
        
        <guid>https://ionfeather.github.io/2024/langchain-learning/</guid>
        <description>&lt;img src="https://ionfeather.github.io/2024/langchain-learning/cover.png" alt="Featured image of post 学习笔记 | LangChain学习笔记" /&gt;&lt;h2 id=&#34;为什么要学习langchain&#34;&gt;为什么要学习LangChain
&lt;/h2&gt;&lt;p&gt;我希望能够构建一个能阅读PDF论文的Agent，并且能够输出对论文优缺点的评价。&lt;/p&gt;

&lt;div class=&#34;chat --other&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34;&gt;导师&amp;nbsp;&amp;nbsp;&amp;nbsp;2024-10-12 14:30&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
做一个论文阅读的大模型。  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;


&lt;div class=&#34;chat --self&#34;&gt;
    &lt;div class=&#34;chat__inner&#34;&gt;
        &lt;div class=&#34;chat__meta&#34; style=&#34;text-align: right;&#34;&gt;2024-10-12 14:45&amp;nbsp;&amp;nbsp;&amp;nbsp;我&lt;/div&gt;
        &lt;div class=&#34;chat__text&#34;&gt;
              
好的老师。  

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .chat {
        margin: 10px;
        padding: 10px;
        position: relative;
         
        transition: transform 0.2s;
         
        max-width: 80%;
        min-width: 15%;
    }
    
    .chat:hover {
        transform: scale(1.05);
    }
    
    .chat.--self {
        text-align: left;
        background-color: #ecf5ff;
        color: #000000;
        border-radius: 15px;
        width: fit-content;
        margin-left: auto;
    }
     
    
    .chat.--self::before {
        content: &#34;&#34;;
        position: absolute;
        right: -18px;
         
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 0 0 20px;
        border-style: solid;
        border-color: transparent transparent transparent #ecf5ff;
         
    }
     
    
    .chat.--other {
        text-align: left;
        background-color: #ffecec;
        color: #333;
        border-radius: 15px;
        position: relative;
        width: fit-content;
    }
     
    
    .chat.--other::before {
        content: &#34;&#34;;
        position: absolute;
        left: -18px;
        bottom: 5px;
        transform: translateY(-50%);
        border-width: 15px 20px 0 0;
        border-style: solid;
        border-color: transparent #ffecec transparent transparent;
    }
     
    
    .chat__meta {
        font-weight: bold;
        font-size: 0.67em;
        color: #707070;
        margin-bottom: 5px;
    }
     
    
    .chat__text {
        font-size: 0.9em;
        margin-left: 10px;
        word-break: break-all;
    }
    
    [data-scheme=&#34;dark&#34;] {
        .chat.--self {
            color: #fefefe;
            background-color: #253958;
        }
        .chat.--self::before {
            border-color: transparent transparent transparent #253958;
        }
        .chat.--other {
            color: #fefefe;
            background-color: #1a1a1a;
        }
        .chat.--other::before {
            border-color: transparent #1a1a1a transparent transparent;
        }
        .chat__meta {
            color: #b1b1b1;
        }
    }
&lt;/style&gt;

&lt;p&gt;使用LangChain听说比较方便。&lt;/p&gt;
&lt;h2 id=&#34;langchain是用来做什么的&#34;&gt;LangChain是用来做什么的？
&lt;/h2&gt;&lt;p&gt;LangChain是一个用于开发由LLM驱动的应用程序的框架。也就是说我们可以把LLM作为内核，LangChain作为外壳，搭建一个程序出来。&lt;/p&gt;
&lt;p&gt;LangChain提供了&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;组件：处理LLM的组件的抽象；&lt;/li&gt;
&lt;li&gt;定制链：把组件拼起来，实现一个特定用例。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于阅读PDF，目前有两个想法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将PDF转为JSON，然后输入到LLM中；&lt;/li&gt;
&lt;li&gt;构建RAG。使用LangChain能够比较方便地实现这个功能，听ZLB说这个也不是很难。我之前的畏难情绪可能太重了，现在写一个文档，激励和记录一下自己学习。&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
    &lt;summary&gt;RAG是什么？&lt;/summary&gt;
    &lt;p&gt;虽然LLM非常强大，但它们对于它们未经训练的信息一无所知。如果您想使用LLM来回答它未经训练的文档相关问题，您需要向其提供这些文档的信息。最常用的方法是通过“检索增强生成”（ retrieval augmented generation，RAG ）。&lt;/p&gt;
&lt;p&gt;检索增强生成的思想是，在给定一个问题时，首先进行检索步骤以获取任何相关文档。然后将这些文档与原始问题一起传递给语言模型，并让它生成一个回答。然而，为了做到这一点，首先需要将文档以适合进行此类查询的格式呈现。&lt;/p&gt;

&lt;/details&gt;

&lt;h2 id=&#34;构造一个语义搜索引擎&#34;&gt;构造一个语义搜索引擎
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/tutorials/retrievers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Build a semantic search engine | 🦜️🔗 LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;读取pdf&#34;&gt;读取PDF
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;How to load PDFs | 🦜️🔗 LangChain&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这里，文档中推荐使用了pypdf库。这里&lt;/p&gt;
&lt;p&gt;在实际应用中可以使用其他提取效果更好的库。LangChain支持的PDF格式很多，可以选择一下。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Document Loader&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
          &lt;th&gt;Package/API&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfloader&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses &lt;code&gt;pypdf&lt;/code&gt; to load and parse PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/unstructured_file&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Unstructured&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses Unstructured&amp;rsquo;s open source library to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/amazon_textract&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Amazon Textract&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses AWS API to load PDFs&lt;/td&gt;
          &lt;td&gt;API&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/mathpix&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MathPix&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Uses MathPix to load PDFs&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfplumber&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFPlumber&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFPlumber&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfdirectory&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFDirectry&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load a directory with PDF files&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pypdfium2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyPDFium2&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyPDFium2&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pymupdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PyMuPDF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PyMuPDF&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/integrations/document_loaders/pdfminer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDFMiner&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Load PDF files using PDFMiner&lt;/td&gt;
          &lt;td&gt;Package&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;此外，导师之前还给我推荐了&lt;a class=&#34;link&#34; href=&#34;https://github.com/titipata/scipdf_parser&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;titipata/scipdf_parser&lt;/a&gt;库，能够更好地处理图像和扫描文本，并且运行在docker上，便于部署。&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;pypdf的介绍&lt;/summary&gt;
    &lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://pypdf.readthedocs.io/en/stable/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Welcome to pypdf — pypdf 5.1.0 documentation&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;PyPDF 是一个用于处理 PDF 文件的 Python库。它提供了一组工具和功能，用于读取、解析和操作 PDF 文件的内容。&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&#34;splitting&#34;&gt;Splitting
&lt;/h3&gt;&lt;details&gt;
    &lt;summary&gt;原文&lt;/summary&gt;
    &lt;p&gt;For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve &lt;code&gt;Document&lt;/code&gt; objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not &amp;ldquo;washed out&amp;rdquo; by surrounding text.&lt;/p&gt;
&lt;p&gt;We can use &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/concepts/text_splitters/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;text splitters&lt;/a&gt; for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/recursive_text_splitter/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RecursiveCharacterTextSplitter&lt;/a&gt;, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.&lt;/p&gt;
&lt;p&gt;We set &lt;code&gt;add_start_index=True&lt;/code&gt; so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”.&lt;/p&gt;
&lt;p&gt;See &lt;a class=&#34;link&#34; href=&#34;https://python.langchain.com/docs/how_to/document_loader_pdf/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;this guide&lt;/a&gt; for more detail about working with PDFs, including how to extract text from specific sections and images.&lt;/p&gt;

&lt;/details&gt;

&lt;p&gt;对于问题提问的文本来说，直接回答一整页肯定是太粗略了。我们最终的目标是检索回答输入查询的文档对象，进一步拆分 PDF 将有助于确保文档相关部分的含义不会被周围的文本“冲淡”。&lt;/p&gt;
&lt;p&gt;所以接下来应该用文本分割器来进行分割（Splitting）处理。这里用一个&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;进行分割。这里使用常见分隔符来对文档进行分割，适用于一般的文本。&lt;/p&gt;

&lt;div class=&#34;notice notice-warning&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 576 512&#34; fill=&#34;#704343&#34;&gt;&lt;path d=&#34;M570 440c18 32-5 72-42 72H48c-37 0-60-40-42-72L246 24c19-32 65-32 84 0l240 416zm-282-86a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;使用&lt;code&gt;RecursiveCharacterTextSplitter&lt;/code&gt;无法读取图像或特定区域的文本。&lt;/p&gt;&lt;/div&gt;

&lt;h3 id=&#34;embeddings&#34;&gt;Embeddings
&lt;/h3&gt;&lt;p&gt;接下来将文本嵌入到向量中去，便于进行相似度指标来识别相关文本。&lt;/p&gt;
&lt;p&gt;这里LangChain支持数十种Embeddings方法。这里我选择了使用Hugging Face，可以选择将模型下载至本地或者使用&lt;code&gt;Hugging Face Inference API&lt;/code&gt;来调用接口。这里可以直接使用&lt;code&gt;HuggingFaceEmbeddings&lt;/code&gt;来进行处理。非常方便。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_huggingface&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HuggingFaceEmbeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sentence-transformers/all-mpnet-base-v2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings_model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Generated vectors of length &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;vector-stores&#34;&gt;Vector Stores
&lt;/h3&gt;&lt;p&gt;LangChain的Vector Stores对象包括了一些把文本和Document对象加入到Stores中的方法，然后通过相似性进行一个排列。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.vectorstores&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InMemoryVectorStore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;add_documents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;documents&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_splits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;此时就完成了存储和排列。&lt;/p&gt;
&lt;p&gt;这里向量存储一般来说是可以连接到现有的Vector Stores中的。&lt;/p&gt;
&lt;h3 id=&#34;usage&#34;&gt;Usage
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;查询和这句话相似的句子&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;Diffusion is a image generation method.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;异步查询（用于流程控制）&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;asimilarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;返回分数&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Note that providers implement different scores; &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# the score here is a distance metric that varies inversely with similarity.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_with_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is Diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Score: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;doc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;通过和embedded query的相似度进行查询&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;embeddings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embed_query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search_by_vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;retrievers&#34;&gt;Retrievers
&lt;/h3&gt;&lt;p&gt;检索器（Retriever）可以从向量存储中进行构建，但是也可以和非向量形式进行交互。如果我们要构建一个能够检索文档的方法的话，我们可以创建一个runnable的检索器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;typing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.documents&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_core.runnables&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@chain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Document&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector_store&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;similarity_search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is diffusion?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is forward process?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;至此，我们构建了一个能够读多篇PDF文章的、能够对PDF文章进行查询的语义搜索引擎。&lt;/p&gt;
&lt;h2 id=&#34;chat-models和prompt模板&#34;&gt;Chat Models和Prompt模板
&lt;/h2&gt;&lt;p&gt;这里通过Vllm启动LLM，以Qwen2.5-7B-Instruct模型为例。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain_community.llms&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VLLM&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/home/ubuntu/jjq/Qwen/Qwen2.5-7B-Instruct/&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;trust_remote_code&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_new_tokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;top_p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.95&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;temperature&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           &lt;span class=&#34;n&#34;&gt;max_model_len&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;What is the capital of France ?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来设计Prompt模板。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LLMChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.memory&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.chains&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.prompts.chat&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ChatPromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SystemMessagePromptTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;HumanMessagePromptTemplate&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;template&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        【任务描述】
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        请仔细阅读论文，回答用户给出的问题，尽量具有批判性。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        【论文】
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        {{context}}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        -----------
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{question}&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 检索器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;as_retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 记忆&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationBufferMemory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;chat_history&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 构建Agent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConversationalRetrievalChain&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;llm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;retriever&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;memory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;qa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;question&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;能不能用中文给出论文的优势或者前景？&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
